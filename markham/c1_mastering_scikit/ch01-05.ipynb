{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course: [Master Machine Learning with scikit-learn](https://courses.dataschool.io/view/courses/master-machine-learning-with-scikit-learn)\n",
    "\n",
    "## Chapters 1-5\n",
    "\n",
    "*Â© 2022 Data School. All rights reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Course overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High-level topics:**\n",
    "\n",
    "- Handling missing values, text data, categorical data, and class imbalance\n",
    "- Building a reusable workflow\n",
    "- Feature engineering, selection, and standardization\n",
    "- Avoiding data leakage\n",
    "- Tuning your entire workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How you will benefit from this course:**\n",
    "\n",
    "- Knowledge of best practices\n",
    "- Confidence when tackling new ML problems\n",
    "- Ability to anticipate and solve problems\n",
    "- Improved code quality\n",
    "- Better, faster results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 scikit-learn vs Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benefits of scikit-learn:**\n",
    "\n",
    "- Consistent interface to many models\n",
    "- Many tuning parameters (but sensible defaults)\n",
    "- Workflow-related functionality\n",
    "- Exceptional documentation\n",
    "- Active community support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drawbacks of deep learning:**\n",
    "\n",
    "- More computational resources\n",
    "- Higher learning curve\n",
    "- Less interpretable models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Prerequisite skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scikit-learn prerequisites:**\n",
    "\n",
    "- Loading a dataset\n",
    "- Defining the features and target\n",
    "- Training and evaluating a model\n",
    "- Making predictions with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New to scikit-learn?**\n",
    "\n",
    "- Enroll in \"Introduction to Machine Learning with scikit-learn\" (free)\n",
    "- Available at https://courses.dataschool.io\n",
    "- Complete lessons 1 through 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Course setup and software versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to install scikit-learn and pandas:**\n",
    "\n",
    "- **Option 1:** Install together\n",
    "  - **Anaconda:** https://www.anaconda.com/products/distribution\n",
    "- **Option 2:** Install separately\n",
    "  - **scikit-learn:** https://scikit-learn.org\n",
    "  - **pandas:** https://pandas.pydata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scikit-learn version:**\n",
    "\n",
    "- **Course version:** 0.23.2\n",
    "- **Minimum version:** 0.20.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to install scikit-learn 0.23.2:**\n",
    "\n",
    "- **Option 1:** conda install scikit-learn==0.23.2\n",
    "- **Option 2:** pip install -U scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Google Colab with the course:**\n",
    "\n",
    "- Similar to the Jupyter Notebook\n",
    "- Runs in your browser\n",
    "- Free (but requires a Google account)\n",
    "- Available at https://colab.research.google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Course outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapters:**\n",
    "\n",
    "1. Introduction\n",
    "2. Review of the Machine Learning workflow\n",
    "3. Encoding categorical features\n",
    "4. Improving your workflow with ColumnTransformer and Pipeline\n",
    "5. Workflow review #1\n",
    "6. Encoding text data\n",
    "7. Handling missing values\n",
    "8. Fixing common workflow problems\n",
    "9. Workflow review #2\n",
    "10. Evaluating and tuning a Pipeline\n",
    "11. Comparing linear and non-linear models\n",
    "12. Ensembling multiple models\n",
    "13. Feature selection\n",
    "14. Feature standardization\n",
    "15. Feature engineering with custom transformers\n",
    "16. Workflow review #3\n",
    "17. High-cardinality categorical features\n",
    "18. Class imbalance\n",
    "19. Class imbalance walkthrough\n",
    "20. Going further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lesson types:**\n",
    "\n",
    "- Core lessons\n",
    "- Q&A lessons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why not focus on algorithms?**\n",
    "\n",
    "- Workflow will have a greater impact on your results\n",
    "- Reusable workflow enables you to try many different algorithms\n",
    "- Hard to know (in advance) which algorithm will work best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Course datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets:**\n",
    "\n",
    "- Titanic\n",
    "- US census\n",
    "- Mammography scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use smaller datasets?**\n",
    "\n",
    "- Easier and faster access to files\n",
    "- Reduced computational time\n",
    "- Greater understanding of the course material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Meet your instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About me:**\n",
    "\n",
    "- Founder of Data School\n",
    "- Teaching data science for 7+ years\n",
    "- Passionate about teaching people who are new to data science\n",
    "- Live in Asheville, North Carolina\n",
    "- Degree in Computer Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Review of the Machine Learning workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Loading and exploring a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:40.690225600Z",
     "start_time": "2023-09-17T05:40:39.963317400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('http://bit.ly/MLtrain', nrows=10)\n",
    "df = pd.read_csv('titanic_train.csv', nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:44.431721800Z",
     "start_time": "2023-09-17T05:40:43.127975200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Survived  Pclass                                               Name  \\\n0         0       3                            Braund, Mr. Owen Harris   \n1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n2         1       3                             Heikkinen, Miss. Laina   \n3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n4         0       3                           Allen, Mr. William Henry   \n5         0       3                                   Moran, Mr. James   \n6         0       1                            McCarthy, Mr. Timothy J   \n7         0       3                     Palsson, Master. Gosta Leonard   \n8         1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n9         1       2                Nasser, Mrs. Nicholas (Adele Achem)   \n\n      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n3  female  35.0      1      0            113803  53.1000  C123        S  \n4    male  35.0      0      0            373450   8.0500   NaN        S  \n5    male   NaN      0      0            330877   8.4583   NaN        Q  \n6    male  54.0      0      0             17463  51.8625   E46        S  \n7    male   2.0      3      1            349909  21.0750   NaN        S  \n8  female  27.0      0      2            347742  11.1333   NaN        S  \n9  female  14.0      1      0            237736  30.0708   NaN        C  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Moran, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy, Mr. Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Palsson, Master. Gosta Leonard</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning terminology:**\n",
    "\n",
    "- **Target:** Goal of prediction\n",
    "- **Classification:** Problem with a categorical target\n",
    "- **Feature:** Input to the model (column)\n",
    "- **Sample:** Single observation (row)\n",
    "- **Training data:** Data with known target values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection methods:**\n",
    "\n",
    "- Human intuition\n",
    "- Domain knowledge\n",
    "- Data exploration\n",
    "- Automated methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Currently selected features:**\n",
    "\n",
    "- **Parch:** Number of parents or children aboard with that passenger\n",
    "- **Fare:** Amount the passenger paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:49:28.140934600Z",
     "start_time": "2023-09-17T05:49:28.025838400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Parch     Fare\n0      0   7.2500\n1      0  71.2833\n2      0   7.9250\n3      0  53.1000\n4      0   8.0500\n5      0   8.4583\n6      0  51.8625\n7      1  21.0750\n8      2  11.1333\n9      0  30.0708",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>7.2500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>71.2833</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>7.9250</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>53.1000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>8.0500</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>8.4583</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>51.8625</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>21.0750</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>11.1333</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>30.0708</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Parch', 'Fare']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:49:50.602191500Z",
     "start_time": "2023-09-17T05:49:50.455583900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    0\n1    1\n2    1\n3    1\n4    0\n5    0\n6    0\n7    0\n8    1\n9    1\nName: Survived, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Survived']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:49:52.664298100Z",
     "start_time": "2023-09-17T05:49:52.380548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(10, 2)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:49:55.475943800Z",
     "start_time": "2023-09-17T05:49:55.329262700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(10,)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Building and evaluating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:55:56.780127400Z",
     "start_time": "2023-09-17T05:55:53.335287Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've defined X and y, our next step is to build and evaluate a model.\n",
    "\n",
    "To start, we're going to use logistic regression as our model. It's a good default choice for classification problems because it's both fast and interpretable.\n",
    "\n",
    "We import it from the linear_model module, and then we create an instance called logreg. This is our model object.\n",
    "\n",
    "The default solver for logistic regression has changed between different scikit-learn versions, but in this course I'm going to set the solver to liblinear. I'm specifying the solver explicitly and setting a value for random_state so that if you run the same code at home, you will most likely get the same results as me.\n",
    "\n",
    "Let's now talk about model evaluation. The goal of model evaluation is to simulate how a model will perform on future data so that we can choose between models today. To do model evaluation, we need both an evaluation procedure and an evaluation metric.\n",
    "\n",
    "The procedure we will use is K-fold cross-validation. Another option is to use train/test split, but cross-validation is generally superior because it gives a lower variance estimate of model performance.\n",
    "\n",
    "The metric we will use is classification accuracy. There are many other classification metrics we could have chosen, but accuracy is suitable for this problem for two reasons:\n",
    "\n",
    "- First, there is not significant class imbalance.\n",
    "- And second, predicting the positive class correctly is just as important to us as predicting the negative class correctly.\n",
    "\n",
    "That being said, I will cover other classification metrics in the chapters on class imbalance.\n",
    "\n",
    "With such a small dataset, we're going to use 3-fold cross-validation, rather than 5 or 10 folds which is more typical. Let me briefly review what happens during 3-fold cross-validation:\n",
    "\n",
    "- The rows are split into 3 subsets, which we'll call A, B, and C.\n",
    "- First, A and B together become the training set, and C becomes the testing set. The model is trained on the training set, the trained model makes predictions for the testing set, and those predictions are evaluated.\n",
    "- Next, A and C together become the training set, and B becomes the testing set. Again, the model is trained, it makes predictions, and the predictions are evaluated.\n",
    "- Finally, B and C together become the training set, and A becomes the testing set. The training, predicting, and evaluation process happens one final time.\n",
    "- Because the evaluation process occurred 3 times, it returns 3 scores, and we will usually take the mean of those scores.\n",
    "\n",
    "Let's go ahead and use cross-validation to evaluate our model:\n",
    "\n",
    "- First we import the cross_val_score function from the model_selection module.\n",
    "- Then we pass it the model object, X and y, the number of cross-validation folds, and the evaluation metric. Although the default metric for classification problems is accuracy, I recommend specifying it explicitly so that there's no ambiguity.\n",
    "- When we run cross_val_score, it does the dataset splitting, training, predicting, and evaluation. 3 accuracy scores are returned, and the mean of those scores is 69%.\n",
    "\n",
    "If you received a different result, that's not a problem. The results can vary based on your scikit-learn version due to changes in the default parameters, algorithm changes, bug fixes, and so on.\n",
    "\n",
    "Unfortunately, we can't take these results seriously because the dataset is so small. There's actually no reliable evaluation procedure when your training data only contains 10 rows, but I did want to demonstrate it anyway to emphasize that model evaluation is a normal part of the Machine Learning workflow.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirements for model evaluation:**\n",
    "\n",
    "- **Procedure:** K-fold cross-validation\n",
    "- **Metric:** Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps of 3-fold cross-validation:**\n",
    "\n",
    "1. Split rows into 3 subsets (A, B, C)\n",
    "2. A & B is training set, C is testing set\n",
    "  - Train model on training set\n",
    "  - Make predictions on testing set\n",
    "  - Evaluate predictions\n",
    "3. Repeat with A & C as training set, B as testing set\n",
    "4. Repeat with B & C as training set, A as testing set\n",
    "5. Calculate the mean of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:58:30.876597700Z",
     "start_time": "2023-09-17T05:58:30.590569500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.6944444444444443"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv=3, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Using the model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "At this point in the workflow, we would typically try making changes in order to achieve a better accuracy, such as:\n",
    "\n",
    "- Tuning the the model's hyperparameters\n",
    "- Adding or removing features\n",
    "- Or trying a different classification model other than logistic regression.\n",
    "\n",
    "We'll cover these topics in detail later in the course, but for now, let's assume that we're happy with the model as-is. Thus, our next steps are to train the model and then use it to make predictions on new data.\n",
    "\n",
    "We use the model's fit method, which instructs the model to try to learn the relationship between X and y.\n",
    "\n",
    "There are four important points I want to note here:\n",
    "\n",
    "- First, you should train your model on the entire dataset before using it to make predictions, otherwise you are throwing away valuable training data. In truth, we do have more than 10 rows, but for now we are considering our entire training dataset to be these 10 rows.\n",
    "- Second, the model object is modified in-place when you run the fit method, and so there's no need to overwrite the logreg object using an assignment statement.\n",
    "- Third, scikit-learn understands how to work with pandas objects, and so we can pass X and y directly to the fit method.\n",
    "- And finally, if you're using scikit-learn 0.23 or later, you will only see the parameters that have changed from the defaults when you print or fit a model. That's why it only displays the random_state and solver parameters, whereas in previous versions of scikit-learn, all model parameters would have been displayed.\n",
    "\n",
    "Now, let's read in a new dataset for which we don't know the target values. You can read it from a URL or from your local computer, so choose whichever option you prefer. Again, we are only going to keep the first 10 rows.\n",
    "\n",
    "You'll notice that it has the same columns as the df DataFrame, except that there's no Survived column, which is the column that we're going to predict.\n",
    "\n",
    "Before we make predictions, we have to define X_new. It has to have the same columns as X, and those columns have to be in the same order.\n",
    "\n",
    "Finally, we'll use the trained model to make predictions by passing X_new to the predict method, which outputs a NumPy array. There are 10 predictions because it makes 1 prediction for each sample in X_new.\n",
    "\n",
    "The predictions are in the same order as the samples in X_new, meaning the first prediction is for the first row in X_new, the second prediction is for the second row in X_new, and so on.\n",
    "\n",
    "Note that we can't actually evaluate the accuracy of these predictions because we don't know the true target values for the samples in X_new.|"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ways to improve the model:**\n",
    "\n",
    "- Hyperparameter tuning\n",
    "- Adding or removing features\n",
    "- Trying a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T06:18:29.121727400Z",
     "start_time": "2023-09-17T06:18:28.833522600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(random_state=1, solver='liblinear')"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important points about model fitting:**\n",
    "\n",
    "- Train your model on the entire dataset before making predictions\n",
    "- Assignment statement is unnecessary\n",
    "- Passing pandas objects is fine\n",
    "- Only prints parameters that have changed (version 0.23 or later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T06:19:43.632862500Z",
     "start_time": "2023-09-17T06:19:42.497704700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Pclass                                          Name     Sex   Age  SibSp  \\\n0       3                              Kelly, Mr. James    male  34.5      0   \n1       3              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n2       2                     Myles, Mr. Thomas Francis    male  62.0      0   \n3       3                              Wirz, Mr. Albert    male  27.0      0   \n4       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1   \n5       3                    Svensson, Mr. Johan Cervin    male  14.0      0   \n6       3                          Connolly, Miss. Kate  female  30.0      0   \n7       2                  Caldwell, Mr. Albert Francis    male  26.0      1   \n8       3     Abrahim, Mrs. Joseph (Sophie Halaut Easu)  female  18.0      0   \n9       3                       Davies, Mr. John Samuel    male  21.0      2   \n\n   Parch     Ticket     Fare  Cabin Embarked  \n0      0     330911   7.8292    NaN        Q  \n1      0     363272   7.0000    NaN        S  \n2      0     240276   9.6875    NaN        Q  \n3      0     315154   8.6625    NaN        S  \n4      1    3101298  12.2875    NaN        S  \n5      0       7538   9.2250    NaN        S  \n6      0     330972   7.6292    NaN        Q  \n7      1     248738  29.0000    NaN        S  \n8      0       2657   7.2292    NaN        C  \n9      0  A/4 48871  24.1500    NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>Svensson, Mr. Johan Cervin</td>\n      <td>male</td>\n      <td>14.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7538</td>\n      <td>9.2250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3</td>\n      <td>Connolly, Miss. Kate</td>\n      <td>female</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330972</td>\n      <td>7.6292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>Caldwell, Mr. Albert Francis</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>248738</td>\n      <td>29.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>Abrahim, Mrs. Joseph (Sophie Halaut Easu)</td>\n      <td>female</td>\n      <td>18.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2657</td>\n      <td>7.2292</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>Davies, Mr. John Samuel</td>\n      <td>male</td>\n      <td>21.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>A/4 48871</td>\n      <td>24.1500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/MLnewdata', nrows=10)\n",
    "df_new = pd.read_csv('titanic_new.csv', nrows=10)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T06:19:48.172203700Z",
     "start_time": "2023-09-17T06:19:47.926477200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Parch     Fare\n0      0   7.8292\n1      0   7.0000\n2      0   9.6875\n3      0   8.6625\n4      1  12.2875\n5      0   9.2250\n6      0   7.6292\n7      1  29.0000\n8      0   7.2292\n9      0  24.1500",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>7.8292</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>7.0000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>9.6875</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>8.6625</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>12.2875</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>9.2250</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>7.6292</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>29.0000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>7.2292</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>24.1500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = df_new[['Parch', 'Fare']]\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T06:19:50.201762300Z",
     "start_time": "2023-09-17T06:19:49.930424200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 1, 0, 0, 1, 0, 1], dtype=int64)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Q&A: How do I adapt this workflow to a regression problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adapting this workflow for regression:**\n",
    "\n",
    "1. Choose a different model\n",
    "2. Choose a different evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Q&A: How do I adapt this workflow to a multiclass problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of classification problems:**\n",
    "\n",
    "- **Binary:** Two output classes\n",
    "- **Multiclass:** More than two output classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How classifiers handle multiclass problems:**\n",
    "\n",
    "- Many are inherently multiclass\n",
    "- Others can be extended using \"one-vs-one\" or \"one-vs-rest\" strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Q&A: Why should I select a Series for the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T08:34:40.116076200Z",
     "start_time": "2023-09-17T08:34:39.910520600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    0\n1    1\n2    1\n3    1\n4    0\n5    0\n6    0\n7    0\n8    1\n9    1\nName: Survived, dtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T08:34:47.222898800Z",
     "start_time": "2023-09-17T08:34:46.848829800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Survived\n0         0\n1         1\n2         1\n3         1\n4         0\n5         0\n6         0\n7         0\n8         1\n9         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T08:35:00.484824500Z",
     "start_time": "2023-09-17T08:35:00.280859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(10,)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T08:35:02.535344800Z",
     "start_time": "2023-09-17T08:35:02.208754600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(10, 1)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Survived']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-09-17T08:35:07.638906300Z",
     "start_time": "2023-09-17T08:35:07.381524100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1], dtype=int64)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T08:35:11.189746800Z",
     "start_time": "2023-09-17T08:35:10.641236500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1]], dtype=int64)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Survived']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multilabel vs multiclass problems:**\n",
    "\n",
    "- **Multilabel:** Each sample can have more than one label\n",
    "- **Multiclass:** Each sample can have one label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multilabel vs multiclass targets:**\n",
    "\n",
    "- **Multilabel:** 2-dimensional y (DataFrame)\n",
    "- **Multiclass:** 1-dimensional y (Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Q&A: How do I add the model's predictions to a DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series(logreg.predict(X_new), index=X_new.index,\n",
    "                        name='Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_new, predictions], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Q&A: How do I determine the confidence level of each prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Array of predicted probabilities:**\n",
    "\n",
    "- One row for each sample\n",
    "- One column for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict_proba(X_new)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Q&A: How do I check the accuracy of the model's predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking model accuracy:**\n",
    "\n",
    "- **Not possible:** Target value is unknown or is private data\n",
    "- **Possible:** Target value is known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10 Q&A: What do the \"solver\" and \"random_state\" parameters do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataschool.io/files/solver_comparison.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default solver for logistic regression:**\n",
    "\n",
    "- **Before version 0.22:** liblinear\n",
    "- **Starting in version 0.22:** lbfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice for random_state:**\n",
    "\n",
    "- Set random_state to any integer when a random process is involved\n",
    "- Allows your code to be reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11 Q&A: How do I show all of the model parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(print_changed_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(print_changed_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12 Q&A: Should I shuffle the samples when using cross-validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(logreg, X, y, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(3)\n",
    "cross_val_score(logreg, X, y, cv=kf, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stratified sampling:**\n",
    "\n",
    "- Ensures that each fold is representative of the dataset\n",
    "- Produces more reliable cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(3, shuffle=True, random_state=1)\n",
    "cross_val_score(logreg, X, y, cv=kf, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to shuffle your samples:**\n",
    "\n",
    "- **Samples in arbitrary order:** Shuffling not needed\n",
    "- **Samples are ordered:** Shuffling needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to shuffle your samples:**\n",
    "\n",
    "- **Classification:** StratifiedKFold\n",
    "- **Regression:** KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Encoding categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Introduction to one-hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to run the code above:**\n",
    "\n",
    "- **Jupyter Notebook:**\n",
    "  - Select this cell\n",
    "  - Click \"Cell\" menu, then \"Run All Above\"\n",
    "- **JupyterLab:**\n",
    "  - Select this cell\n",
    "  - Click \"Run\" menu, then \"Run All Above Selected Cell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Currently selected features:**\n",
    "\n",
    "- **Parch:** Number of parents or children aboard with that passenger\n",
    "- **Fare:** Amount the passenger paid\n",
    "- **Embarked:** Port the passenger embarked from\n",
    "- **Sex:** Male or Female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unordered categorical data:**\n",
    "\n",
    "- Contains distinct categories\n",
    "- No inherent logical ordering to the categories\n",
    "- Also called \"nominal data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix representations:**\n",
    "\n",
    "- **Sparse:** More efficient and performant\n",
    "- **Dense:** More readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use double brackets?**\n",
    "\n",
    "- **Single brackets:**\n",
    "  - Outputs a Series\n",
    "  - Could be interpreted as a single feature or a single sample\n",
    "- **Double brackets:**\n",
    "  - Outputs a single-column DataFrame\n",
    "  - Interpreted as a single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(df[['Embarked']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output of OneHotEncoder:**\n",
    "\n",
    "- One column for each unique value\n",
    "- One non-zero value in each row:\n",
    "  - 1, 0, 0 means \"C\"\n",
    "  - 0, 1, 0 means \"Q\"\n",
    "  - 0, 0, 1 means \"S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use one-hot encoding?**\n",
    "\n",
    "- Model can learn the relationship between each level and the target value\n",
    "- Example: Model might learn that \"C\" passengers have a higher survival rate than \"not C\" passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why not encode as a single feature?**\n",
    "\n",
    "- **Pretend:**\n",
    "  - C: high survival rate\n",
    "  - Q: low survival rate\n",
    "  - S: high survival rate\n",
    "- **Single feature would need two coefficients:**\n",
    "  - Negative coefficient for impact of Q (with respect to C)\n",
    "  - Positive coefficient for impact of S (with respect to Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Transformer methods: fit, transform, fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generic transformer methods:**\n",
    "\n",
    "- **fit:** Transformer learns something\n",
    "- **transform:** Transformer uses what it learned to do the data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneHotEncoder methods:**\n",
    "\n",
    "- **fit:** Learn the categories\n",
    "- **transform:** Create the feature matrix using those categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 One-hot encoding of multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(df[['Embarked', 'Sex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding the output array:**\n",
    "\n",
    "- **First three columns:**\n",
    "  - 1, 0, 0 means \"C\"\n",
    "  - 0, 1, 0 means \"Q\"\n",
    "  - 0, 0, 1 means \"S\"\n",
    "- **Last two columns:**\n",
    "  - 1, 0 means \"female\"\n",
    "  - 0, 1 means \"male\"\n",
    "- **Example:**\n",
    "  - 0, 0, 1, 0, 1 means \"S, male\"\n",
    "  - 1, 0, 0, 1, 0 means \"C, female\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to manually add Embarked and Sex to the model:**\n",
    "\n",
    "1. Stack Parch and Fare side-by-side with OneHotEncoder output\n",
    "2. Repeat the same process with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems with a manual approach:**\n",
    "\n",
    "- Repeating steps is inefficient and error-prone\n",
    "- Complexity will increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Q&A: When should I use transform instead of fit_transform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_train = pd.DataFrame({'letter':['A', 'B', 'C', 'B']})\n",
    "demo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of fit_transform on training data:**\n",
    "\n",
    "- **fit:** Learn 3 categories (A, B, C)\n",
    "- **transform:** Create feature matrix with 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_test = pd.DataFrame({'letter':['A', 'C', 'A']})\n",
    "demo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of fit_transform on testing data:**\n",
    "\n",
    "- **fit:** Learn 2 categories (A, C)\n",
    "- **transform:** Create feature matrix with 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(demo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correct process:**\n",
    "\n",
    "1. Run fit_transform on training data:\n",
    "  - **fit:** Learn 3 categories (A, B, C)\n",
    "  - **transform:** Create feature matrix with 3 columns\n",
    "2. Run transform on testing data:\n",
    "  - **transform:** Create feature matrix with 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Q&A: What happens if the testing data includes a new category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_test_unknown = pd.DataFrame({'letter':['A', 'C', 'D']})\n",
    "demo_test_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(demo_test_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, categories=[['A', 'B', 'C', 'D']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(demo_test_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why you might not know all possible categories:**\n",
    "\n",
    "- Rare categories aren't present in your set of samples\n",
    "- New categories are added later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(demo_test_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice for OneHotEncoder:**\n",
    "\n",
    "1. Start with handle_unknown set to 'error'\n",
    "2. If possible, specify the categories manually\n",
    "3. If necessary, set handle_unknown to 'ignore' and then retrain your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Q&A: Should I drop one of the one-hot encoded categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can drop the first column:**\n",
    "\n",
    "- Contains redundant information\n",
    "- Avoids collinearity between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding the output array (after dropping the first column):**\n",
    "\n",
    "- 0, 0 means \"A\"\n",
    "- 1, 0 means \"B\"\n",
    "- 0, 1 means \"C\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Should you drop the first column?**\n",
    "\n",
    "- **Advantages:**\n",
    "  - Useful if perfectly collinear features will cause problems (does not apply to most models)\n",
    "- **Disadvantages:**\n",
    "  - Incompatible with handle_unknown='ignore'\n",
    "  - Introduces bias if you standardize features or use a regularized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Q&A: How do I encode an ordinal feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of categorical data:**\n",
    "\n",
    "- Unordered (nominal data)\n",
    "- Ordered (ordinal data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options for encoding Pclass:**\n",
    "\n",
    "- **Ordinal encoding:** Creates one feature\n",
    "- **One-hot encoding:** Creates three features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordinal = pd.DataFrame({'Class': ['third', 'first', 'second', 'third'],\n",
    "                           'Size': ['S', 'S', 'L', 'XL']})\n",
    "df_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder(categories=[['first', 'second', 'third'],\n",
    "                                ['S', 'M', 'L', 'XL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe.fit_transform(df_ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding the output array:**\n",
    "\n",
    "- **First column:**\n",
    "  - 0 means \"first\"\n",
    "  - 1 means \"second\"\n",
    "  - 2 means \"third\"\n",
    "- **Second column:**\n",
    "  - 0 means \"S\"\n",
    "  - 1 means \"M\"\n",
    "  - 2 means \"L\"\n",
    "  - 3 means \"XL\"\n",
    "- **Example:**\n",
    "  - 2, 0 means \"third, S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, categories=[['first', 'second', 'third'],\n",
    "                                              ['S', 'M', 'L', 'XL']])\n",
    "ohe.fit_transform(df_ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice for encoding categorical data:**\n",
    "\n",
    "- **Ordinal feature stored as numbers:** Leave as-is\n",
    "- **Ordinal feature stored as strings:** Use OrdinalEncoder\n",
    "- **Nominal feature:** Use OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Q&A: What's the difference between OrdinalEncoder and LabelEncoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; | OrdinalEncoder | LabelEncoder\n",
    ":--- | :---: | :---:\n",
    "Can you define the category order? | Yes | No\n",
    "Can you encode multiple features? | Yes | No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outdated uses for LabelEncoder:**\n",
    "\n",
    "- Encoding string-based labels for some classifiers\n",
    "- Encoding string-based features for OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Q&A: Should I encode numeric features as ordinal features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = KBinsDiscretizer(n_bins=3, strategy='quantile', encode='ordinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.fit_transform(df[['Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why not discretize numeric features?**\n",
    "\n",
    "- Makes it harder to learn the actual trends\n",
    "- Makes it easier to discover non-existent trends\n",
    "- May result in overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Improving your workflow with ColumnTransformer and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Preprocessing features with ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems from Chapter 3:**\n",
    "\n",
    "- Need to stack categorical features next to numerical features\n",
    "- Need to apply the same preprocessing to new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to solve those problems:**\n",
    "\n",
    "- **ColumnTransformer:** Apply different preprocessing steps to different columns\n",
    "- **Pipeline:** Apply the same workflow to training data and new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df[cols]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuple elements for make_column_transformer:**\n",
    "\n",
    "1. Transformer object\n",
    "2. List of columns to which the transformer should be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output columns:**\n",
    "\n",
    "- **Columns 1-3:** Embarked\n",
    "- **Columns 4-5:** Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output columns:**\n",
    "\n",
    "- **Columns 1-3:** Embarked\n",
    "- **Columns 4-5:** Sex\n",
    "- **Column 6:** Parch\n",
    "- **Column 7:** Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes about get_feature_names:**\n",
    "\n",
    "- **Before version 0.23:** Didn't work with passthrough columns\n",
    "- **Starting in version 1.0:** Has been replaced with get_feature_names_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuple elements for make_column_transformer (revised):**\n",
    "\n",
    "1. Transformer object or \"drop\" or \"passthrough\"\n",
    "2. List of columns to which the transformer should be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('passthrough', ['Parch', 'Fare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Chaining steps with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(ct, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline steps:**\n",
    "\n",
    "1. Data preprocessing with ColumnTransformer\n",
    "2. Model building with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the Pipeline:**\n",
    "\n",
    "1. ColumnTransformer converts X (4 columns) into a numeric feature matrix (7 columns)\n",
    "2. LogisticRegression model is fit to the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = ct.fit_transform(X)\n",
    "logreg.fit(X_t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Using the Pipeline to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new = df_new[cols]\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting with the Pipeline:**\n",
    "\n",
    "1. ColumnTransformer applies the same transformations to X_new\n",
    "2. Fitted LogisticRegression model makes predictions on the transformed version of X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_t = ct.transform(X_new)\n",
    "logreg.predict(X_new_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_new.shape)\n",
    "print(X_new_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ColumnTransformer methods:**\n",
    "\n",
    "1. Run fit_transform on X:\n",
    "  - **fit:** Learn the encoding\n",
    "  - **transform:** Apply the encoding to create 7 columns\n",
    "2. Run transform on X_new:\n",
    "  - **transform:** Apply the encoding to create 7 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Q&A: How do I drop some columns and passthrough others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('drop', ['Fare']),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('passthrough', ['Parch']),\n",
    "    remainder='drop')\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Q&A: How do I transform the unspecified columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('drop', ['Fare']),\n",
    "    remainder=scaler)\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Q&A: How do I select columns from a NumPy array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = X.to_numpy()\n",
    "X_new_array = X_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, [2, 3]),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, slice(2, 4)),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, [False, False, True, True]),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options for selecting columns from a NumPy array:**\n",
    "\n",
    "- Integer position\n",
    "- Slice\n",
    "- Boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_array, y)\n",
    "pipe.predict(X_new_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Q&A: How do I select columns by data type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_object = make_column_selector(dtype_include=object)\n",
    "select_number = make_column_selector(dtype_include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, select_object),\n",
    "    ('passthrough', select_number))\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_object = make_column_selector(dtype_exclude=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, select_object),\n",
    "    ('passthrough', exclude_object))\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_datetime = make_column_selector(dtype_include='datetime')\n",
    "select_category = make_column_selector(dtype_include='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_multiple = make_column_selector(dtype_include=[object, 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Q&A: How do I select columns by column name pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_ES = make_column_selector(pattern='E|S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, select_ES),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Q&A: Should I use ColumnTransformer or make_column_transformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer(\n",
    "    [('OHE', ohe, ['Embarked', 'Sex']),\n",
    "     ('pass', 'passthrough', ['Parch', 'Fare'])])\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuple elements for ColumnTransformer:**\n",
    "\n",
    "1. Transformer name\n",
    "2. Transformer object or \"drop\" or \"passthrough\"\n",
    "3. List of columns to which the transformer should be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('passthrough', ['Parch', 'Fare']))\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; | ColumnTransformer | make_column_transformer\n",
    ":--- | :---: | :---:\n",
    "Allows custom names? | Yes | No\n",
    "Allows transformer weights? | Yes | No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10 Q&A: Should I use Pipeline or make_pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('preprocessor', ct), ('classifier', logreg)])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuple elements for Pipeline:**\n",
    "\n",
    "1. Step name\n",
    "2. Model or transformer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; | Pipeline | make_pipeline\n",
    ":--- | :---: | :---:\n",
    "Allows custom names? | Yes | No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11 Q&A: How do I examine the steps of a Pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['columntransformer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['logisticregression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['columntransformer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['logisticregression'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps.logisticregression.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe['logisticregression'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe[1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Workflow review #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Recap of our workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://bit.ly/MLtrain', nrows=10)\n",
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/MLnewdata', nrows=10)\n",
    "X_new = df_new[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('passthrough', ['Parch', 'Fare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Comparing ColumnTransformer and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataschool.io/files/simple_pipeline.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ColumnTransformer vs Pipeline:**\n",
    "\n",
    "- **ColumnTransformer:**\n",
    "  - Selects subsets of columns, transforms them independently, stacks the results side-by-side\n",
    "  - Only includes transformers\n",
    "  - Does not have steps (transformers operate in parallel)\n",
    "- **Pipeline:**\n",
    "  - Series of steps that occur in order\n",
    "  - Output of each step becomes the input to the next step\n",
    "  - Last step is a model or transformer, all other steps are transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Creating a Pipeline diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display='text')\n",
    "pipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
