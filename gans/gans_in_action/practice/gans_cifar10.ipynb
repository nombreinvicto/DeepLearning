{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, \\\n",
    "    BatchNormalization, LeakyReLU, ReLU, Flatten, Dropout, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(32, 32, 3)):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    #Conv2D-1\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3, 3),\n",
    "                     padding='same',\n",
    "                     input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    #Conv2D-2\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3,3),\n",
    "                     strides=(2,2),\n",
    "                     padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    #Conv2D-3\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3,3),\n",
    "                     strides=(2,2),\n",
    "                     padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    #Conv2D-4\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     strides=(2,2),\n",
    "                     padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 522,497\n",
      "Trainable params: 522,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# visualise the discriminator\n",
    "d_model = define_discriminator()\n",
    "d_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "\n",
    "    # load cifar10\n",
    "    (trainx, trainy), (testx, testy) = cifar10.load_data()\n",
    "    X = trainx.astype('float32')\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset:np.ndarray, n_samples):\n",
    "\n",
    "    # choose random instances\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    x = dataset[ix]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    # foundation for 4x4 image\n",
    "    n_nodes = 256*4*4\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((4, 4, 256)))\n",
    "\n",
    "    # upsample to 8x8\n",
    "    model.add(Conv2DTranspose(filters=128,\n",
    "                              kernel_size=(4, 4),\n",
    "                              strides=(2, 2),\n",
    "                              padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # upsample to 16x16\n",
    "    model.add(Conv2DTranspose(filters=128,\n",
    "                              kernel_size=(4, 4),\n",
    "                              strides=(2, 2),\n",
    "                              padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # upsample 32x32\n",
    "    model.add(Conv2DTranspose(filters=128,\n",
    "                              kernel_size=(4,4),\n",
    "                              strides=(2,2),\n",
    "                              padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Conv2D(filters=3,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='tanh',\n",
    "                     padding='same'))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 4096)              413696    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 8, 8, 128)         524416    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 32, 32, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 32, 32, 3)         3459      \n",
      "=================================================================\n",
      "Total params: 1,466,115\n",
      "Trainable params: 1,466,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g_model = define_generator(latent_dim=100)\n",
    "g_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# genrate points in the latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "\n",
    "    return x_input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model:Model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    x = g_model.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def define_gan(g_model:Model, d_model:Model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_12 (Sequential)   (None, 32, 32, 3)         1466115   \n",
      "_________________________________________________________________\n",
      "sequential_11 (Sequential)   (None, 1)                 522497    \n",
      "=================================================================\n",
      "Total params: 1,988,612\n",
      "Trainable params: 1,466,115\n",
      "Non-trainable params: 522,497\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "gan_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n=10):\n",
    "    # plot images\n",
    "    for i in range(n*n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1+i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "\n",
    "    # save plot to file\n",
    "    filename = f\"generated_plot_epoch{epoch+1}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def summarise_performance(epoch,\n",
    "                          g_model:Model,\n",
    "                          d_model:Model,\n",
    "                          dataset:np.ndarray,\n",
    "                          latent_dim,\n",
    "                          n_samples=150):\n",
    "    # get real samples\n",
    "    xreal, yreal = generate_real_samples(dataset, n_samples)\n",
    "\n",
    "    # evaluate discriminator on real samples\n",
    "    loss_real, acc_real = d_model.evaluate(xreal, yreal, verbose=0)\n",
    "\n",
    "    # prepare fake samples\n",
    "    xfake, yfake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "\n",
    "    # eval discrimiantor on fake samples\n",
    "    loss_fake, acc_fake = d_model.evaluate(xfake, yfake, verbose=0)\n",
    "\n",
    "    # summarise discrimiantor performance\n",
    "    print(f\"Epoch={epoch+1} Discriminator Accuracy  \"\n",
    "          f\"Real={acc_real*100} and \"\n",
    "          f\"Fake={acc_fake*100}\")\n",
    "\n",
    "    # save the plot\n",
    "    save_plot(xfake, epoch)\n",
    "\n",
    "    # save the generaor model to file\n",
    "    g_model.save(f\"generator_model_epoch{epoch+1}.hdf5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the generator and the discriminator\n",
    "def train(g_model:Model,\n",
    "          d_model:Model,\n",
    "          gan_model:Model,\n",
    "          dataset:np.ndarray,\n",
    "          latent_dim: int,\n",
    "          n_epochs=200,\n",
    "          n_batch=128):\n",
    "\n",
    "    # evaluate batch per epoch\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\n",
    "    # calculate half-batch\n",
    "    half_batch = int(n_batch / 2)\n",
    "\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "\n",
    "        # enumerate bacthes over the trainign set\n",
    "        for j in range(bat_per_epo):\n",
    "            # get randomly selected real samples\n",
    "            xreal, yreal = generate_real_samples(dataset, half_batch)\n",
    "\n",
    "            # get fake examples\n",
    "            xfake, yfake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\n",
    "            # update the discrinator on real images\n",
    "            d_loss1, d_acc1 = d_model.train_on_batch(xreal, yreal)\n",
    "\n",
    "            # update discriminator model weights\n",
    "            d_loss2, d_acc2 = d_model.train_on_batch(xfake, yfake)\n",
    "\n",
    "            # prepare points in the latent space as inputs for the generator\n",
    "            xgan = generate_latent_points(latent_dim, n_batch)\n",
    "\n",
    "            # create inverted labels for the fake samples\n",
    "            ygan = np.ones((n_batch, 1))\n",
    "\n",
    "            # update the generator via the discriminators error\n",
    "            g_loss = gan_model.train_on_batch(xgan, ygan)\n",
    "\n",
    "            # summarise the loss in this batch\n",
    "            print(f\"Train Epoch: {i+1}, {j+1}/{bat_per_epo} d1={d_loss1}, \"\n",
    "                  f\"d2={d_loss2} g={g_loss}\")\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            summarise_performance(i, g_model, d_model, dataset, latent_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "dataset = load_real_samples()\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}