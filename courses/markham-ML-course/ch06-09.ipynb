{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course: [Master Machine Learning with scikit-learn](https://courses.dataschool.io/view/courses/master-machine-learning-with-scikit-learn)\n",
    "\n",
    "## Chapters 6-9\n",
    "\n",
    "*Â© 2024 Data School. All rights reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Encoding text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Vectorizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://bit.ly/MLtrain', nrows=10)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/MLnewdata', nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ideas for encoding the Name column:**\n",
    "\n",
    "- **OneHotEncoder:** Each full name is treated as a category (not recommended)\n",
    "- **CountVectorizer:** Each word in a name is treated independently (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.fit_transform(df['Name'])\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVectorizer vs other transformers:**\n",
    "\n",
    "- **CountVectorizer:** 1-dimensional input (Series)\n",
    "- **Other transformers:** 2-dimensional input (DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default settings for CountVectorizer:**\n",
    "\n",
    "- Convert all words to lowercase\n",
    "- Remove all punctuation\n",
    "- Exclude one-character words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About the document-term matrix:**\n",
    "\n",
    "- 10 rows and 40 columns\n",
    "- Rows represent rows from training data, columns represent words\n",
    "- Rows are \"documents\", feature names are \"terms\"\n",
    "- Sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to examine a document-term matrix:**\n",
    "\n",
    "1. Use toarray method to make it dense\n",
    "2. Convert dense matrix into a DataFrame\n",
    "3. Use feature names as column headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Bag of Words\" representation:**\n",
    "\n",
    "- Ignores word order\n",
    "- Only counts how many times a word appears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Including text data in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name']\n",
    "X = df[cols]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    ('passthrough', ['Parch', 'Fare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.get_feature_names() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output columns:**\n",
    "\n",
    "- **Columns 1-3:** Embarked\n",
    "- **Columns 4-5:** Sex\n",
    "- **Columns 6-45:** Name\n",
    "- **Column 46:** Parch\n",
    "- **Column 47:** Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_new[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Q&A: Why is the document-term matrix stored as a sparse matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['Machine Learning is fun', 'I am learning Machine Learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vect.fit_transform(text).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.fit_transform(text)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preferred matrix representation:**\n",
    "\n",
    "- **Most elements are zero:** Sparse matrix\n",
    "- **Most elements are non-zero:** Dense matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Q&A: What happens if the testing data includes new words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.fit_transform(text)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_new = ['Data Science is FUN!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.transform(text_new).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVectorizer methods:**\n",
    "\n",
    "- **fit:** Learn the vocabulary\n",
    "- **transform:** Create the document-term matrix using that vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Q&A: How do I vectorize multiple columns of text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Name', 'Ticket']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit_transform(df['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit_transform(df['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit_transform(df[['Name', 'Ticket']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (vect, 'Name'),\n",
    "    (vect, 'Ticket'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.named_transformers_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Q&A: Should I one-hot encode or vectorize categorical features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Embarked', 'Sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit_transform(df['Sex']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit_transform(df[['Embarked', 'Sex']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit_transform(df['Embarked']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of OneHotEncoder for categorical data:**\n",
    "\n",
    "- Encodes multiple columns at once\n",
    "- Allows one-character category names\n",
    "- Gives more options for handling unknown categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Introduction to missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common sources of missing values:**\n",
    "\n",
    "- Value purposefully wasn't collected\n",
    "- Error in the data collection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values vs unknown categories:**\n",
    "\n",
    "- **Missing value:** Value encoded as \"NaN\"\n",
    "- **Unknown category:** Category not seen in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name', 'Age']\n",
    "X = df[cols]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    ('passthrough', ['Parch', 'Fare', 'Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Three ways to handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 1: Drop rows with missing values**\n",
    "\n",
    "- May discard too much training data\n",
    "- May obscure a pattern in the \"missingness\"\n",
    "- Doesn't help you with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 2: Drop columns with missing values**\n",
    "\n",
    "- May discard useful features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 3: Impute missing values**\n",
    "\n",
    "- **Benefit:** Keeps more samples and features\n",
    "- **Cost:** Imputed values may not match the true values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Factors to consider before imputing:**\n",
    "\n",
    "- How important are the samples?\n",
    "- How important are the features?\n",
    "- What percentage of values would need to be imputed?\n",
    "- Are there other samples or features that contain the same information?\n",
    "- Is the missingness random?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.fit_transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple imputation strategies:**\n",
    "\n",
    "- Mean value\n",
    "- Median value\n",
    "- Most frequent value\n",
    "- User-defined value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age']),\n",
    "    ('passthrough', ['Parch', 'Fare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pipe.named_steps['columntransformer']\n",
    "     .named_transformers_['simpleimputer']\n",
    "     .statistics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_new[cols]\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would have been imputed for Age in X_new?**\n",
    "\n",
    "- Imputed value would be the mean of Age in **X**, not the mean of Age in **X_new**\n",
    "- Transformer is only allowed to learn from the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do transformers learn from the training data?**\n",
    "\n",
    "- **OneHotEncoder:** Learns categories\n",
    "- **CountVectorizer:** Learns vocabulary\n",
    "- **SimpleImputer:** Learns imputation value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Using \"missingness\" as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_indicator = SimpleImputer(add_indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_indicator.fit_transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why add a missing indicator?**\n",
    "\n",
    "- Useful when the data is not missing at random\n",
    "- Can encode the relationship between \"missingness\" and the target value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Q&A: How do I perform multivariate imputation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of imputation:**\n",
    "\n",
    "- **Univariate imputation:** Only examines the feature being imputed\n",
    "  - SimpleImputer\n",
    "- **Multivariate imputation:** Takes multiple features into account\n",
    "  - IterativeImputer\n",
    "  - KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_iterative = IterativeImputer()\n",
    "imp_iterative.fit_transform(X[['Parch', 'Fare', 'Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How IterativeImputer works:**\n",
    "\n",
    "1. **Age not missing:** Train a regression model to predict Age using Parch and Fare\n",
    "2. **Age missing:** Predict Age using trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes about IterativeImputer:**\n",
    "\n",
    "- Only works with numerical features\n",
    "- You have to decide which features to include\n",
    "- You can include multiple features with missing values\n",
    "- You can choose the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp_iterative, ['Parch', 'Fare', 'Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imp_knn = KNNImputer(n_neighbors=2)\n",
    "imp_knn.fit_transform(X[['Parch', 'Fare', 'Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How KNNImputer works:**\n",
    "\n",
    "1. Find the row in which **Age is missing**\n",
    "2. Find the n_neighbors \"nearest\" rows in which **Age is not missing**\n",
    "3. Calculate the mean of Age from the \"nearest\" rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Q&A: What are the best practices for missing value imputation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of missing data:**\n",
    "\n",
    "- **Missing Completely At Random (MCAR):**\n",
    "  - No relationship between missingness and underlying data\n",
    "  - Example: Booking agent forgot to gather Age\n",
    "- **Missing Not At Random (MNAR):**\n",
    "  - Relationship between missingness and underlying data\n",
    "  - Example: Older passengers declined to give their Age\n",
    "- **Missing due to a structural deficiency:**\n",
    "  - Data omitted for a specific purpose\n",
    "  - Example: Staff members did not pay a Fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice for MCAR imputation:**\n",
    "\n",
    "- **Small dataset:** IterativeImputer is more effective than mean imputation\n",
    "- **Large dataset:** IterativeImputer and mean imputation work equally well\n",
    "- No benefit to adding a missing indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice for MNAR imputation:**\n",
    "\n",
    "- Mean imputation is more effective than IterativeImputer\n",
    "- Add a missing indicator\n",
    "- Use a powerful, non-linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice for structural deficiency imputation:**\n",
    "\n",
    "- Impute a logical and reasonable user-defined value\n",
    "- Add a missing indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of histogram-based gradient boosting trees:**\n",
    "\n",
    "- Built-in support for missing values\n",
    "- Lower computational cost than IterativeImputer\n",
    "- Performs well across many missing value scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 Q&A: What's the difference between ColumnTransformer and FeatureUnion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_indicator = SimpleImputer(add_indicator=True)\n",
    "imp_indicator.fit_transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.fit_transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "indicator = MissingIndicator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator.fit_transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union\n",
    "union = make_union(imp, indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union.fit_transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp, ['Age']),\n",
    "    (indicator, ['Age']))\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FeatureUnion vs ColumnTransformer:**\n",
    "\n",
    "- **FeatureUnion:**\n",
    "  - Single input column\n",
    "  - Applies multiple different transformations to that column in parallel\n",
    "- **ColumnTransformer:**\n",
    "  - Multiple input columns\n",
    "  - Applies a different transformation to each column in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Fixing common workflow problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Two new problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://bit.ly/MLtrain')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/MLnewdata')\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features with missing values:**\n",
    "\n",
    "- Problematic:\n",
    "  - **Embarked:** Missing values in df\n",
    "  - **Fare:** Missing value in df_new\n",
    "- Not problematic:\n",
    "  - **Cabin:** Not currently using\n",
    "  - **Age:** Already being imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Problem 1: Missing values in a categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age']),\n",
    "    ('passthrough', ['Parch', 'Fare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How OneHotEncoder handles missing values:**\n",
    "\n",
    "- **Before version 0.24:** Errors if the input contains missing values\n",
    "- **Starting in version 0.24:** Treats missing values as a new category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputation strategies for categorical features:**\n",
    "\n",
    "- Most frequent value\n",
    "- User-defined value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_constant = SimpleImputer(strategy='constant', fill_value='missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ohe = make_pipeline(imp_constant, ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ohe.fit_transform(X[['Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ohe[1].categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(imp_constant.fit_transform(X[['Embarked']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age']),\n",
    "    ('passthrough', ['Parch', 'Fare']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes about the imp_ohe Pipeline:**\n",
    "\n",
    "- Treated like a transformer because all of its steps are transformers\n",
    "- Imputation step won't affect the Sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Problem 2: Missing values in the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age', 'Fare']),\n",
    "    ('passthrough', ['Parch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What will be imputed for Fare?**\n",
    "\n",
    "- **X:** No missing Fare values, thus no imputation of Fare\n",
    "- **X_new:** Missing Fare value, thus **impute the mean of Fare in X** during prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new = df_new[cols]\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Q&A: How do I see the feature names output by the ColumnTransformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changes to get_feature_names:**\n",
    "\n",
    "- **Starting in version 1.0:** get_feature_names replaced with get_feature_names_out\n",
    "- **Starting in version 1.1:** get_feature_names_out available for all transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.named_transformers_['pipeline'].named_steps['onehotencoder'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ct.named_transformers_['countvectorizer'].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features output by each transformer:**\n",
    "\n",
    "- **Pipeline:** 6 features (Embarked and Sex)\n",
    "- **CountVectorizer:** 1509 features (Name)\n",
    "- **SimpleImputer:** 2 features (Age and Fare)\n",
    "- **passthrough:** 1 feature (Parch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Q&A: Why did we create a Pipeline inside of the ColumnTransformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ohe = make_pipeline(imp_constant, ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked']),\n",
    "    (ohe, ['Sex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_constant, ['Embarked']),\n",
    "    (ohe, ['Embarked', 'Sex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline vs ColumnTransformer:**\n",
    "\n",
    "- **Pipeline:**\n",
    "  - Output of one step becomes the input to the next step\n",
    "  - **imp_ohe:** Output of **imp_constant** becomes the input to **ohe**\n",
    "- **ColumnTransformer:**\n",
    "  - Transformers operate in parallel\n",
    "  - **ct:** Output of each transformer is stacked beside the other transformer outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Q&A: Which imputation strategy should I use with categorical features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputation strategies for categorical features:**\n",
    "\n",
    "- **Constant user-defined value:**\n",
    "  - Treats missing values as a new category (recommended)\n",
    "  - Important if the majority of values are missing\n",
    "- **Most frequent value:**\n",
    "  - Acceptable if only a small number of values are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible problem with imputing a constant value:**\n",
    "\n",
    "- **Condition:** The feature only has missing values in the new data\n",
    "- **Solution:** Set handle_unknown to 'ignore' for the OneHotEncoder\n",
    "- **Alternative:** Impute the most frequent value, and leave handle_unknown set to 'error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Q&A: Should I impute missing values before all other transformations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impute missing values as a first step?**\n",
    "\n",
    "- **Current Pipeline:**\n",
    "  - **Step 1:** All data transformations\n",
    "  - **Step 2:** Model\n",
    "- **Alternative Pipeline:**\n",
    "  - **Step 1:** Missing value imputation\n",
    "  - **Step 2:** All other data transformations\n",
    "  - **Step 3:** Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = make_column_transformer(\n",
    "    (imp_constant, ['Embarked']),\n",
    "    (imp, ['Age', 'Fare']),\n",
    "    ('passthrough', ['Sex', 'Name', 'Parch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct2 = make_column_transformer(\n",
    "    (ohe, [0, 3]),\n",
    "    (vect, 4),\n",
    "    ('passthrough', [1, 2, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct1, ct2, logreg)\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8 Q&A: What methods can I use with a Pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rules for Pipeline steps:**\n",
    "\n",
    "- All steps other than the final step must be a **transformer**\n",
    "- Final step can be a **model** or a **transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline ends in a model:**\n",
    "\n",
    "- **fit:**\n",
    "  - All steps before the final step run **fit_transform**\n",
    "  - Final step runs **fit**\n",
    "- **predict:**\n",
    "  - All steps before the final step run **transform**\n",
    "  - Final step runs **predict**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline ends in a transformer:**\n",
    "\n",
    "- **fit_transform:**\n",
    "  - All steps run **fit_transform**\n",
    "- **transform:**\n",
    "  - All steps run **transform**\n",
    "- **fit:**\n",
    "  - All steps before the final step run **fit_transform**\n",
    "  - Final step runs **fit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Workflow review #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Recap of our workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://bit.ly/MLtrain')\n",
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/MLnewdata')\n",
    "X_new = df_new[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer()\n",
    "imp_constant = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "ohe = OneHotEncoder()\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ohe = make_pipeline(imp_constant, ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age', 'Fare']),\n",
    "    ('passthrough', ['Parch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Comparing ColumnTransformer and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataschool.io/files/complex_pipeline.png\" width=\"625\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ColumnTransformer vs Pipeline:**\n",
    "\n",
    "- **ColumnTransformer:**\n",
    "  - Selects subsets of columns, transforms them independently, stacks the results side-by-side\n",
    "  - Only includes transformers\n",
    "  - Does not have steps (transformers operate in parallel)\n",
    "- **Pipeline:**\n",
    "  - Series of steps that occur in order\n",
    "  - Output of each step becomes the input to the next step\n",
    "  - Last step is a model or transformer, all other steps are transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Why not use pandas for transformations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; | scikit-learn | pandas\n",
    ":--- | :--- | :---\n",
    "**Encoding text data** | CountVectorizer | Not available\n",
    "**One-hot encoding** | OneHotEncoder | get_dummies (results in larger DataFrame)\n",
    "**Imputing missing values** | SimpleImputer & other imputers | fillna (results in data leakage)\n",
    "**Cross-validation and tuning** | Your entire Pipeline | Just your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Preventing data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is data leakage?**\n",
    "\n",
    "- Inadvertently including knowledge from the testing data when training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is data leakage problematic?**\n",
    "\n",
    "- Your model evaluation scores will be less reliable\n",
    "- You might make bad decisions when tuning hyperparameters\n",
    "- You will overestimate how well your model will perform on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputation on the full dataset can cause data leakage:**\n",
    "\n",
    "- Your model evaluation procedure is supposed to simulate the future\n",
    "- Imputation based on your full dataset \"leaks\" information about the future into model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other transformations on the full dataset can also cause data leakage:**\n",
    "\n",
    "- Feature scaling\n",
    "- One-hot encoding\n",
    "- Any transformation which incorporates information about other rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does scikit-learn prevent data leakage?**\n",
    "\n",
    "- Transformers have separate fit and transform steps\n",
    "- Pipeline methods call fit_transform and transform at the appropriate times\n",
    "- cross_val_score splits the data prior to performing transformations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
