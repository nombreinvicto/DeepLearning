{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course: [Master Machine Learning with scikit-learn](https://courses.dataschool.io/view/courses/master-machine-learning-with-scikit-learn)\n",
    "\n",
    "## Chapters 1-5\n",
    "\n",
    "*Â© 2024 Data School. All rights reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Course overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High-level topics:**\n",
    "\n",
    "- Handling missing values, text data, categorical data, and class imbalance\n",
    "- Building a reusable workflow\n",
    "- Feature engineering, selection, and standardization\n",
    "- Avoiding data leakage\n",
    "- Tuning your entire workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How you will benefit from this course:**\n",
    "\n",
    "- Knowledge of best practices\n",
    "- Confidence when tackling new ML problems\n",
    "- Ability to anticipate and solve problems\n",
    "- Improved code quality\n",
    "- Better, faster results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 scikit-learn vs Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benefits of scikit-learn:**\n",
    "\n",
    "- Consistent interface to many models\n",
    "- Many tuning parameters (but sensible defaults)\n",
    "- Workflow-related functionality\n",
    "- Exceptional documentation\n",
    "- Active community support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drawbacks of deep learning:**\n",
    "\n",
    "- More computational resources\n",
    "- Higher learning curve\n",
    "- Less interpretable models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Prerequisite skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scikit-learn prerequisites:**\n",
    "\n",
    "- Loading a dataset\n",
    "- Defining the features and target\n",
    "- Training and evaluating a model\n",
    "- Making predictions with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New to scikit-learn?**\n",
    "\n",
    "- Enroll in \"Introduction to Machine Learning with scikit-learn\" (free)\n",
    "- Available at https://courses.dataschool.io\n",
    "- Complete lessons 1 through 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Course setup and software versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to install scikit-learn and pandas:**\n",
    "\n",
    "- **Option 1:** Install together\n",
    "  - **Anaconda:** https://www.anaconda.com/products/distribution\n",
    "- **Option 2:** Install separately\n",
    "  - **scikit-learn:** https://scikit-learn.org\n",
    "  - **pandas:** https://pandas.pydata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scikit-learn version:**\n",
    "\n",
    "- **Course version:** 0.23.2\n",
    "- **Minimum version:** 0.20.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to install scikit-learn 0.23.2:**\n",
    "\n",
    "- **Option 1:** conda install scikit-learn==0.23.2\n",
    "- **Option 2:** pip install -U scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Google Colab with the course:**\n",
    "\n",
    "- Similar to the Jupyter Notebook\n",
    "- Runs in your browser\n",
    "- Free (but requires a Google account)\n",
    "- Available at https://colab.research.google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Course outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapters:**\n",
    "\n",
    "1. Introduction\n",
    "2. Review of the Machine Learning workflow\n",
    "3. Encoding categorical features\n",
    "4. Improving your workflow with ColumnTransformer and Pipeline\n",
    "5. Workflow review #1\n",
    "6. Encoding text data\n",
    "7. Handling missing values\n",
    "8. Fixing common workflow problems\n",
    "9. Workflow review #2\n",
    "10. Evaluating and tuning a Pipeline\n",
    "11. Comparing linear and non-linear models\n",
    "12. Ensembling multiple models\n",
    "13. Feature selection\n",
    "14. Feature standardization\n",
    "15. Feature engineering with custom transformers\n",
    "16. Workflow review #3\n",
    "17. High-cardinality categorical features\n",
    "18. Class imbalance\n",
    "19. Class imbalance walkthrough\n",
    "20. Going further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lesson types:**\n",
    "\n",
    "- Core lessons\n",
    "- Q&A lessons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why not focus on algorithms?**\n",
    "\n",
    "- Workflow will have a greater impact on your results\n",
    "- Reusable workflow enables you to try many different algorithms\n",
    "- Hard to know (in advance) which algorithm will work best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Course datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets:**\n",
    "\n",
    "- Titanic\n",
    "- US census\n",
    "- Mammography scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use smaller datasets?**\n",
    "\n",
    "- Easier and faster access to files\n",
    "- Reduced computational time\n",
    "- Greater understanding of the course material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Meet your instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About me:**\n",
    "\n",
    "- Founder of Data School\n",
    "- Teaching data science for 7+ years\n",
    "- Passionate about teaching people who are new to data science\n",
    "- Live in Asheville, North Carolina\n",
    "- Degree in Computer Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Review of the Machine Learning workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Loading and exploring a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('http://bit.ly/MLtrain', nrows=10)\n",
    "df = pd.read_csv('titanic_train.csv', nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning terminology:**\n",
    "\n",
    "- **Target:** Goal of prediction\n",
    "- **Classification:** Problem with a categorical target\n",
    "- **Feature:** Input to the model (column)\n",
    "- **Sample:** Single observation (row)\n",
    "- **Training data:** Data with known target values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection methods:**\n",
    "\n",
    "- Human intuition\n",
    "- Domain knowledge\n",
    "- Data exploration\n",
    "- Automated methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Currently selected features:**\n",
    "\n",
    "- **Parch:** Number of parents or children aboard with that passenger\n",
    "- **Fare:** Amount the passenger paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Parch', 'Fare']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Survived']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Building and evaluating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirements for model evaluation:**\n",
    "\n",
    "- **Procedure:** K-fold cross-validation\n",
    "- **Metric:** Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps of 3-fold cross-validation:**\n",
    "\n",
    "1. Split rows into 3 subsets (A, B, C)\n",
    "2. A & B is training set, C is testing set\n",
    "  - Train model on training set\n",
    "  - Make predictions on testing set\n",
    "  - Evaluate predictions\n",
    "3. Repeat with A & C as training set, B as testing set\n",
    "4. Repeat with B & C as training set, A as testing set\n",
    "5. Calculate the mean of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv=3, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Using the model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ways to improve the model:**\n",
    "\n",
    "- Hyperparameter tuning\n",
    "- Adding or removing features\n",
    "- Trying a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important points about model fitting:**\n",
    "\n",
    "- Train your model on the entire dataset before making predictions\n",
    "- Assignment statement is unnecessary\n",
    "- Passing pandas objects is fine\n",
    "- Only prints parameters that have changed (version 0.23 or later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/MLnewdata', nrows=10)\n",
    "df_new = pd.read_csv('titanic_new.csv', nrows=10)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_new[['Parch', 'Fare']]\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logreg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Q&A: How do I adapt this workflow to a regression problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adapting this workflow for regression:**\n",
    "\n",
    "1. Choose a different model\n",
    "2. Choose a different evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Q&A: How do I adapt this workflow to a multiclass problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of classification problems:**\n",
    "\n",
    "- **Binary:** Two output classes\n",
    "- **Multiclass:** More than two output classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How classifiers handle multiclass problems:**\n",
    "\n",
    "- Many are inherently multiclass\n",
    "- Others can be extended using \"one-vs-one\" or \"one-vs-rest\" strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Q&A: Why should I select a Series for the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Survived'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Survived']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Survived'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Survived']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multilabel vs multiclass problems:**\n",
    "\n",
    "- **Multilabel:** Each sample can have more than one label\n",
    "- **Multiclass:** Each sample can have one label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multilabel vs multiclass targets:**\n",
    "\n",
    "- **Multilabel:** 2-dimensional y (DataFrame)\n",
    "- **Multiclass:** 1-dimensional y (Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Q&A: How do I add the model's predictions to a DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series(logreg.predict(X_new), index=X_new.index,\n",
    "                        name='Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_new, predictions], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Q&A: How do I determine the confidence level of each prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Array of predicted probabilities:**\n",
    "\n",
    "- One row for each sample\n",
    "- One column for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict_proba(X_new)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Q&A: How do I check the accuracy of the model's predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking model accuracy:**\n",
    "\n",
    "- **Not possible:** Target value is unknown or is private data\n",
    "- **Possible:** Target value is known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10 Q&A: What do the \"solver\" and \"random_state\" parameters do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataschool.io/files/solver_comparison.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default solver for logistic regression:**\n",
    "\n",
    "- **Before version 0.22:** liblinear\n",
    "- **Starting in version 0.22:** lbfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice for random_state:**\n",
    "\n",
    "- Set random_state to any integer when a random process is involved\n",
    "- Allows your code to be reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11 Q&A: How do I show all of the model parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(print_changed_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(print_changed_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12 Q&A: Should I shuffle the samples when using cross-validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(logreg, X, y, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(3)\n",
    "cross_val_score(logreg, X, y, cv=kf, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stratified sampling:**\n",
    "\n",
    "- Ensures that each fold is representative of the dataset\n",
    "- Produces more reliable cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(3, shuffle=True, random_state=1)\n",
    "cross_val_score(logreg, X, y, cv=kf, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to shuffle your samples:**\n",
    "\n",
    "- **Samples in arbitrary order:** Shuffling not needed\n",
    "- **Samples are ordered:** Shuffling needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to shuffle your samples:**\n",
    "\n",
    "- **Classification:** StratifiedKFold\n",
    "- **Regression:** KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Encoding categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Introduction to one-hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to run the code above:**\n",
    "\n",
    "- **Jupyter Notebook:**\n",
    "  - Select this cell\n",
    "  - Click \"Cell\" menu, then \"Run All Above\"\n",
    "- **JupyterLab:**\n",
    "  - Select this cell\n",
    "  - Click \"Run\" menu, then \"Run All Above Selected Cell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Currently selected features:**\n",
    "\n",
    "- **Parch:** Number of parents or children aboard with that passenger\n",
    "- **Fare:** Amount the passenger paid\n",
    "- **Embarked:** Port the passenger embarked from\n",
    "- **Sex:** Male or Female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unordered categorical data:**\n",
    "\n",
    "- Contains distinct categories\n",
    "- No inherent logical ordering to the categories\n",
    "- Also called \"nominal data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix representations:**\n",
    "\n",
    "- **Sparse:** More efficient and performant\n",
    "- **Dense:** More readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use double brackets?**\n",
    "\n",
    "- **Single brackets:**\n",
    "  - Outputs a Series\n",
    "  - Could be interpreted as a single feature or a single sample\n",
    "- **Double brackets:**\n",
    "  - Outputs a single-column DataFrame\n",
    "  - Interpreted as a single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(df[['Embarked']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output of OneHotEncoder:**\n",
    "\n",
    "- One column for each unique value\n",
    "- One non-zero value in each row:\n",
    "  - 1, 0, 0 means \"C\"\n",
    "  - 0, 1, 0 means \"Q\"\n",
    "  - 0, 0, 1 means \"S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use one-hot encoding?**\n",
    "\n",
    "- Model can learn the relationship between each level and the target value\n",
    "- Example: Model might learn that \"C\" passengers have a higher survival rate than \"not C\" passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why not encode as a single feature?**\n",
    "\n",
    "- **Pretend:**\n",
    "  - C: high survival rate\n",
    "  - Q: low survival rate\n",
    "  - S: high survival rate\n",
    "- **Single feature would need two coefficients:**\n",
    "  - Negative coefficient for impact of Q (with respect to C)\n",
    "  - Positive coefficient for impact of S (with respect to Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Transformer methods: fit, transform, fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generic transformer methods:**\n",
    "\n",
    "- **fit:** Transformer learns something\n",
    "- **transform:** Transformer uses what it learned to do the data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneHotEncoder methods:**\n",
    "\n",
    "- **fit:** Learn the categories\n",
    "- **transform:** Create the feature matrix using those categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 One-hot encoding of multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(df[['Embarked', 'Sex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding the output array:**\n",
    "\n",
    "- **First three columns:**\n",
    "  - 1, 0, 0 means \"C\"\n",
    "  - 0, 1, 0 means \"Q\"\n",
    "  - 0, 0, 1 means \"S\"\n",
    "- **Last two columns:**\n",
    "  - 1, 0 means \"female\"\n",
    "  - 0, 1 means \"male\"\n",
    "- **Example:**\n",
    "  - 0, 0, 1, 0, 1 means \"S, male\"\n",
    "  - 1, 0, 0, 1, 0 means \"C, female\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to manually add Embarked and Sex to the model:**\n",
    "\n",
    "1. Stack Parch and Fare side-by-side with OneHotEncoder output\n",
    "2. Repeat the same process with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems with a manual approach:**\n",
    "\n",
    "- Repeating steps is inefficient and error-prone\n",
    "- Complexity will increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Q&A: When should I use transform instead of fit_transform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_train = pd.DataFrame({'letter':['A', 'B', 'C', 'B']})\n",
    "demo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of fit_transform on training data:**\n",
    "\n",
    "- **fit:** Learn 3 categories (A, B, C)\n",
    "- **transform:** Create feature matrix with 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_test = pd.DataFrame({'letter':['A', 'C', 'A']})\n",
    "demo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of fit_transform on testing data:**\n",
    "\n",
    "- **fit:** Learn 2 categories (A, C)\n",
    "- **transform:** Create feature matrix with 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(demo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correct process:**\n",
    "\n",
    "1. Run fit_transform on training data:\n",
    "  - **fit:** Learn 3 categories (A, B, C)\n",
    "  - **transform:** Create feature matrix with 3 columns\n",
    "2. Run transform on testing data:\n",
    "  - **transform:** Create feature matrix with 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Q&A: What happens if the testing data includes a new category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_test_unknown = pd.DataFrame({'letter':['A', 'C', 'D']})\n",
    "demo_test_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(demo_test_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, categories=[['A', 'B', 'C', 'D']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(demo_test_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why you might not know all possible categories:**\n",
    "\n",
    "- Rare categories aren't present in your set of samples\n",
    "- New categories are added later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(demo_test_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice for OneHotEncoder:**\n",
    "\n",
    "1. Start with handle_unknown set to 'error'\n",
    "2. If possible, specify the categories manually\n",
    "3. If necessary, set handle_unknown to 'ignore' and then retrain your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Q&A: Should I drop one of the one-hot encoded categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can drop the first column:**\n",
    "\n",
    "- Contains redundant information\n",
    "- Avoids collinearity between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "ohe.fit_transform(demo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding the output array (after dropping the first column):**\n",
    "\n",
    "- 0, 0 means \"A\"\n",
    "- 1, 0 means \"B\"\n",
    "- 0, 1 means \"C\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Should you drop the first column?**\n",
    "\n",
    "- **Advantages:**\n",
    "  - Useful if perfectly collinear features will cause problems (does not apply to most models)\n",
    "- **Disadvantages:**\n",
    "  - Incompatible with handle_unknown='ignore'\n",
    "  - Introduces bias if you standardize features or use a regularized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Q&A: How do I encode an ordinal feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of categorical data:**\n",
    "\n",
    "- Unordered (nominal data)\n",
    "- Ordered (ordinal data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options for encoding Pclass:**\n",
    "\n",
    "- **Ordinal encoding:** Creates one feature\n",
    "- **One-hot encoding:** Creates three features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordinal = pd.DataFrame({'Class': ['third', 'first', 'second', 'third'],\n",
    "                           'Size': ['S', 'S', 'L', 'XL']})\n",
    "df_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder(categories=[['first', 'second', 'third'],\n",
    "                                ['S', 'M', 'L', 'XL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe.fit_transform(df_ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding the output array:**\n",
    "\n",
    "- **First column:**\n",
    "  - 0 means \"first\"\n",
    "  - 1 means \"second\"\n",
    "  - 2 means \"third\"\n",
    "- **Second column:**\n",
    "  - 0 means \"S\"\n",
    "  - 1 means \"M\"\n",
    "  - 2 means \"L\"\n",
    "  - 3 means \"XL\"\n",
    "- **Example:**\n",
    "  - 2, 0 means \"third, S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, categories=[['first', 'second', 'third'],\n",
    "                                              ['S', 'M', 'L', 'XL']])\n",
    "ohe.fit_transform(df_ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice for encoding categorical data:**\n",
    "\n",
    "- **Ordinal feature stored as numbers:** Leave as-is\n",
    "- **Ordinal feature stored as strings:** Use OrdinalEncoder\n",
    "- **Nominal feature:** Use OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Q&A: What's the difference between OrdinalEncoder and LabelEncoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; | OrdinalEncoder | LabelEncoder\n",
    ":--- | :---: | :---:\n",
    "Can you define the category order? | Yes | No\n",
    "Can you encode multiple features? | Yes | No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outdated uses for LabelEncoder:**\n",
    "\n",
    "- Encoding string-based labels for some classifiers\n",
    "- Encoding string-based features for OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Q&A: Should I encode numeric features as ordinal features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = KBinsDiscretizer(n_bins=3, strategy='quantile', encode='ordinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.fit_transform(df[['Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why not discretize numeric features?**\n",
    "\n",
    "- Makes it harder to learn the actual trends\n",
    "- Makes it easier to discover non-existent trends\n",
    "- May result in overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Improving your workflow with ColumnTransformer and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Preprocessing features with ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems from Chapter 3:**\n",
    "\n",
    "- Need to stack categorical features next to numerical features\n",
    "- Need to apply the same preprocessing to new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to solve those problems:**\n",
    "\n",
    "- **ColumnTransformer:** Apply different preprocessing steps to different columns\n",
    "- **Pipeline:** Apply the same workflow to training data and new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df[cols]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuple elements for make_column_transformer:**\n",
    "\n",
    "1. Transformer object\n",
    "2. List of columns to which the transformer should be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output columns:**\n",
    "\n",
    "- **Columns 1-3:** Embarked\n",
    "- **Columns 4-5:** Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output columns:**\n",
    "\n",
    "- **Columns 1-3:** Embarked\n",
    "- **Columns 4-5:** Sex\n",
    "- **Column 6:** Parch\n",
    "- **Column 7:** Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes about get_feature_names:**\n",
    "\n",
    "- **Before version 0.23:** Didn't work with passthrough columns\n",
    "- **Starting in version 1.0:** Has been replaced with get_feature_names_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuple elements for make_column_transformer (revised):**\n",
    "\n",
    "1. Transformer object or \"drop\" or \"passthrough\"\n",
    "2. List of columns to which the transformer should be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('passthrough', ['Parch', 'Fare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Chaining steps with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(ct, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline steps:**\n",
    "\n",
    "1. Data preprocessing with ColumnTransformer\n",
    "2. Model building with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the Pipeline:**\n",
    "\n",
    "1. ColumnTransformer converts X (4 columns) into a numeric feature matrix (7 columns)\n",
    "2. LogisticRegression model is fit to the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = ct.fit_transform(X)\n",
    "logreg.fit(X_t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Using the Pipeline to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new = df_new[cols]\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting with the Pipeline:**\n",
    "\n",
    "1. ColumnTransformer applies the same transformations to X_new\n",
    "2. Fitted LogisticRegression model makes predictions on the transformed version of X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_t = ct.transform(X_new)\n",
    "logreg.predict(X_new_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_new.shape)\n",
    "print(X_new_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ColumnTransformer methods:**\n",
    "\n",
    "1. Run fit_transform on X:\n",
    "  - **fit:** Learn the encoding\n",
    "  - **transform:** Apply the encoding to create 7 columns\n",
    "2. Run transform on X_new:\n",
    "  - **transform:** Apply the encoding to create 7 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Q&A: How do I drop some columns and passthrough others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('drop', ['Fare']),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('passthrough', ['Parch']),\n",
    "    remainder='drop')\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Q&A: How do I transform the unspecified columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('drop', ['Fare']),\n",
    "    remainder=scaler)\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Q&A: How do I select columns from a NumPy array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = X.to_numpy()\n",
    "X_new_array = X_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, [2, 3]),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, slice(2, 4)),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, [False, False, True, True]),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options for selecting columns from a NumPy array:**\n",
    "\n",
    "- Integer position\n",
    "- Slice\n",
    "- Boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_array, y)\n",
    "pipe.predict(X_new_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Q&A: How do I select columns by data type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_object = make_column_selector(dtype_include=object)\n",
    "select_number = make_column_selector(dtype_include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, select_object),\n",
    "    ('passthrough', select_number))\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_object = make_column_selector(dtype_exclude=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, select_object),\n",
    "    ('passthrough', exclude_object))\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_datetime = make_column_selector(dtype_include='datetime')\n",
    "select_category = make_column_selector(dtype_include='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_multiple = make_column_selector(dtype_include=[object, 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Q&A: How do I select columns by column name pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_ES = make_column_selector(pattern='E|S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, select_ES),\n",
    "    remainder='passthrough')\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Q&A: Should I use ColumnTransformer or make_column_transformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer(\n",
    "    [('OHE', ohe, ['Embarked', 'Sex']),\n",
    "     ('pass', 'passthrough', ['Parch', 'Fare'])])\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuple elements for ColumnTransformer:**\n",
    "\n",
    "1. Transformer name\n",
    "2. Transformer object or \"drop\" or \"passthrough\"\n",
    "3. List of columns to which the transformer should be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('passthrough', ['Parch', 'Fare']))\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; | ColumnTransformer | make_column_transformer\n",
    ":--- | :---: | :---:\n",
    "Allows custom names? | Yes | No\n",
    "Allows transformer weights? | Yes | No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10 Q&A: Should I use Pipeline or make_pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('preprocessor', ct), ('classifier', logreg)])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuple elements for Pipeline:**\n",
    "\n",
    "1. Step name\n",
    "2. Model or transformer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; | Pipeline | make_pipeline\n",
    ":--- | :---: | :---:\n",
    "Allows custom names? | Yes | No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11 Q&A: How do I examine the steps of a Pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['columntransformer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['logisticregression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['columntransformer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['logisticregression'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps.logisticregression.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe['logisticregression'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe[1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Workflow review #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Recap of our workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://bit.ly/MLtrain', nrows=10)\n",
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/MLnewdata', nrows=10)\n",
    "X_new = df_new[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    ('passthrough', ['Parch', 'Fare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Comparing ColumnTransformer and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataschool.io/files/simple_pipeline.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ColumnTransformer vs Pipeline:**\n",
    "\n",
    "- **ColumnTransformer:**\n",
    "  - Selects subsets of columns, transforms them independently, stacks the results side-by-side\n",
    "  - Only includes transformers\n",
    "  - Does not have steps (transformers operate in parallel)\n",
    "- **Pipeline:**\n",
    "  - Series of steps that occur in order\n",
    "  - Output of each step becomes the input to the next step\n",
    "  - Last step is a model or transformer, all other steps are transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Creating a Pipeline diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display='text')\n",
    "pipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
