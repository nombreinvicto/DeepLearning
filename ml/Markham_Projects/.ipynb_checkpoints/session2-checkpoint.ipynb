{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course: Building an Effective ML Workflow with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last week:\n",
    "\n",
    "- Review of the basic Machine Learning workflow\n",
    "- Encoding categorical data\n",
    "- Using ColumnTransformer and Pipeline\n",
    "- Recap\n",
    "- Encoding text data\n",
    "\n",
    "### This week:\n",
    "\n",
    "- Handling missing values\n",
    "- Switching to the full dataset\n",
    "- Recap\n",
    "- Evaluating and tuning a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter code (copy from here: http://bit.ly/first-ml-lesson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://bit.ly/kaggletrain', nrows=10)\n",
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/kaggletest', nrows=10)\n",
    "X_new = df_new[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use \"Age\" as a feature, but note that it has a missing value (encoded as \"NaN\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to add the \"Age\" column to our model:\n",
    "\n",
    "- Fitting the pipeline will throw an error due to the presence of a missing value\n",
    "- scikit-learn models don't accept data with missing values (except for Histogram-based Gradient Boosting Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>male</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch     Fare Embarked     Sex  \\\n",
       "0      0   7.2500        S    male   \n",
       "1      0  71.2833        C  female   \n",
       "2      0   7.9250        S  female   \n",
       "3      0  53.1000        S  female   \n",
       "4      0   8.0500        S    male   \n",
       "5      0   8.4583        Q    male   \n",
       "6      0  51.8625        S    male   \n",
       "7      1  21.0750        S    male   \n",
       "8      2  11.1333        S  female   \n",
       "9      0  30.0708        C  female   \n",
       "\n",
       "                                                Name   Age  \n",
       "0                            Braund, Mr. Owen Harris  22.0  \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0  \n",
       "2                             Heikkinen, Miss. Laina  26.0  \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0  \n",
       "4                           Allen, Mr. William Henry  35.0  \n",
       "5                                   Moran, Mr. James   NaN  \n",
       "6                            McCarthy, Mr. Timothy J  54.0  \n",
       "7                     Palsson, Master. Gosta Leonard   2.0  \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  27.0  \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  14.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name', 'Age']\n",
    "X = df[cols]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option is to drop any rows from the DataFrame that have missing values:\n",
    "\n",
    "- This can be a useful approach, but only if you know that the missingness is random and it only affects a small portion of your dataset\n",
    "- If a lot of your rows have missing values, then this approach will throw away too much useful training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch     Fare Embarked     Sex  \\\n",
       "0      0   7.2500        S    male   \n",
       "1      0  71.2833        C  female   \n",
       "2      0   7.9250        S  female   \n",
       "3      0  53.1000        S  female   \n",
       "4      0   8.0500        S    male   \n",
       "6      0  51.8625        S    male   \n",
       "7      1  21.0750        S    male   \n",
       "8      2  11.1333        S  female   \n",
       "9      0  30.0708        C  female   \n",
       "\n",
       "                                                Name   Age  \n",
       "0                            Braund, Mr. Owen Harris  22.0  \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0  \n",
       "2                             Heikkinen, Miss. Laina  26.0  \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0  \n",
       "4                           Allen, Mr. William Henry  35.0  \n",
       "6                            McCarthy, Mr. Timothy J  54.0  \n",
       "7                     Palsson, Master. Gosta Leonard   2.0  \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  27.0  \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  14.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second option is to drop any features that have missing values:\n",
    "\n",
    "- However, you may be throwing away a useful feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>male</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch     Fare Embarked     Sex  \\\n",
       "0      0   7.2500        S    male   \n",
       "1      0  71.2833        C  female   \n",
       "2      0   7.9250        S  female   \n",
       "3      0  53.1000        S  female   \n",
       "4      0   8.0500        S    male   \n",
       "5      0   8.4583        Q    male   \n",
       "6      0  51.8625        S    male   \n",
       "7      1  21.0750        S    male   \n",
       "8      2  11.1333        S  female   \n",
       "9      0  30.0708        C  female   \n",
       "\n",
       "                                                Name  \n",
       "0                            Braund, Mr. Owen Harris  \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  \n",
       "2                             Heikkinen, Miss. Laina  \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  \n",
       "4                           Allen, Mr. William Henry  \n",
       "5                                   Moran, Mr. James  \n",
       "6                            McCarthy, Mr. Timothy J  \n",
       "7                     Palsson, Master. Gosta Leonard  \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third option is to impute missing values:\n",
    "\n",
    "- Imputation means that you are filling in missing values based on what you know from the non-missing data\n",
    "- Carefully consider the costs and benefits of imputation before proceeding, because you are making up data\n",
    "\n",
    "Use SimpleImputer to perform the imputation:\n",
    "\n",
    "- It requires 2-dimensional input (just like OneHotEncoder)\n",
    "- By default, it fills missing values with the mean of the non-missing values\n",
    "- It also supports other imputation strategies: median value, most frequent value, or a user-defined value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.        ],\n",
       "       [38.        ],\n",
       "       [26.        ],\n",
       "       [35.        ],\n",
       "       [35.        ],\n",
       "       [28.11111111],\n",
       "       [54.        ],\n",
       "       [ 2.        ],\n",
       "       [27.        ],\n",
       "       [14.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer()\n",
    "imp.fit_transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the statistics_ attribute (which was learned during the fit step) to see what value was imputed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.11111111])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the ColumnTransformer to include the SimpleImputer:\n",
    "\n",
    "- Brackets are required around \"Age\" because SimpleImputer expects 2-dimensional input\n",
    "- Reminder: Brackets are not allowed around \"Name\" because CountVectorizer expects 1-dimensional input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x48 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 88 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the Pipeline to include the revised ColumnTransformer, and fit it on X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the \"named_steps\" to confirm that the Pipeline looks correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer': ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('onehotencoder',\n",
       "                                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                                dtype=<class 'numpy.float64'>,\n",
       "                                                handle_unknown='error',\n",
       "                                                sparse=True),\n",
       "                                  ['Embarked', 'Sex']),\n",
       "                                 ('countvectorizer',\n",
       "                                  CountVectorizer(analyzer='word', binary=False,\n",
       "                                                  decode_error='strict',\n",
       "                                                  dtype=...\n",
       "                                                  input='content',\n",
       "                                                  lowercase=True, max_df=1.0,\n",
       "                                                  max_features=None, min_df=1,\n",
       "                                                  ngram_range=(1, 1),\n",
       "                                                  preprocessor=None,\n",
       "                                                  stop_words=None,\n",
       "                                                  strip_accents=None,\n",
       "                                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                  tokenizer=None,\n",
       "                                                  vocabulary=None),\n",
       "                                  'Name'),\n",
       "                                 ('simpleimputer',\n",
       "                                  SimpleImputer(add_indicator=False, copy=True,\n",
       "                                                fill_value=None,\n",
       "                                                missing_values=nan,\n",
       "                                                strategy='mean', verbose=0),\n",
       "                                  ['Age'])],\n",
       "                   verbose=False),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=1, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                    warm_start=False)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update X_new to use the same columns as X, and then make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = df_new[cols]\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened during the predict step?\n",
    "\n",
    "- If X_new didn't have any missing values in \"Age\", then nothing gets imputed during prediction\n",
    "- If X_new did have missing values in \"Age\", then the imputation value is the mean of \"Age\" in X (which was 28.11), not the mean of \"Age\" in X_new\n",
    "  - This is important because you are only allowed to learn from the training data, and then apply what you learned to both the training and testing data\n",
    "  - This is why we fit_transform on training data, and transform (only) on testing data\n",
    "- During prediction, every row (in X_new) is considered independently and predictions are done one at a time\n",
    "  - Thus if you passed a single row to the predict method, it becomes obvious that scikit-learn has to look to the training data for the imputation value\n",
    "\n",
    "When imputing missing values, you can also add \"missingness\" as a feature:\n",
    "\n",
    "- Set \"add_indicator=True\" (new in version 0.21) to add a binary indicator matrix indicating the presence of missing values\n",
    "- This is useful when the data is not missing at random, since there might be a relationship between \"missingness\" and the target\n",
    "  - Example: If \"Age\" is missing because older passengers declined to give their ages, and older passengers are more likely to have survived, then there is a relationship between \"missing Age\" and \"Survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.        ,  0.        ],\n",
       "       [38.        ,  0.        ],\n",
       "       [26.        ,  0.        ],\n",
       "       [35.        ,  0.        ],\n",
       "       [35.        ,  0.        ],\n",
       "       [28.11111111,  1.        ],\n",
       "       [54.        ,  0.        ],\n",
       "       [ 2.        ,  0.        ],\n",
       "       [27.        ,  0.        ],\n",
       "       [14.        ,  0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_indicator = SimpleImputer(add_indicator=True)\n",
    "imp_indicator.fit_transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also other imputers available in scikit-learn:\n",
    "\n",
    "- IterativeImputer (new in version 0.21)\n",
    "- KNNImputer (new in version 0.22)\n",
    "\n",
    "These new imputers will produce more useful imputations than SimpleImputer in some (but not all) cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Switching to the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the full datasets into df and df_new:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/kaggletest')\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values in the full datasets:\n",
    "\n",
    "- There are two new problems we'll have to handle that weren't present in our smaller datasets:\n",
    "  - Problem 1: \"Embarked\" has missing values in df\n",
    "  - Problem 2: \"Fare\" has missing values in df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine X and y for the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_transform will error since \"Embarked\" contains missing values (problem 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll solve problem 1 by imputing missing values for \"Embarked\" before one-hot encoding it.\n",
    "\n",
    "First create a new imputer:\n",
    "\n",
    "- For categorical features, you can impute the most frequent value or a user-defined value\n",
    "- We'll impute a user-defined value of \"missing\" (a string):\n",
    "  - This essentially treats missing values as a fourth category, and it will become a fourth column during one-hot encoding\n",
    "  - This is similar (but not identical) to imputing the most frequent value and then adding a missing indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_constant = SimpleImputer(strategy='constant', fill_value='missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create a Pipeline of two transformers:\n",
    "\n",
    "- Step 1 is imputation, and step 2 is one-hot encoding\n",
    "- fit_transform on \"Embarked\" now outputs four columns (rather than three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ohe = make_pipeline(imp_constant, ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<891x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 891 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_ohe.fit_transform(X[['Embarked']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what happens \"under the hood\" when you fit_transform the Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<891x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 891 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit_transform(imp_constant.fit_transform(X[['Embarked']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the rules for Pipelines:\n",
    "\n",
    "- All Pipeline steps (other than the final step) must be a transformer, and the final step can be a model or a transformer\n",
    "- Our larger Pipeline (called \"pipe\") ends in a model, and thus we use the fit and predict methods with it\n",
    "- Our smaller Pipeline (called \"imp_ohe\") ends in a transformer, and thus we use the fit_transform and transform methods with it\n",
    "\n",
    "Replace \"ohe\" with \"imp_ohe\" in the ColumnTransformer:\n",
    "\n",
    "- You can use any transformer inside of a ColumnTransformer, and \"imp_ohe\" is eligible since it acts like a transformer\n",
    "- It's fine to apply \"imp_ohe\" to \"Sex\" as well as \"Embarked\":\n",
    "  - There are no missing values in \"Sex\" so the imputation step won't affect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have solved problem 1, so we can now fit_transform on X:\n",
    "\n",
    "- The feature matrix is much wider than before because \"Name\" has a ton of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<891x1518 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7328 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll solve problem 2 by imputing missing values for \"Fare\":\n",
    "\n",
    "- Modify the ColumnTransformer to apply the \"imp\" transformer to \"Fare\"\n",
    "- Remember that \"Fare\" only has missing values in X_new, but not in X:\n",
    "  - When the imputer is fit to X, it will learn the imputation value that will be applied to X_new during prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age', 'Fare']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_transform outputs the same number of columns as before, since \"Fare\" just moved from a passthrough column to a transformed column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<891x1518 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7328 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the Pipeline to include the revised ColumnTransformer, and fit it on X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update X_new to use the same columns as X, and then make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = df_new[cols]\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all of the code that is necessary to recreate our workflow up to this point:\n",
    "\n",
    "- You can copy/paste this code from http://bit.ly/complex-pipeline\n",
    "- There are no calls to \"fit_transform\" or \"transform\" because all of that functionality is encapsulated by the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Parch', 'Fare', 'Embarked', 'Sex', 'Name', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "X = df[cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('http://bit.ly/kaggletest')\n",
    "X_new = df_new[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_constant = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ohe = make_pipeline(imp_constant, ohe)\n",
    "vect = CountVectorizer()\n",
    "imp = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (imp_ohe, ['Embarked', 'Sex']),\n",
    "    (vect, 'Name'),\n",
    "    (imp, ['Age', 'Fare']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(ct, logreg)\n",
    "pipe.fit(X, y)\n",
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Pipeline and ColumnTransformer:\n",
    "\n",
    "- ColumnTransformer pulls out subsets of columns and transforms them independently, and then stacks the results side-by-side\n",
    "- Pipeline is a series of steps that occur in order, and the output of each step passes to the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/6509492/80736064-9d52a280-8adf-11ea-8832-2b2740e70d0c.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why wouldn't we do all of the transformations in pandas, and just use scikit-learn for model building?\n",
    "\n",
    "1. CountVectorizer is a highly useful technique for encoding text data, and it can't be done using pandas\n",
    "  - Using both pandas and scikit-learn for transformations adds workflow complexity, especially if you have to combine a dense matrix (output by pandas) and a sparse matrix (output by CountVectorizer)\n",
    "2. One-hot encoding can be done using pandas, but you will probably add those columns to your DataFrame\n",
    "  - This makes the DataFrame larger and more difficult to navigate\n",
    "3. Missing value imputation can be done using pandas, but it will result in data leakage\n",
    "\n",
    "What is data leakage?\n",
    "\n",
    "- Inadvertently including knowledge from the testing data when training a model\n",
    "\n",
    "Why is data leakage bad?\n",
    "\n",
    "- Your model evaluation scores will be less reliable\n",
    "  - This may lead you to make bad decisions when tuning hyperparameters\n",
    "  - This will lead you to overestimate how well your model will perform on new data\n",
    "- It's hard to know whether your scores will be off by a negligible amount or a huge amount\n",
    "\n",
    "Why would missing value imputation in pandas cause data leakage?\n",
    "\n",
    "- Your model evaluation procedure (such as cross-validation) is supposed to simulate the future, so that you can accurately estimate right now how well your model will perform on new data\n",
    "- If you impute missing values on your whole dataset in pandas and then pass your dataset to scikit-learn, your model evaluation procedure will no longer be an accurate simulation of reality\n",
    "  - This is because the imputation values are based on your entire dataset, rather than just the training portion of your dataset\n",
    "  - Keep in mind that the \"training portion\" will change 5 times during 5-fold cross-validation, thus it's quite impractical to avoid data leakage if you use pandas for imputation\n",
    "\n",
    "What other transformations in pandas will cause data leakage?\n",
    "\n",
    "- Feature scaling\n",
    "- One-hot encoding (unless there is a fixed set of categories)\n",
    "- Any transformations which incorporate information about other rows when transforming a row\n",
    "\n",
    "How does scikit-learn prevent data leakage?\n",
    "\n",
    "- It has separate fit and transform steps, which allow you to base your data transformations on the training set only, and then apply those transformations to both the training set and the testing set\n",
    "- Pipeline's fit and predict methods ensure that fit_transform and transform are called at the appropriate times\n",
    "- cross_val_score and GridSearchCV split the data prior to performing data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Evaluating and tuning a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use cross_val_score on the entire Pipeline to estimate its classification accuracy:\n",
    "\n",
    "- Cross-validation is a useful tool now that we're using the full dataset\n",
    "- We're using 5 folds because it has been shown to be a reasonable default choice\n",
    "- cross_val_score performs the data transformations (specified in the ColumnTransformer) after each of the 5 data splits in order to prevent data leakage\n",
    "  - If it performed the data transformations before the data splits, that would have resulted in data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8114619295712762"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to tune the hyperparameters for both the model and the transformers:\n",
    "\n",
    "- We have been using the default hyperparameters for most objects\n",
    "- \"Hyperparameters\" are values you set, whereas \"parameters\" are values learned by the estimator during the fitting process\n",
    "- Hyperparameter tuning is likely to result in a more accurate model\n",
    "\n",
    "We'll use GridSearchCV for hyperparameter tuning:\n",
    "\n",
    "- You define what values you want to try for each hyperparameter, and it cross-validates every possible combination of those values\n",
    "- You have to tune hyperparameters together, since the best performing combination might be when none of them are at their default values\n",
    "- Being able to tune the transformers simultaneous to the model is yet another benefit of doing transformations in scikit-learn rather than pandas\n",
    "\n",
    "Because we're tuning a Pipeline, we need to know the step names from named_steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['columntransformer', 'logisticregression'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the hyperparameters and values to try in a dictionary:\n",
    "\n",
    "- Create an empty dictionary called params\n",
    "- For our logistic regression model, we will tune:\n",
    "  - penalty: type of regularization (default is 'l2')\n",
    "  - C: amount of regularization (default is 1.0)\n",
    "  - Choosing which hyperparameters to tune and what values to try requires both research and experience\n",
    "- The dictionary key is the step name, followed by 2 underscores, followed by the hyperparameter name\n",
    "- The dictionary value is the list of values you want to try for that hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__penalty': ['l1', 'l2'],\n",
       " 'logisticregression__C': [0.1, 1, 10]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params['logisticregression__penalty'] = ['l1', 'l2']\n",
    "params['logisticregression__C'] = [0.1, 1, 10]\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the grid search:\n",
    "\n",
    "- Creating a GridSearchCV instance is similar to cross_val_score, except that you don't pass X and y but you do pass params\n",
    "- Fitting the GridSearchCV object performs the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the results of the grid search into a DataFrame:\n",
    "\n",
    "- 6 rows means that it ran cross-validation 6 times, which is every possible combination of C (3 values) and penalty (2 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013179</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012467</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.788990</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.814814</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012881</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.811462</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018128</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.818178</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.013179      0.001090         0.006131        0.001403   \n",
       "1       0.012467      0.000274         0.004867        0.000117   \n",
       "2       0.013442      0.000392         0.004720        0.000045   \n",
       "3       0.012881      0.000346         0.004768        0.000058   \n",
       "4       0.018128      0.002229         0.004792        0.000173   \n",
       "5       0.013615      0.000414         0.004737        0.000087   \n",
       "\n",
       "  param_logisticregression__C param_logisticregression__penalty  \\\n",
       "0                         0.1                                l1   \n",
       "1                         0.1                                l2   \n",
       "2                           1                                l1   \n",
       "3                           1                                l2   \n",
       "4                          10                                l1   \n",
       "5                          10                                l2   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'logisticregression__C': 0.1, 'logisticregres...           0.787709   \n",
       "1  {'logisticregression__C': 0.1, 'logisticregres...           0.798883   \n",
       "2  {'logisticregression__C': 1, 'logisticregressi...           0.815642   \n",
       "3  {'logisticregression__C': 1, 'logisticregressi...           0.798883   \n",
       "4  {'logisticregression__C': 10, 'logisticregress...           0.821229   \n",
       "5  {'logisticregression__C': 10, 'logisticregress...           0.782123   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.803371           0.769663           0.758427           0.797753   \n",
       "1           0.803371           0.764045           0.775281           0.803371   \n",
       "2           0.820225           0.797753           0.792135           0.848315   \n",
       "3           0.825843           0.803371           0.786517           0.842697   \n",
       "4           0.814607           0.814607           0.792135           0.848315   \n",
       "5           0.803371           0.808989           0.797753           0.853933   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.783385        0.016946                6  \n",
       "1         0.788990        0.016258                5  \n",
       "2         0.814814        0.019787                2  \n",
       "3         0.811462        0.020141                3  \n",
       "4         0.818178        0.018007                1  \n",
       "5         0.809234        0.024080                4  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the DataFrame by \"rank_test_score\":\n",
    "\n",
    "- Our column of interest is \"mean_test_score\"\n",
    "- Best result was C=10 and penalty='l1', neither of which was the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018128</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.818178</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.814814</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012881</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.811462</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012467</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.788990</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013179</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4       0.018128      0.002229         0.004792        0.000173   \n",
       "2       0.013442      0.000392         0.004720        0.000045   \n",
       "3       0.012881      0.000346         0.004768        0.000058   \n",
       "5       0.013615      0.000414         0.004737        0.000087   \n",
       "1       0.012467      0.000274         0.004867        0.000117   \n",
       "0       0.013179      0.001090         0.006131        0.001403   \n",
       "\n",
       "  param_logisticregression__C param_logisticregression__penalty  \\\n",
       "4                          10                                l1   \n",
       "2                           1                                l1   \n",
       "3                           1                                l2   \n",
       "5                          10                                l2   \n",
       "1                         0.1                                l2   \n",
       "0                         0.1                                l1   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "4  {'logisticregression__C': 10, 'logisticregress...           0.821229   \n",
       "2  {'logisticregression__C': 1, 'logisticregressi...           0.815642   \n",
       "3  {'logisticregression__C': 1, 'logisticregressi...           0.798883   \n",
       "5  {'logisticregression__C': 10, 'logisticregress...           0.782123   \n",
       "1  {'logisticregression__C': 0.1, 'logisticregres...           0.798883   \n",
       "0  {'logisticregression__C': 0.1, 'logisticregres...           0.787709   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "4           0.814607           0.814607           0.792135           0.848315   \n",
       "2           0.820225           0.797753           0.792135           0.848315   \n",
       "3           0.825843           0.803371           0.786517           0.842697   \n",
       "5           0.803371           0.808989           0.797753           0.853933   \n",
       "1           0.803371           0.764045           0.775281           0.803371   \n",
       "0           0.803371           0.769663           0.758427           0.797753   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "4         0.818178        0.018007                1  \n",
       "2         0.814814        0.019787                2  \n",
       "3         0.811462        0.020141                3  \n",
       "5         0.809234        0.024080                4  \n",
       "1         0.788990        0.016258                5  \n",
       "0         0.783385        0.016946                6  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to tune the transformers, we need to know their names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(add_indicator=False, copy=True,\n",
       "                                fill_value='missing', missing_values=nan,\n",
       "                                strategy='constant', verbose=0)),\n",
       "                 ('onehotencoder',\n",
       "                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='error', sparse=True))],\n",
       "          verbose=False),\n",
       " 'countvectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, vocabulary=None),\n",
       " 'simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "               missing_values=nan, strategy='mean', verbose=0),\n",
       " 'remainder': 'passthrough'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps.columntransformer.named_transformers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the \"drop\" hyperparameter of OneHotEncoder by adding it to the params dictionary:\n",
    "\n",
    "- Pipeline step: \"columntransformer\"\n",
    "- First transformer: \"pipeline\"\n",
    "- Second step of the inner pipeline: \"onehotencoder\"\n",
    "- Hyperparameter: \"drop\"\n",
    "- Separate each of these components by 2 underscores\n",
    "\n",
    "Try the values None and 'first':\n",
    "\n",
    "- None is the default\n",
    "- 'first' means drop the first level of each feature after encoding (new in version 0.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['columntransformer__pipeline__onehotencoder__drop'] = [None, 'first']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the \"ngram_range\" hyperparameter of CountVectorizer:\n",
    "\n",
    "- Pipeline step: \"columntransformer\"\n",
    "- Second transformer: \"countvectorizer\"\n",
    "- Hyperparameter: \"ngram_range\" (note the single underscore)\n",
    "\n",
    "Try the values (1, 1) and (1, 2):\n",
    "\n",
    "- (1, 1) is the default, which creates a single feature from each word\n",
    "- (1, 2) creates features from both single words and word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['columntransformer__countvectorizer__ngram_range'] = [(1, 1), (1, 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the \"add_indicator\" hyperparameter of SimpleImputer:\n",
    "\n",
    "- Pipeline step: \"columntransformer\"\n",
    "- Third transformer: \"simpleimputer\"\n",
    "- Hyperparameter: \"add_indicator\" (note the single underscore)\n",
    "\n",
    "Try the values False and True:\n",
    "\n",
    "- False is the default\n",
    "- True means add a binary indicator matrix (new in version 0.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['columntransformer__simpleimputer__add_indicator'] = [False, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the params dictionary for any typos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__penalty': ['l1', 'l2'],\n",
       " 'logisticregression__C': [0.1, 1, 10],\n",
       " 'columntransformer__pipeline__onehotencoder__drop': [None, 'first'],\n",
       " 'columntransformer__countvectorizer__ngram_range': [(1, 1), (1, 2)],\n",
       " 'columntransformer__simpleimputer__add_indicator': [False, True]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the grid search again:\n",
    "\n",
    "- There are 48 combinations to try, so it takes 8 times longer than the previous search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort and review the search results:\n",
    "\n",
    "- Accuracy of the best model is an improvement over the previous grid search\n",
    "- It's hard to pick out trends for each hyperparameter because many of them affect one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_columntransformer__countvectorizer__ngram_range</th>\n",
       "      <th>param_columntransformer__pipeline__onehotencoder__drop</th>\n",
       "      <th>param_columntransformer__simpleimputer__add_indicator</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.023061</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.829370</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.029656</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.828259</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.826006</td>\n",
       "      <td>0.024549</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.023133</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.824889</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.020138</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.819296</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.021249</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.818178</td>\n",
       "      <td>0.026034</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018240</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.818178</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.014477</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.814820</td>\n",
       "      <td>0.021852</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.814814</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.021138</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.814808</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.018747</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.813703</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.018135</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.026265</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013765</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.812579</td>\n",
       "      <td>0.026183</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.812579</td>\n",
       "      <td>0.020194</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.017634</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.812579</td>\n",
       "      <td>0.020194</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.014208</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.811481</td>\n",
       "      <td>0.031065</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.013204</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.811468</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.811462</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.811449</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.810363</td>\n",
       "      <td>0.032182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.023233</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.012510</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.810332</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.017513</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.810332</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.013241</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.018231</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.025357</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013436</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.809234</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.023017</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.808104</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.017329</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.808097</td>\n",
       "      <td>0.022143</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.017454</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.806980</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.016762</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.805844</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.005101</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.805844</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.016940</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.804739</td>\n",
       "      <td>0.024489</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.016125</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.794608</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.793484</td>\n",
       "      <td>0.017253</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.012406</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.791243</td>\n",
       "      <td>0.017572</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.790114</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.789003</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.015791</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.788996</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.788990</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.011891</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.787885</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014173</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.015586</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012031</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.783385</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.016099</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.777785</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.777785</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.012544</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.777785</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.012307</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'columntransformer__countvectorizer__ngram_ra...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.777785</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "28       0.023061      0.002269         0.005146        0.000024   \n",
       "46       0.029656      0.003894         0.005461        0.000197   \n",
       "40       0.030675      0.002119         0.005186        0.000081   \n",
       "34       0.023133      0.001805         0.005422        0.000201   \n",
       "10       0.020138      0.002229         0.005470        0.000890   \n",
       "22       0.021249      0.001699         0.004953        0.000112   \n",
       "4        0.018240      0.001837         0.004744        0.000091   \n",
       "20       0.014477      0.001047         0.005164        0.000368   \n",
       "2        0.013728      0.000415         0.004839        0.000075   \n",
       "16       0.021138      0.001391         0.004800        0.000139   \n",
       "44       0.018747      0.001117         0.005938        0.000527   \n",
       "47       0.018135      0.000447         0.005382        0.000114   \n",
       "8        0.013765      0.000456         0.004881        0.000127   \n",
       "14       0.013688      0.000971         0.004796        0.000181   \n",
       "38       0.017634      0.000525         0.005225        0.000081   \n",
       "11       0.014208      0.000597         0.005329        0.000715   \n",
       "21       0.013204      0.000708         0.004958        0.000345   \n",
       "3        0.013157      0.000342         0.004966        0.000461   \n",
       "26       0.017373      0.000133         0.005122        0.000050   \n",
       "23       0.013665      0.000259         0.004913        0.000128   \n",
       "9        0.012987      0.000245         0.004787        0.000074   \n",
       "15       0.012510      0.000078         0.004724        0.000065   \n",
       "32       0.017513      0.000521         0.005245        0.000034   \n",
       "17       0.013241      0.000162         0.004707        0.000095   \n",
       "35       0.018231      0.000590         0.005368        0.000091   \n",
       "5        0.013436      0.000172         0.004653        0.000031   \n",
       "29       0.023017      0.011150         0.005115        0.000026   \n",
       "45       0.017329      0.000598         0.005484        0.000115   \n",
       "41       0.017454      0.000328         0.005192        0.000138   \n",
       "39       0.016762      0.000371         0.005216        0.000141   \n",
       "27       0.016690      0.000149         0.005101        0.000031   \n",
       "33       0.016940      0.000164         0.005267        0.000074   \n",
       "31       0.016125      0.000202         0.005330        0.000113   \n",
       "7        0.012880      0.001058         0.005017        0.000315   \n",
       "19       0.012406      0.000379         0.004833        0.000086   \n",
       "43       0.016018      0.000072         0.005258        0.000042   \n",
       "37       0.016297      0.001262         0.005391        0.000457   \n",
       "25       0.015791      0.000137         0.005094        0.000033   \n",
       "1        0.012500      0.000984         0.004949        0.000352   \n",
       "13       0.011891      0.000116         0.004815        0.000203   \n",
       "0        0.014173      0.001353         0.005162        0.000298   \n",
       "24       0.015586      0.000120         0.005175        0.000132   \n",
       "6        0.012031      0.000139         0.004970        0.000330   \n",
       "30       0.016099      0.000485         0.005302        0.000050   \n",
       "36       0.015749      0.000290         0.005128        0.000038   \n",
       "42       0.016111      0.000190         0.005278        0.000020   \n",
       "12       0.012544      0.000763         0.004768        0.000070   \n",
       "18       0.012307      0.000567         0.004854        0.000064   \n",
       "\n",
       "   param_columntransformer__countvectorizer__ngram_range  \\\n",
       "28                                             (1, 2)      \n",
       "46                                             (1, 2)      \n",
       "40                                             (1, 2)      \n",
       "34                                             (1, 2)      \n",
       "10                                             (1, 1)      \n",
       "22                                             (1, 1)      \n",
       "4                                              (1, 1)      \n",
       "20                                             (1, 1)      \n",
       "2                                              (1, 1)      \n",
       "16                                             (1, 1)      \n",
       "44                                             (1, 2)      \n",
       "47                                             (1, 2)      \n",
       "8                                              (1, 1)      \n",
       "14                                             (1, 1)      \n",
       "38                                             (1, 2)      \n",
       "11                                             (1, 1)      \n",
       "21                                             (1, 1)      \n",
       "3                                              (1, 1)      \n",
       "26                                             (1, 2)      \n",
       "23                                             (1, 1)      \n",
       "9                                              (1, 1)      \n",
       "15                                             (1, 1)      \n",
       "32                                             (1, 2)      \n",
       "17                                             (1, 1)      \n",
       "35                                             (1, 2)      \n",
       "5                                              (1, 1)      \n",
       "29                                             (1, 2)      \n",
       "45                                             (1, 2)      \n",
       "41                                             (1, 2)      \n",
       "39                                             (1, 2)      \n",
       "27                                             (1, 2)      \n",
       "33                                             (1, 2)      \n",
       "31                                             (1, 2)      \n",
       "7                                              (1, 1)      \n",
       "19                                             (1, 1)      \n",
       "43                                             (1, 2)      \n",
       "37                                             (1, 2)      \n",
       "25                                             (1, 2)      \n",
       "1                                              (1, 1)      \n",
       "13                                             (1, 1)      \n",
       "0                                              (1, 1)      \n",
       "24                                             (1, 2)      \n",
       "6                                              (1, 1)      \n",
       "30                                             (1, 2)      \n",
       "36                                             (1, 2)      \n",
       "42                                             (1, 2)      \n",
       "12                                             (1, 1)      \n",
       "18                                             (1, 1)      \n",
       "\n",
       "   param_columntransformer__pipeline__onehotencoder__drop  \\\n",
       "28                                               None       \n",
       "46                                              first       \n",
       "40                                              first       \n",
       "34                                               None       \n",
       "10                                               None       \n",
       "22                                              first       \n",
       "4                                                None       \n",
       "20                                              first       \n",
       "2                                                None       \n",
       "16                                              first       \n",
       "44                                              first       \n",
       "47                                              first       \n",
       "8                                                None       \n",
       "14                                              first       \n",
       "38                                              first       \n",
       "11                                               None       \n",
       "21                                              first       \n",
       "3                                                None       \n",
       "26                                               None       \n",
       "23                                              first       \n",
       "9                                                None       \n",
       "15                                              first       \n",
       "32                                               None       \n",
       "17                                              first       \n",
       "35                                               None       \n",
       "5                                                None       \n",
       "29                                               None       \n",
       "45                                              first       \n",
       "41                                              first       \n",
       "39                                              first       \n",
       "27                                               None       \n",
       "33                                               None       \n",
       "31                                               None       \n",
       "7                                                None       \n",
       "19                                              first       \n",
       "43                                              first       \n",
       "37                                              first       \n",
       "25                                               None       \n",
       "1                                                None       \n",
       "13                                              first       \n",
       "0                                                None       \n",
       "24                                               None       \n",
       "6                                                None       \n",
       "30                                               None       \n",
       "36                                              first       \n",
       "42                                              first       \n",
       "12                                              first       \n",
       "18                                              first       \n",
       "\n",
       "   param_columntransformer__simpleimputer__add_indicator  \\\n",
       "28                                              False      \n",
       "46                                               True      \n",
       "40                                              False      \n",
       "34                                               True      \n",
       "10                                               True      \n",
       "22                                               True      \n",
       "4                                               False      \n",
       "20                                               True      \n",
       "2                                               False      \n",
       "16                                              False      \n",
       "44                                               True      \n",
       "47                                               True      \n",
       "8                                                True      \n",
       "14                                              False      \n",
       "38                                              False      \n",
       "11                                               True      \n",
       "21                                               True      \n",
       "3                                               False      \n",
       "26                                              False      \n",
       "23                                               True      \n",
       "9                                                True      \n",
       "15                                              False      \n",
       "32                                               True      \n",
       "17                                              False      \n",
       "35                                               True      \n",
       "5                                               False      \n",
       "29                                              False      \n",
       "45                                               True      \n",
       "41                                              False      \n",
       "39                                              False      \n",
       "27                                              False      \n",
       "33                                               True      \n",
       "31                                               True      \n",
       "7                                                True      \n",
       "19                                               True      \n",
       "43                                               True      \n",
       "37                                              False      \n",
       "25                                              False      \n",
       "1                                               False      \n",
       "13                                              False      \n",
       "0                                               False      \n",
       "24                                              False      \n",
       "6                                                True      \n",
       "30                                               True      \n",
       "36                                              False      \n",
       "42                                               True      \n",
       "12                                              False      \n",
       "18                                               True      \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__penalty  \\\n",
       "28                          10                                l1   \n",
       "46                          10                                l1   \n",
       "40                          10                                l1   \n",
       "34                          10                                l1   \n",
       "10                          10                                l1   \n",
       "22                          10                                l1   \n",
       "4                           10                                l1   \n",
       "20                           1                                l1   \n",
       "2                            1                                l1   \n",
       "16                          10                                l1   \n",
       "44                           1                                l1   \n",
       "47                          10                                l2   \n",
       "8                            1                                l1   \n",
       "14                           1                                l1   \n",
       "38                           1                                l1   \n",
       "11                          10                                l2   \n",
       "21                           1                                l2   \n",
       "3                            1                                l2   \n",
       "26                           1                                l1   \n",
       "23                          10                                l2   \n",
       "9                            1                                l2   \n",
       "15                           1                                l2   \n",
       "32                           1                                l1   \n",
       "17                          10                                l2   \n",
       "35                          10                                l2   \n",
       "5                           10                                l2   \n",
       "29                          10                                l2   \n",
       "45                           1                                l2   \n",
       "41                          10                                l2   \n",
       "39                           1                                l2   \n",
       "27                           1                                l2   \n",
       "33                           1                                l2   \n",
       "31                         0.1                                l2   \n",
       "7                          0.1                                l2   \n",
       "19                         0.1                                l2   \n",
       "43                         0.1                                l2   \n",
       "37                         0.1                                l2   \n",
       "25                         0.1                                l2   \n",
       "1                          0.1                                l2   \n",
       "13                         0.1                                l2   \n",
       "0                          0.1                                l1   \n",
       "24                         0.1                                l1   \n",
       "6                          0.1                                l1   \n",
       "30                         0.1                                l1   \n",
       "36                         0.1                                l1   \n",
       "42                         0.1                                l1   \n",
       "12                         0.1                                l1   \n",
       "18                         0.1                                l1   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "28  {'columntransformer__countvectorizer__ngram_ra...           0.860335   \n",
       "46  {'columntransformer__countvectorizer__ngram_ra...           0.849162   \n",
       "40  {'columntransformer__countvectorizer__ngram_ra...           0.854749   \n",
       "34  {'columntransformer__countvectorizer__ngram_ra...           0.849162   \n",
       "10  {'columntransformer__countvectorizer__ngram_ra...           0.826816   \n",
       "22  {'columntransformer__countvectorizer__ngram_ra...           0.821229   \n",
       "4   {'columntransformer__countvectorizer__ngram_ra...           0.821229   \n",
       "20  {'columntransformer__countvectorizer__ngram_ra...           0.810056   \n",
       "2   {'columntransformer__countvectorizer__ngram_ra...           0.815642   \n",
       "16  {'columntransformer__countvectorizer__ngram_ra...           0.821229   \n",
       "44  {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "47  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "8   {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "14  {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "38  {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "11  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "21  {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "3   {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "26  {'columntransformer__countvectorizer__ngram_ra...           0.810056   \n",
       "23  {'columntransformer__countvectorizer__ngram_ra...           0.776536   \n",
       "9   {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "15  {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "32  {'columntransformer__countvectorizer__ngram_ra...           0.804469   \n",
       "17  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "35  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "5   {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "29  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "45  {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "41  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "39  {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "27  {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "33  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "31  {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "7   {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "19  {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "43  {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "37  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "25  {'columntransformer__countvectorizer__ngram_ra...           0.793296   \n",
       "1   {'columntransformer__countvectorizer__ngram_ra...           0.798883   \n",
       "13  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "0   {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "24  {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "6   {'columntransformer__countvectorizer__ngram_ra...           0.787709   \n",
       "30  {'columntransformer__countvectorizer__ngram_ra...           0.782123   \n",
       "36  {'columntransformer__countvectorizer__ngram_ra...           0.770950   \n",
       "42  {'columntransformer__countvectorizer__ngram_ra...           0.770950   \n",
       "12  {'columntransformer__countvectorizer__ngram_ra...           0.770950   \n",
       "18  {'columntransformer__countvectorizer__ngram_ra...           0.770950   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "28           0.820225           0.820225           0.786517   \n",
       "46           0.831461           0.820225           0.786517   \n",
       "40           0.825843           0.814607           0.786517   \n",
       "34           0.820225           0.820225           0.780899   \n",
       "10           0.814607           0.820225           0.780899   \n",
       "22           0.803371           0.825843           0.780899   \n",
       "4            0.814607           0.814607           0.792135   \n",
       "20           0.820225           0.797753           0.792135   \n",
       "2            0.820225           0.797753           0.792135   \n",
       "16           0.803371           0.814607           0.780899   \n",
       "44           0.820225           0.797753           0.792135   \n",
       "47           0.820225           0.820225           0.780899   \n",
       "8            0.820225           0.786517           0.792135   \n",
       "14           0.820225           0.797753           0.792135   \n",
       "38           0.820225           0.797753           0.792135   \n",
       "11           0.803371           0.808989           0.792135   \n",
       "21           0.820225           0.803371           0.786517   \n",
       "3            0.825843           0.803371           0.786517   \n",
       "26           0.820225           0.786517           0.792135   \n",
       "23           0.803371           0.808989           0.792135   \n",
       "9            0.825843           0.797753           0.786517   \n",
       "15           0.820225           0.803371           0.786517   \n",
       "32           0.820225           0.780899           0.792135   \n",
       "17           0.803371           0.808989           0.797753   \n",
       "35           0.820225           0.814607           0.780899   \n",
       "5            0.803371           0.808989           0.797753   \n",
       "29           0.814607           0.820225           0.780899   \n",
       "45           0.814607           0.797753           0.786517   \n",
       "41           0.814607           0.820225           0.780899   \n",
       "39           0.808989           0.797753           0.786517   \n",
       "27           0.814607           0.792135           0.786517   \n",
       "33           0.814607           0.792135           0.786517   \n",
       "31           0.803371           0.769663           0.786517   \n",
       "7            0.803371           0.764045           0.786517   \n",
       "19           0.803371           0.764045           0.780899   \n",
       "43           0.797753           0.764045           0.780899   \n",
       "37           0.803371           0.764045           0.780899   \n",
       "25           0.803371           0.764045           0.775281   \n",
       "1            0.803371           0.764045           0.775281   \n",
       "13           0.803371           0.764045           0.780899   \n",
       "0            0.803371           0.769663           0.758427   \n",
       "24           0.803371           0.769663           0.758427   \n",
       "6            0.803371           0.769663           0.758427   \n",
       "30           0.803371           0.769663           0.758427   \n",
       "36           0.797753           0.769663           0.758427   \n",
       "42           0.797753           0.769663           0.758427   \n",
       "12           0.797753           0.769663           0.758427   \n",
       "18           0.797753           0.769663           0.758427   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "28           0.859551         0.829370        0.027833                1  \n",
       "46           0.853933         0.828259        0.024138                2  \n",
       "40           0.848315         0.826006        0.024549                3  \n",
       "34           0.853933         0.824889        0.026120                4  \n",
       "10           0.853933         0.819296        0.023467                5  \n",
       "22           0.859551         0.818178        0.026034                6  \n",
       "4            0.848315         0.818178        0.018007                6  \n",
       "20           0.853933         0.814820        0.021852                8  \n",
       "2            0.848315         0.814814        0.019787                9  \n",
       "16           0.853933         0.814808        0.023886               10  \n",
       "44           0.853933         0.813703        0.022207               11  \n",
       "47           0.853933         0.812598        0.026265               12  \n",
       "8            0.859551         0.812579        0.026183               13  \n",
       "14           0.848315         0.812579        0.020194               14  \n",
       "38           0.848315         0.812579        0.020194               14  \n",
       "11           0.870787         0.811481        0.031065               16  \n",
       "21           0.853933         0.811468        0.024076               17  \n",
       "3            0.842697         0.811462        0.020141               18  \n",
       "26           0.848315         0.811449        0.022058               19  \n",
       "23           0.870787         0.810363        0.032182               20  \n",
       "9            0.848315         0.810345        0.023233               21  \n",
       "15           0.837079         0.810332        0.017107               22  \n",
       "32           0.853933         0.810332        0.025419               22  \n",
       "17           0.853933         0.809234        0.024080               24  \n",
       "35           0.848315         0.809234        0.025357               24  \n",
       "5            0.853933         0.809234        0.024080               24  \n",
       "29           0.837079         0.808104        0.020904               27  \n",
       "45           0.848315         0.808097        0.022143               28  \n",
       "41           0.831461         0.806980        0.019414               29  \n",
       "39           0.837079         0.805844        0.017164               30  \n",
       "27           0.837079         0.805844        0.018234               30  \n",
       "33           0.848315         0.804739        0.024489               32  \n",
       "31           0.814607         0.794608        0.015380               33  \n",
       "7            0.814607         0.793484        0.017253               34  \n",
       "19           0.814607         0.791243        0.017572               35  \n",
       "43           0.808989         0.790114        0.015849               36  \n",
       "37           0.808989         0.789003        0.016100               37  \n",
       "25           0.808989         0.788996        0.016944               38  \n",
       "1            0.803371         0.788990        0.016258               39  \n",
       "13           0.808989         0.787885        0.016343               40  \n",
       "0            0.797753         0.783385        0.016946               41  \n",
       "24           0.797753         0.783385        0.016946               41  \n",
       "6            0.797753         0.783385        0.016946               41  \n",
       "30           0.797753         0.782267        0.016807               44  \n",
       "36           0.792135         0.777785        0.014779               45  \n",
       "42           0.792135         0.777785        0.014779               45  \n",
       "12           0.792135         0.777785        0.014779               45  \n",
       "18           0.792135         0.777785        0.014779               45  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the single best score and best set of hyperparameters:\n",
    "\n",
    "- Two of the hyperparameters used the default values (drop, add_indicator)\n",
    "- Three of the hyperparameters did not use the default values (ngram_range, C, penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293704098926622"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer__countvectorizer__ngram_range': (1, 2),\n",
       " 'columntransformer__pipeline__onehotencoder__drop': None,\n",
       " 'columntransformer__simpleimputer__add_indicator': False,\n",
       " 'logisticregression__C': 10,\n",
       " 'logisticregression__penalty': 'l1'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the GridSearchCV object to make predictions:\n",
    "\n",
    "- It automatically refits the Pipeline on all of the data (X and y) with the best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
