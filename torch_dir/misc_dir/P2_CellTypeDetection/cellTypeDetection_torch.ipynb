{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from loader_util.datasets import CustomTorchDataset, train_test_split_paths \n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define constants\n",
    "batch_size = 32\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = r\"/home/mhasan3/Desktop/WorkFolder/cellImages3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\mhasa/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "baseModel = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove classifier head\n",
    "for param in baseModel.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%    \n"
    }
   },
   "outputs": [],
   "source": [
    "# remove head\n",
    "cell_types = 3\n",
    "fcHead = nn.Linear(in_features=4096, out_features=cell_types)\n",
    "baseModel.classifier[6] = fcHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%    \n"
    }
   },
   "outputs": [],
   "source": [
    "trainPaths, testPaths = train_test_split_paths(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = CustomTorchDataset(pathList=trainPaths,\n",
    "                                tranforms=train_transform)\n",
    "test_data = CustomTorchDataset(pathList=testPaths,\n",
    "                                tranforms=valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18032/964457181.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m                           \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m                           \u001B[0mshuffle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m                           num_workers=4)\n\u001B[0m\u001B[0;32m      5\u001B[0m test_loader = DataLoader(test_data,\n\u001B[0;32m      6\u001B[0m                          batch_size=batch_size)\n",
      "\u001B[1;32mc:\\users\\mhasa\\pycharmprojects\\dl4cv\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001B[0m\n\u001B[0;32m    268\u001B[0m                     \u001B[1;31m# Cannot statically verify that dataset is Sized\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    269\u001B[0m                     \u001B[1;31m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 270\u001B[1;33m                     \u001B[0msampler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRandomSampler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgenerator\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[arg-type]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    271\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    272\u001B[0m                     \u001B[0msampler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSequentialSampler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[arg-type]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\mhasa\\pycharmprojects\\dl4cv\\venv\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[0;32m    101\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_samples\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    102\u001B[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001B[1;32m--> 103\u001B[1;33m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001B[0m\u001B[0;32m    104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    105\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "test_loader = DataLoader(test_data,\n",
    "                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "baseModel.to(device=device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "print(\"Params to learn:\")\n",
    "\n",
    "for name,param in baseModel.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_train_losses = []\n",
    "epoch_train_accus = []\n",
    "epoch_valid_losses = []\n",
    "epoch_valid_accus = []\n",
    "\n",
    "# define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "# loop over the epochs\n",
    "for epoch in range (1, num_epochs + 1):\n",
    "    \n",
    "    # keep track of all losses\n",
    "    running_train_loss = 0\n",
    "    running_valid_loss = 0\n",
    "    \n",
    "    running_train_acc = 0\n",
    "    running_valid_acc = 0\n",
    "    \n",
    "    train_batch_no = 0\n",
    "    valid_batch_no = 0\n",
    "    \n",
    "    # TRAIN\n",
    "    baseModel.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        train_batch_no += 1\n",
    "        \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = baseModel(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # exponentiate the logits\n",
    "        exp_logits = torch.exp(logits)\n",
    "        \n",
    "        # pass thru softmax to calculate probs\n",
    "        probs = exp_logits / (torch.sum(exp_logits, dim=1).view(exp_logits.shape[0],-1))\n",
    "        \n",
    "        # get top class and to class prob\n",
    "        top_p, top_class = probs.topk(1, dim=1)\n",
    "        \n",
    "        # reshape labels into column vector\n",
    "        labels = labels.view(labels.shape[0], -1)\n",
    "    \n",
    "        # find which labels are correctly classified\n",
    "        acc_boolean = top_class == labels\n",
    "       \n",
    "        # finally calculate accuracy\n",
    "        running_train_acc += np.sum(acc_boolean.cpu().numpy()) / len(acc_boolean)\n",
    "        \n",
    "        # make gradient descent step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "    else:\n",
    "        epoch_train_loss = running_train_loss / train_batch_no\n",
    "        epoch_train_losses.append(epoch_train_loss)\n",
    "        epoch_train_accu = running_train_acc / train_batch_no\n",
    "        epoch_train_accus.append(epoch_train_accu)\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        print(f'{train_batch_no} train batches completed')\n",
    "        \n",
    "        \n",
    "    \n",
    "    # VALIDATE\n",
    "    baseModel.eval()\n",
    "    with torch.no_grad():\n",
    "        for valid_images, valid_labels in test_loader:\n",
    "            valid_images, valid_labels = valid_images.to(device), valid_labels.to\\\n",
    "                (device)\n",
    "            valid_batch_no += 1\n",
    "            \n",
    "            # Validation pass\n",
    "            valid_logits = baseModel(valid_images)\n",
    "            valid_loss = criterion(valid_logits, valid_labels)\n",
    "            \n",
    "            # exponentiate the logits\n",
    "            valid_exp_logits = torch.exp(valid_logits)\n",
    "            \n",
    "            # pass thru softmax to calculate probs\n",
    "            valid_probs = valid_exp_logits / (torch.sum(valid_exp_logits, dim=1)\n",
    "                                              .view(valid_exp_logits.shape[0],-1))\n",
    "            \n",
    "            # get top class and to class prob\n",
    "            valid_top_p, valid_top_class = valid_probs.topk(1, dim=1)\n",
    "            \n",
    "            # reshape labels into column vector\n",
    "            valid_labels = valid_labels.view(valid_labels.shape[0], -1)\n",
    "        \n",
    "            # find which labels are correctly classified\n",
    "            valid_acc_boolean = valid_top_class == valid_labels\n",
    "           \n",
    "            # finally calculate accuracy\n",
    "            running_valid_acc += np.sum(valid_acc_boolean.cpu().numpy()) / len\\\n",
    "                (valid_acc_boolean)\n",
    "    \n",
    "            running_valid_loss += valid_loss.item()\n",
    "        else:\n",
    "            # dividing because running loss is the sum loss of all batches \n",
    "            epoch_valid_loss = running_valid_loss / valid_batch_no\n",
    "            epoch_valid_accu = running_valid_acc / valid_batch_no\n",
    "            epoch_valid_losses.append(epoch_valid_loss)\n",
    "            epoch_valid_accus.append(epoch_valid_accu)\n",
    "            print ( f\"Training loss: {epoch_train_loss} \" )\n",
    "            print(f'Train accu: {epoch_train_accu}')\n",
    "            print(f'{valid_batch_no} test batches completed')\n",
    "            print ( f\"Validation loss: {epoch_valid_loss}\")\n",
    "            print(f'Validation accu: {epoch_valid_accu}')\n",
    "            print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%   \n"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "# plot the performance\n",
    "import pandas as pd\n",
    "epochs = range(1, num_epochs+1)\n",
    "plot_df = pd.DataFrame(data=np.c_[epochs, epoch_train_losses, \n",
    "                                  epoch_valid_losses, epoch_train_accus, \n",
    "                                  epoch_valid_accus], \n",
    "                       columns=['epochs','train_loss', 'test_loss', \n",
    "                                'train_acc', 'valid_acc'])\n",
    "\n",
    "# do the actual plots\n",
    "sns.set(font_scale=1)\n",
    "f, ax = plt.subplots(1, 1, figsize=(15,8))\n",
    "sns.lineplot(data=plot_df, x='epochs', y='train_loss', ax=ax, label='trainloss', linewidth=3)\n",
    "sns.lineplot(data=plot_df, x='epochs', y='test_loss', ax=ax, label='val loss', linewidth=3)\n",
    "sns.lineplot(data=plot_df, x='epochs', y='valid_acc', ax=ax, label='val_acc', \n",
    "             linewidth=3)\n",
    "sns.lineplot(data=plot_df, x='epochs', y='train_acc', ax=ax, \n",
    "             label='train_acc', linewidth=3)\n",
    "ax.set_ylabel('Loss/Accuracy')\n",
    "ax.set_xlabel('Epochs')\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='18'); # for legend text         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_tensor in baseModel.state_dict():\n",
    "    print(param_tensor, \"\\t\", baseModel.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(baseModel, 'torch_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('torch_checkpoint.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image_name = 'MG63Sample.jpg'\n",
    "cv_img = cv2.imread(image_name)\n",
    "plt.imshow(cv_img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = Image.open(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_pil_image = valid_transforms(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_pil_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_pil_image = torch.unsqueeze(transformed_pil_image, 0)\n",
    "transformed_pil_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_for_image = model(transformed_pil_image.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_logits = torch.exp(logits_for_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = exp_logits / torch.sum(exp_logits)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Image.fromarray(cv_img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}