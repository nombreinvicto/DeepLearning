{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "PgFKbnZ-Vnlp",
    "outputId": "1e4b7b4f-8e01-481b-c463-7dafe0a9183b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3mfwVKYtUqam",
    "outputId": "288471d1-58f4-4625-db7f-b9a76103c66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/loader_util.zip\n",
      "   creating: loader_util/\n",
      "   creating: loader_util/callbacks/\n",
      "  inflating: loader_util/callbacks/epochcheckpoint.py  \n",
      "  inflating: loader_util/callbacks/trainingmonitor.py  \n",
      "  inflating: loader_util/callbacks/__init__.py  \n",
      "   creating: loader_util/callbacks/__pycache__/\n",
      "  inflating: loader_util/callbacks/__pycache__/epochcheckpoint.cpython-36.pyc  \n",
      "  inflating: loader_util/callbacks/__pycache__/trainingmonitor.cpython-36.pyc  \n",
      "  inflating: loader_util/callbacks/__pycache__/__init__.cpython-36.pyc  \n",
      "   creating: loader_util/datasets/\n",
      "  inflating: loader_util/datasets/simpledatasetloader.py  \n",
      "  inflating: loader_util/datasets/torch_dataset_loader.py  \n",
      "  inflating: loader_util/datasets/torch_train_test_split.py  \n",
      "  inflating: loader_util/datasets/__init__.py  \n",
      "   creating: loader_util/datasets/__pycache__/\n",
      "  inflating: loader_util/datasets/__pycache__/simpledatasetloader.cpython-36.pyc  \n",
      "  inflating: loader_util/datasets/__pycache__/torch_dataset_loader.cpython-36.pyc  \n",
      "  inflating: loader_util/datasets/__pycache__/torch_train_test_split.cpython-36.pyc  \n",
      "  inflating: loader_util/datasets/__pycache__/__init__.cpython-36.pyc  \n",
      "   creating: loader_util/deepgooglenet/\n",
      "  inflating: loader_util/deepgooglenet/build_tiny_imagenet.py  \n",
      "   creating: loader_util/deepgooglenet/config/\n",
      "  inflating: loader_util/deepgooglenet/config/tiny_imagenet_config.py  \n",
      " extracting: loader_util/deepgooglenet/config/__init__.py  \n",
      "   creating: loader_util/deepgooglenet/config/__pycache__/\n",
      "  inflating: loader_util/deepgooglenet/config/__pycache__/tiny_imagenet_config.cpython-36.pyc  \n",
      "  inflating: loader_util/deepgooglenet/config/__pycache__/__init__.cpython-36.pyc  \n",
      "   creating: loader_util/deepgooglenet/output/\n",
      "   creating: loader_util/deepgooglenet/output/checkpoints/\n",
      " extracting: loader_util/deepgooglenet/output/checkpoints/__init__.py  \n",
      " extracting: loader_util/deepgooglenet/output/tiny-image-net-200-mean.json  \n",
      " extracting: loader_util/deepgooglenet/output/__init__.py  \n",
      " extracting: loader_util/deepgooglenet/rank_accuracy.py  \n",
      " extracting: loader_util/deepgooglenet/train.py  \n",
      "   creating: loader_util/dogs_vs_cats/\n",
      "  inflating: loader_util/dogs_vs_cats/build_dogs_vs_cats.py  \n",
      "   creating: loader_util/dogs_vs_cats/config/\n",
      "  inflating: loader_util/dogs_vs_cats/config/dog_vs_cats_config.py  \n",
      " extracting: loader_util/dogs_vs_cats/config/__init__.py  \n",
      "   creating: loader_util/dogs_vs_cats/config/__pycache__/\n",
      "  inflating: loader_util/dogs_vs_cats/config/__pycache__/dog_vs_cats_config.cpython-36.pyc  \n",
      "  inflating: loader_util/dogs_vs_cats/config/__pycache__/__init__.cpython-36.pyc  \n",
      "   creating: loader_util/dogs_vs_cats/output/\n",
      " extracting: loader_util/dogs_vs_cats/output/__init__.py  \n",
      " extracting: loader_util/dogs_vs_cats/__init__.py  \n",
      "   creating: loader_util/dogs_vs_cats/__pycache__/\n",
      "  inflating: loader_util/dogs_vs_cats/__pycache__/__init__.cpython-36.pyc  \n",
      "   creating: loader_util/io/\n",
      "  inflating: loader_util/io/hdf5datasetgenerator.py  \n",
      "  inflating: loader_util/io/hdf5_dataset_writer.py  \n",
      "  inflating: loader_util/io/hdf5_dataset_writer_research_nlp.py  \n",
      "  inflating: loader_util/io/__init__.py  \n",
      "   creating: loader_util/io/__pycache__/\n",
      "  inflating: loader_util/io/__pycache__/hdf5datasetgenerator.cpython-36.pyc  \n",
      "  inflating: loader_util/io/__pycache__/hdf5_dataset_writer.cpython-36.pyc  \n",
      "  inflating: loader_util/io/__pycache__/hdf5_dataset_writer_research_nlp.cpython-36.pyc  \n",
      "  inflating: loader_util/io/__pycache__/__init__.cpython-36.pyc  \n",
      "   creating: loader_util/nn/\n",
      "   creating: loader_util/nn/conv/\n",
      "  inflating: loader_util/nn/conv/alexnet.py  \n",
      "  inflating: loader_util/nn/conv/deepergooglenet.py  \n",
      "  inflating: loader_util/nn/conv/fcheadnet.py  \n",
      "  inflating: loader_util/nn/conv/lenet.py  \n",
      "  inflating: loader_util/nn/conv/lenet_batchnorm.py  \n",
      "  inflating: loader_util/nn/conv/lenet_torch.py  \n",
      "  inflating: loader_util/nn/conv/minigooglenet.py  \n",
      "  inflating: loader_util/nn/conv/minvggnet.py  \n",
      "  inflating: loader_util/nn/conv/resnet.py  \n",
      "  inflating: loader_util/nn/conv/shallownet.py  \n",
      "  inflating: loader_util/nn/conv/shallownet_torch.py  \n",
      "  inflating: loader_util/nn/conv/__init__.py  \n",
      "   creating: loader_util/nn/conv/__pycache__/\n",
      "  inflating: loader_util/nn/conv/__pycache__/alexnet.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/deepergooglenet.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/fcheadnet.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/lenet.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/lenet.cpython-37.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/lenet_batchnorm.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/minigooglenet.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/minvggnet.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/minvggnet.cpython-37.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/resnet.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/shallownet.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/shallownet.cpython-37.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/shallownet_torch.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/__init__.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/conv/__pycache__/__init__.cpython-37.pyc  \n",
      "  inflating: loader_util/nn/perceptron.py  \n",
      " extracting: loader_util/nn/__init__.py  \n",
      "   creating: loader_util/nn/__pycache__/\n",
      "  inflating: loader_util/nn/__pycache__/__init__.cpython-36.pyc  \n",
      "  inflating: loader_util/nn/__pycache__/__init__.cpython-37.pyc  \n",
      "   creating: loader_util/preprocessing/\n",
      "  inflating: loader_util/preprocessing/aspect_aware_preprocessing.py  \n",
      "  inflating: loader_util/preprocessing/croppreprocessor.py  \n",
      "  inflating: loader_util/preprocessing/imagetoarraypreprocesor.py  \n",
      "  inflating: loader_util/preprocessing/meanpreprocessor.py  \n",
      "  inflating: loader_util/preprocessing/mean_subtraction_legacy.py  \n",
      "  inflating: loader_util/preprocessing/patchpreprocessor.py  \n",
      "  inflating: loader_util/preprocessing/simplepreprocesor.py  \n",
      "  inflating: loader_util/preprocessing/__init__.py  \n",
      "   creating: loader_util/preprocessing/__pycache__/\n",
      "  inflating: loader_util/preprocessing/__pycache__/aspect_aware_preprocessing.cpython-36.pyc  \n",
      "  inflating: loader_util/preprocessing/__pycache__/croppreprocessor.cpython-36.pyc  \n",
      "  inflating: loader_util/preprocessing/__pycache__/imagetoarraypreprocesor.cpython-36.pyc  \n",
      "  inflating: loader_util/preprocessing/__pycache__/meanpreprocessor.cpython-36.pyc  \n",
      "  inflating: loader_util/preprocessing/__pycache__/mean_subtraction_legacy.cpython-36.pyc  \n",
      "  inflating: loader_util/preprocessing/__pycache__/patchpreprocessor.cpython-36.pyc  \n",
      "  inflating: loader_util/preprocessing/__pycache__/simplepreprocesor.cpython-36.pyc  \n",
      "  inflating: loader_util/preprocessing/__pycache__/__init__.cpython-36.pyc  \n",
      "   creating: loader_util/utils/\n",
      "  inflating: loader_util/utils/captchahelper.py  \n",
      "  inflating: loader_util/utils/ranked.py  \n",
      "  inflating: loader_util/utils/simple_obj_det.py  \n",
      "  inflating: loader_util/utils/__init__.py  \n",
      "   creating: loader_util/utils/__pycache__/\n",
      "  inflating: loader_util/utils/__pycache__/captchahelper.cpython-36.pyc  \n",
      "  inflating: loader_util/utils/__pycache__/ranked.cpython-36.pyc  \n",
      "  inflating: loader_util/utils/__pycache__/__init__.cpython-36.pyc  \n",
      " extracting: loader_util/__init__.py  \n",
      "   creating: loader_util/__pycache__/\n",
      "  inflating: loader_util/__pycache__/__init__.cpython-36.pyc  \n",
      "  inflating: loader_util/__pycache__/__init__.cpython-37.pyc  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"/content/drive/My Drive/loader_util.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RJyGj7uWVf7D",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.axes._axes as axes\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yx_fpkmVVf7L",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from loader_util.preprocessing import ImageToArrayPreprocessor, \\\n",
    "    AspectAwarePreprocessor, MeanSubtractionPreProcessor, SimplePreProcessor\n",
    "from loader_util.datasets import SimpleDatasetLoader\n",
    "from loader_util.io import HDF5DatasetGenerator\n",
    "from loader_util.nn.conv import FCHeadNet, LeNet, AlexNet, MinVGGNet, MiniGoogleNet, DeeperGoogleNet\n",
    "from loader_util.callbacks import TrainingMonitor, EpochCheckpoint\n",
    "##\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mo1e-wTDVf7T",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct the train image generator\n",
    "aug = ImageDataGenerator(rotation_range=20,\n",
    "                         zoom_range=0.15,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         shear_range=0.15,\n",
    "                         horizontal_flip=True,\n",
    "                         fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_qA3Q3m_Vf7Y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch_num = 600\n",
    "image_size = 28\n",
    "\n",
    "# initialise the image preprocessors\n",
    "sp = SimplePreProcessor(width=image_size, height=image_size)\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "NNiE_Qk7Vf7c",
    "outputId": "477a8ab1-43a0-43b2-e705-8f4896262570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of classes in dataset: 10\n",
      "Unique Labels: ['Brackets', 'Bulky', 'Cylindrical', 'Gasket', 'HeadlessScrews', 'Nuts', 'O-Rings', 'Pipes', 'Springs', 'Toothy']\n"
     ]
    }
   ],
   "source": [
    "# initialise the data paths\n",
    "\n",
    "dbBase = r\"C:\\Users\\mhasa\\GDrive\\mvcnn\"\n",
    "dbTrainPath = f\"{dbBase}//train_mvcnn_color_roi_10class_28px1px_255.hdf5\"\n",
    "dbValidPath = f\"{dbBase}//test_mvcnn_color_roi_10class_28px1px_255.hdf5\"\n",
    "\n",
    "# get the no. of classes\n",
    "trainFile = h5py.File(name=dbTrainPath, mode=\"r\")\n",
    "class_num = len(list(np.unique(trainFile[\"labels\"])))\n",
    "print(f\"Total no. of classes in dataset: {class_num}\")\n",
    "\n",
    "# get unique labels\n",
    "labels = list(trainFile[\"label_names\"])\n",
    "labels = [label.decode() for label in labels]\n",
    "print(f\"Unique Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "mb8F-N5rVf7o",
    "outputId": "631e9cf5-5e30-4f05-fa9e-fff7517277b8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabels: [0 1 2 3 4 5 6 7 8 9]\n",
      "ClassWeights: [5.9427314 2.48893   4.014881  4.401305  2.0850077 3.6508796 1.\n",
      " 3.3809524 1.4536638 4.870036 ]\n"
     ]
    }
   ],
   "source": [
    "# consider class weight discrepency\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(trainFile[\"labels\"])\n",
    "encoded_labels = to_categorical(labels)\n",
    "\n",
    "classLabels = le.classes_\n",
    "classTotals = encoded_labels.sum(axis=0) # type: np.ndarray\n",
    "classWeight = classTotals.max() / classTotals\n",
    "\n",
    "print(f\"ClassLabels: {classLabels}\")\n",
    "print(f\"ClassWeights: {classWeight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xPSO7MX-Vf8H",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialise the train and valid generators\n",
    "trainGen = HDF5DatasetGenerator(dbPath=dbTrainPath,\n",
    "                                batchSize=batch_size,\n",
    "                                preprocessors=[sp, iap],\n",
    "                                classes=class_num,\n",
    "                                aug=aug)\n",
    "\n",
    "valGen = HDF5DatasetGenerator(dbPath=dbValidPath,\n",
    "                              batchSize=batch_size,\n",
    "                              preprocessors=[sp, iap],\n",
    "                              classes=class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DD7EEC8NVf8U"
   },
   "outputs": [],
   "source": [
    "# define the Learning Rate Scheduler\n",
    "\n",
    "initial_rate = 5e-3\n",
    "\n",
    "def poly_decay(epoch):\n",
    "    max_epochs = epoch_num\n",
    "    baseLR = initial_rate\n",
    "    power = 1.0\n",
    "    \n",
    "    alpha = baseLR * (1 - (epoch / float(max_epochs))) ** power\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gpfi-74uVf8c"
   },
   "outputs": [],
   "source": [
    "# model = AlexNet.build(width=32, height=32, depth=3, classes=class_num)\n",
    "# model = LeNet.build(width=28,\n",
    "#                     height=28,\n",
    "#                     depth=1,\n",
    "#                     classes=len(classLabels))\n",
    "\n",
    "model = MinVGGNet.build(width=28,\n",
    "                    height=28,\n",
    "                    depth=1,\n",
    "                    classes=len(classLabels))\n",
    "\n",
    "# model = MiniGoogleNet.build(width=28, height=28, depth=1, classes=class_num)\n",
    "#model =DeeperGoogleNet.build(width=image_size, height=image_size, depth=1, classes=class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "id": "loYIuA7HVf8i",
    "outputId": "11ff6b67-4b54-475f-9925-2e0b7edcfb2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,679,082\n",
      "Trainable params: 1,677,674\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vqpseYGHVf8m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compile and optimise model\n",
    "opt = Adam(lr=initial_rate)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# construct callbacks\n",
    "path = os.path.sep.join([dbBase, f'{os.getpid()}.png'])\n",
    "callbacks = [TrainingMonitor(path),\n",
    "             LearningRateScheduler(poly_decay),]\n",
    "             #EpochCheckpoint(outputPath=dbBase)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "7w731F5-aL_Z",
    "outputId": "44e530e0-1644-4041-8abf-392b9bdbaa0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5.9427314,\n",
       " 1: 2.48893,\n",
       " 2: 4.014881,\n",
       " 3: 4.401305,\n",
       " 4: 2.0850077,\n",
       " 5: 3.6508796,\n",
       " 6: 1.0,\n",
       " 7: 3.3809524,\n",
       " 8: 1.4536638,\n",
       " 9: 4.870036}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classWeight = {i : classWeight[i] for i in range(len(classWeight))}\n",
    "classWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AVP3yaj8Vf8u",
    "outputId": "ecb0ea70-582c-4ad0-f725-5cef3b76845d",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "336/336 [==============================] - 45s 133ms/step - loss: 4.4066 - accuracy: 0.4622 - val_loss: 6.4125 - val_accuracy: 0.1267\n",
      "Epoch 2/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 3.1087 - accuracy: 0.5858 - val_loss: 1.5449 - val_accuracy: 0.4916\n",
      "Epoch 3/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 2.6988 - accuracy: 0.6404 - val_loss: 0.9359 - val_accuracy: 0.6756\n",
      "Epoch 4/600\n",
      "336/336 [==============================] - 31s 91ms/step - loss: 2.3745 - accuracy: 0.6860 - val_loss: 0.6480 - val_accuracy: 0.7992\n",
      "Epoch 5/600\n",
      "336/336 [==============================] - 31s 92ms/step - loss: 2.0209 - accuracy: 0.7312 - val_loss: 0.6341 - val_accuracy: 0.8031\n",
      "Epoch 6/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 1.8529 - accuracy: 0.7544 - val_loss: 0.5834 - val_accuracy: 0.8182\n",
      "Epoch 7/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 1.8639 - accuracy: 0.7577 - val_loss: 1.3754 - val_accuracy: 0.5999\n",
      "Epoch 8/600\n",
      "336/336 [==============================] - 31s 92ms/step - loss: 1.7243 - accuracy: 0.7632 - val_loss: 1.5485 - val_accuracy: 0.6193\n",
      "Epoch 9/600\n",
      "336/336 [==============================] - 30s 89ms/step - loss: 1.5539 - accuracy: 0.7936 - val_loss: 0.3566 - val_accuracy: 0.8836\n",
      "Epoch 10/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 1.4591 - accuracy: 0.8082 - val_loss: 0.4124 - val_accuracy: 0.8599\n",
      "Epoch 11/600\n",
      "336/336 [==============================] - 31s 94ms/step - loss: 1.3977 - accuracy: 0.8165 - val_loss: 4.2207 - val_accuracy: 0.3447\n",
      "Epoch 12/600\n",
      "336/336 [==============================] - 31s 93ms/step - loss: 1.5239 - accuracy: 0.7966 - val_loss: 0.4209 - val_accuracy: 0.8548\n",
      "Epoch 13/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 1.3613 - accuracy: 0.8227 - val_loss: 0.7373 - val_accuracy: 0.7566\n",
      "Epoch 14/600\n",
      "336/336 [==============================] - 32s 94ms/step - loss: 1.2424 - accuracy: 0.8393 - val_loss: 0.4573 - val_accuracy: 0.8577\n",
      "Epoch 15/600\n",
      "336/336 [==============================] - 31s 93ms/step - loss: 1.2255 - accuracy: 0.8392 - val_loss: 1.5345 - val_accuracy: 0.6376\n",
      "Epoch 16/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 1.2433 - accuracy: 0.8341 - val_loss: 0.3278 - val_accuracy: 0.8948\n",
      "Epoch 17/600\n",
      "336/336 [==============================] - 31s 93ms/step - loss: 1.1580 - accuracy: 0.8464 - val_loss: 0.3505 - val_accuracy: 0.8843\n",
      "Epoch 18/600\n",
      "336/336 [==============================] - 31s 91ms/step - loss: 1.1676 - accuracy: 0.8483 - val_loss: 0.3092 - val_accuracy: 0.9044\n",
      "Epoch 19/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 1.1324 - accuracy: 0.8495 - val_loss: 0.5776 - val_accuracy: 0.8350\n",
      "Epoch 20/600\n",
      "336/336 [==============================] - 31s 92ms/step - loss: 1.1776 - accuracy: 0.8426 - val_loss: 1.5976 - val_accuracy: 0.5822\n",
      "Epoch 21/600\n",
      "336/336 [==============================] - 30s 89ms/step - loss: 1.0480 - accuracy: 0.8629 - val_loss: 0.4609 - val_accuracy: 0.8426\n",
      "Epoch 22/600\n",
      "336/336 [==============================] - 30s 90ms/step - loss: 1.1022 - accuracy: 0.8559 - val_loss: 2.4604 - val_accuracy: 0.4881\n",
      "Epoch 23/600\n",
      "336/336 [==============================] - 30s 88ms/step - loss: 1.0266 - accuracy: 0.8666 - val_loss: 0.2798 - val_accuracy: 0.9140\n",
      "Epoch 24/600\n",
      "336/336 [==============================] - 30s 88ms/step - loss: 0.9874 - accuracy: 0.8710 - val_loss: 0.3005 - val_accuracy: 0.9105\n",
      "Epoch 25/600\n",
      "336/336 [==============================] - 29s 88ms/step - loss: 0.9480 - accuracy: 0.8742 - val_loss: 0.3895 - val_accuracy: 0.8889\n",
      "Epoch 26/600\n",
      "336/336 [==============================] - 31s 92ms/step - loss: 0.8718 - accuracy: 0.8825 - val_loss: 0.2791 - val_accuracy: 0.9140\n",
      "Epoch 27/600\n",
      "336/336 [==============================] - 29s 86ms/step - loss: 0.9122 - accuracy: 0.8827 - val_loss: 0.3866 - val_accuracy: 0.8828\n",
      "Epoch 28/600\n",
      "336/336 [==============================] - 29s 88ms/step - loss: 0.9251 - accuracy: 0.8795 - val_loss: 0.7829 - val_accuracy: 0.8031\n",
      "Epoch 29/600\n",
      "336/336 [==============================] - 30s 90ms/step - loss: 0.9081 - accuracy: 0.8817 - val_loss: 0.2415 - val_accuracy: 0.9175\n",
      "Epoch 30/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.8828 - accuracy: 0.8860 - val_loss: 0.2437 - val_accuracy: 0.9253\n",
      "Epoch 31/600\n",
      "336/336 [==============================] - 30s 90ms/step - loss: 0.8805 - accuracy: 0.8887 - val_loss: 0.3117 - val_accuracy: 0.9055\n",
      "Epoch 32/600\n",
      "336/336 [==============================] - 31s 91ms/step - loss: 0.8409 - accuracy: 0.8925 - val_loss: 0.2126 - val_accuracy: 0.9330\n",
      "Epoch 33/600\n",
      "336/336 [==============================] - 30s 88ms/step - loss: 0.8318 - accuracy: 0.8900 - val_loss: 0.1902 - val_accuracy: 0.9413\n",
      "Epoch 34/600\n",
      "336/336 [==============================] - 30s 88ms/step - loss: 0.8543 - accuracy: 0.8873 - val_loss: 0.2850 - val_accuracy: 0.9129\n",
      "Epoch 35/600\n",
      "336/336 [==============================] - 29s 87ms/step - loss: 0.7986 - accuracy: 0.8954 - val_loss: 0.1743 - val_accuracy: 0.9428\n",
      "Epoch 36/600\n",
      "336/336 [==============================] - 31s 93ms/step - loss: 0.7993 - accuracy: 0.8989 - val_loss: 0.2661 - val_accuracy: 0.9288\n",
      "Epoch 37/600\n",
      "336/336 [==============================] - 31s 91ms/step - loss: 0.7956 - accuracy: 0.8977 - val_loss: 0.2943 - val_accuracy: 0.9155\n",
      "Epoch 38/600\n",
      "336/336 [==============================] - 30s 89ms/step - loss: 0.7766 - accuracy: 0.9012 - val_loss: 0.9025 - val_accuracy: 0.7647\n",
      "Epoch 39/600\n",
      "336/336 [==============================] - 30s 89ms/step - loss: 0.7927 - accuracy: 0.8970 - val_loss: 0.3265 - val_accuracy: 0.9280\n",
      "Epoch 40/600\n",
      "336/336 [==============================] - 30s 89ms/step - loss: 0.7076 - accuracy: 0.9076 - val_loss: 0.2129 - val_accuracy: 0.9352\n",
      "Epoch 41/600\n",
      "336/336 [==============================] - 30s 89ms/step - loss: 0.7687 - accuracy: 0.8990 - val_loss: 0.2055 - val_accuracy: 0.9415\n",
      "Epoch 42/600\n",
      "336/336 [==============================] - 30s 91ms/step - loss: 0.7519 - accuracy: 0.9034 - val_loss: 0.3309 - val_accuracy: 0.9199\n",
      "Epoch 43/600\n",
      "336/336 [==============================] - 30s 90ms/step - loss: 0.7311 - accuracy: 0.9078 - val_loss: 0.8718 - val_accuracy: 0.7714\n",
      "Epoch 44/600\n",
      "336/336 [==============================] - 30s 90ms/step - loss: 0.7715 - accuracy: 0.9023 - val_loss: 0.2292 - val_accuracy: 0.9343\n",
      "Epoch 45/600\n",
      "336/336 [==============================] - 31s 91ms/step - loss: 0.7089 - accuracy: 0.9078 - val_loss: 0.1400 - val_accuracy: 0.9542\n",
      "Epoch 46/600\n",
      "336/336 [==============================] - 31s 92ms/step - loss: 0.6872 - accuracy: 0.9100 - val_loss: 0.2255 - val_accuracy: 0.9264\n",
      "Epoch 47/600\n",
      "336/336 [==============================] - 29s 86ms/step - loss: 0.7167 - accuracy: 0.9065 - val_loss: 0.4378 - val_accuracy: 0.8730\n",
      "Epoch 48/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.6986 - accuracy: 0.9082 - val_loss: 0.2195 - val_accuracy: 0.9430\n",
      "Epoch 49/600\n",
      "336/336 [==============================] - 30s 89ms/step - loss: 0.6953 - accuracy: 0.9080 - val_loss: 0.7401 - val_accuracy: 0.8398\n",
      "Epoch 50/600\n",
      "336/336 [==============================] - 30s 89ms/step - loss: 0.6781 - accuracy: 0.9128 - val_loss: 0.1475 - val_accuracy: 0.9528\n",
      "Epoch 51/600\n",
      "336/336 [==============================] - 30s 90ms/step - loss: 0.6641 - accuracy: 0.9136 - val_loss: 0.2985 - val_accuracy: 0.9234\n",
      "Epoch 52/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.6353 - accuracy: 0.9185 - val_loss: 0.1401 - val_accuracy: 0.9537\n",
      "Epoch 53/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.5944 - accuracy: 0.9209 - val_loss: 0.1806 - val_accuracy: 0.9432\n",
      "Epoch 54/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.6491 - accuracy: 0.9192 - val_loss: 0.3264 - val_accuracy: 0.9118\n",
      "Epoch 55/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.6177 - accuracy: 0.9211 - val_loss: 0.3017 - val_accuracy: 0.9325\n",
      "Epoch 56/600\n",
      "336/336 [==============================] - 39s 115ms/step - loss: 0.6183 - accuracy: 0.9202 - val_loss: 0.1655 - val_accuracy: 0.9500\n",
      "Epoch 57/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 36s 108ms/step - loss: 0.6432 - accuracy: 0.9181 - val_loss: 0.4691 - val_accuracy: 0.8933\n",
      "Epoch 58/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.6435 - accuracy: 0.9162 - val_loss: 0.2079 - val_accuracy: 0.9415\n",
      "Epoch 59/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.5648 - accuracy: 0.9247 - val_loss: 0.2079 - val_accuracy: 0.9440\n",
      "Epoch 60/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.6014 - accuracy: 0.9221 - val_loss: 0.1594 - val_accuracy: 0.9522\n",
      "Epoch 61/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.6147 - accuracy: 0.9244 - val_loss: 0.1328 - val_accuracy: 0.9568\n",
      "Epoch 62/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.6277 - accuracy: 0.9197 - val_loss: 0.1585 - val_accuracy: 0.9478\n",
      "Epoch 63/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.5936 - accuracy: 0.9228 - val_loss: 0.1374 - val_accuracy: 0.9574\n",
      "Epoch 64/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.6329 - accuracy: 0.9196 - val_loss: 0.1698 - val_accuracy: 0.9474\n",
      "Epoch 65/600\n",
      "336/336 [==============================] - 34s 103ms/step - loss: 0.5908 - accuracy: 0.9226 - val_loss: 0.1526 - val_accuracy: 0.9520\n",
      "Epoch 66/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.5914 - accuracy: 0.9200 - val_loss: 0.6238 - val_accuracy: 0.8697\n",
      "Epoch 67/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.5322 - accuracy: 0.9307 - val_loss: 0.1334 - val_accuracy: 0.9627\n",
      "Epoch 68/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.5788 - accuracy: 0.9289 - val_loss: 0.1806 - val_accuracy: 0.9441\n",
      "Epoch 69/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.5916 - accuracy: 0.9253 - val_loss: 0.1972 - val_accuracy: 0.9404\n",
      "Epoch 70/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.5326 - accuracy: 0.9308 - val_loss: 0.1835 - val_accuracy: 0.9513\n",
      "Epoch 71/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.5675 - accuracy: 0.9258 - val_loss: 0.1830 - val_accuracy: 0.9467\n",
      "Epoch 72/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.5758 - accuracy: 0.9246 - val_loss: 0.1664 - val_accuracy: 0.9585\n",
      "Epoch 73/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.5431 - accuracy: 0.9284 - val_loss: 0.1696 - val_accuracy: 0.9465\n",
      "Epoch 74/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.5351 - accuracy: 0.9308 - val_loss: 0.1147 - val_accuracy: 0.9668\n",
      "Epoch 75/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.5368 - accuracy: 0.9293 - val_loss: 0.2320 - val_accuracy: 0.9253\n",
      "Epoch 76/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.5132 - accuracy: 0.9331 - val_loss: 0.2606 - val_accuracy: 0.9349\n",
      "Epoch 77/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.5427 - accuracy: 0.9278 - val_loss: 0.1801 - val_accuracy: 0.9515\n",
      "Epoch 78/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.5386 - accuracy: 0.9298 - val_loss: 0.2255 - val_accuracy: 0.9467\n",
      "Epoch 79/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.5066 - accuracy: 0.9316 - val_loss: 0.1822 - val_accuracy: 0.9504\n",
      "Epoch 80/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.5539 - accuracy: 0.9303 - val_loss: 0.2006 - val_accuracy: 0.9398\n",
      "Epoch 81/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.5207 - accuracy: 0.9324 - val_loss: 0.2943 - val_accuracy: 0.9131\n",
      "Epoch 82/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.5051 - accuracy: 0.9336 - val_loss: 0.2791 - val_accuracy: 0.9173\n",
      "Epoch 83/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.5348 - accuracy: 0.9295 - val_loss: 0.3599 - val_accuracy: 0.9081\n",
      "Epoch 84/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.5185 - accuracy: 0.9330 - val_loss: 0.1750 - val_accuracy: 0.9450\n",
      "Epoch 85/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.4756 - accuracy: 0.9363 - val_loss: 0.1707 - val_accuracy: 0.9491\n",
      "Epoch 86/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.5089 - accuracy: 0.9373 - val_loss: 0.1412 - val_accuracy: 0.9574\n",
      "Epoch 87/600\n",
      "336/336 [==============================] - 34s 103ms/step - loss: 0.4777 - accuracy: 0.9351 - val_loss: 0.4179 - val_accuracy: 0.8978\n",
      "Epoch 88/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.4634 - accuracy: 0.9381 - val_loss: 0.2087 - val_accuracy: 0.9366\n",
      "Epoch 89/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.4893 - accuracy: 0.9365 - val_loss: 0.1779 - val_accuracy: 0.9489\n",
      "Epoch 90/600\n",
      "336/336 [==============================] - 35s 106ms/step - loss: 0.4880 - accuracy: 0.9363 - val_loss: 0.1653 - val_accuracy: 0.9513\n",
      "Epoch 91/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.4893 - accuracy: 0.9380 - val_loss: 0.1899 - val_accuracy: 0.9441\n",
      "Epoch 92/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.4774 - accuracy: 0.9368 - val_loss: 0.2653 - val_accuracy: 0.9363\n",
      "Epoch 93/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.5129 - accuracy: 0.9369 - val_loss: 0.1861 - val_accuracy: 0.9489\n",
      "Epoch 94/600\n",
      "336/336 [==============================] - 34s 103ms/step - loss: 0.4989 - accuracy: 0.9356 - val_loss: 0.1472 - val_accuracy: 0.9581\n",
      "Epoch 95/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.4809 - accuracy: 0.9379 - val_loss: 0.2144 - val_accuracy: 0.9378\n",
      "Epoch 96/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.4590 - accuracy: 0.9395 - val_loss: 0.2439 - val_accuracy: 0.9339\n",
      "Epoch 97/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.4577 - accuracy: 0.9389 - val_loss: 0.2341 - val_accuracy: 0.9330\n",
      "Epoch 98/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.4915 - accuracy: 0.9387 - val_loss: 0.2714 - val_accuracy: 0.9363\n",
      "Epoch 99/600\n",
      "336/336 [==============================] - 31s 93ms/step - loss: 0.4838 - accuracy: 0.9393 - val_loss: 0.1784 - val_accuracy: 0.9526\n",
      "Epoch 100/600\n",
      "336/336 [==============================] - 32s 94ms/step - loss: 0.4451 - accuracy: 0.9427 - val_loss: 0.1511 - val_accuracy: 0.9607\n",
      "Epoch 101/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.4302 - accuracy: 0.9438 - val_loss: 0.1941 - val_accuracy: 0.9472\n",
      "Epoch 102/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.4672 - accuracy: 0.9392 - val_loss: 0.2273 - val_accuracy: 0.9369\n",
      "Epoch 103/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.4461 - accuracy: 0.9417 - val_loss: 0.1464 - val_accuracy: 0.9544\n",
      "Epoch 104/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.4485 - accuracy: 0.9428 - val_loss: 0.2121 - val_accuracy: 0.9467\n",
      "Epoch 105/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.4628 - accuracy: 0.9393 - val_loss: 0.3301 - val_accuracy: 0.9125\n",
      "Epoch 106/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.4467 - accuracy: 0.9441 - val_loss: 0.2908 - val_accuracy: 0.9315\n",
      "Epoch 107/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.4684 - accuracy: 0.9385 - val_loss: 0.3716 - val_accuracy: 0.9015\n",
      "Epoch 108/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.4345 - accuracy: 0.9421 - val_loss: 0.2350 - val_accuracy: 0.9363\n",
      "Epoch 109/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.4524 - accuracy: 0.9418 - val_loss: 0.1131 - val_accuracy: 0.9683\n",
      "Epoch 110/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.3971 - accuracy: 0.9454 - val_loss: 0.1646 - val_accuracy: 0.9577\n",
      "Epoch 111/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.4351 - accuracy: 0.9441 - val_loss: 0.1867 - val_accuracy: 0.9463\n",
      "Epoch 112/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 34s 101ms/step - loss: 0.4142 - accuracy: 0.9469 - val_loss: 0.2040 - val_accuracy: 0.9454\n",
      "Epoch 113/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.4092 - accuracy: 0.9466 - val_loss: 0.3375 - val_accuracy: 0.9090\n",
      "Epoch 114/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.4348 - accuracy: 0.9458 - val_loss: 0.2981 - val_accuracy: 0.9253\n",
      "Epoch 115/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.4417 - accuracy: 0.9426 - val_loss: 0.1297 - val_accuracy: 0.9640\n",
      "Epoch 116/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.4010 - accuracy: 0.9455 - val_loss: 0.1488 - val_accuracy: 0.9585\n",
      "Epoch 117/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.4340 - accuracy: 0.9432 - val_loss: 0.1524 - val_accuracy: 0.9605\n",
      "Epoch 118/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.4321 - accuracy: 0.9432 - val_loss: 0.2252 - val_accuracy: 0.9339\n",
      "Epoch 119/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.4717 - accuracy: 0.9391 - val_loss: 0.1287 - val_accuracy: 0.9605\n",
      "Epoch 120/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.4303 - accuracy: 0.9453 - val_loss: 0.2062 - val_accuracy: 0.9485\n",
      "Epoch 121/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3753 - accuracy: 0.9505 - val_loss: 0.1443 - val_accuracy: 0.9609\n",
      "Epoch 122/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.4362 - accuracy: 0.9466 - val_loss: 0.1213 - val_accuracy: 0.9596\n",
      "Epoch 123/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.4127 - accuracy: 0.9478 - val_loss: 0.1324 - val_accuracy: 0.9635\n",
      "Epoch 124/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.3928 - accuracy: 0.9504 - val_loss: 0.1521 - val_accuracy: 0.9577\n",
      "Epoch 125/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.4229 - accuracy: 0.9481 - val_loss: 0.1528 - val_accuracy: 0.9528\n",
      "Epoch 126/600\n",
      "336/336 [==============================] - 32s 94ms/step - loss: 0.3859 - accuracy: 0.9487 - val_loss: 0.1737 - val_accuracy: 0.9467\n",
      "Epoch 127/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3582 - accuracy: 0.9528 - val_loss: 0.1596 - val_accuracy: 0.9574\n",
      "Epoch 128/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.4074 - accuracy: 0.9499 - val_loss: 0.2304 - val_accuracy: 0.9387\n",
      "Epoch 129/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.4105 - accuracy: 0.9458 - val_loss: 0.1244 - val_accuracy: 0.9579\n",
      "Epoch 130/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.3696 - accuracy: 0.9534 - val_loss: 0.1508 - val_accuracy: 0.9594\n",
      "Epoch 131/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.4053 - accuracy: 0.9508 - val_loss: 0.1259 - val_accuracy: 0.9651\n",
      "Epoch 132/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.4069 - accuracy: 0.9500 - val_loss: 0.2331 - val_accuracy: 0.9349\n",
      "Epoch 133/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.4015 - accuracy: 0.9503 - val_loss: 0.2294 - val_accuracy: 0.9424\n",
      "Epoch 134/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3657 - accuracy: 0.9538 - val_loss: 0.1317 - val_accuracy: 0.9566\n",
      "Epoch 135/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.3918 - accuracy: 0.9469 - val_loss: 0.1629 - val_accuracy: 0.9557\n",
      "Epoch 136/600\n",
      "336/336 [==============================] - 38s 112ms/step - loss: 0.4076 - accuracy: 0.9486 - val_loss: 0.1235 - val_accuracy: 0.9686\n",
      "Epoch 137/600\n",
      "336/336 [==============================] - 39s 117ms/step - loss: 0.3679 - accuracy: 0.9526 - val_loss: 0.1293 - val_accuracy: 0.9616\n",
      "Epoch 138/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.3965 - accuracy: 0.9505 - val_loss: 0.1138 - val_accuracy: 0.9646\n",
      "Epoch 139/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.3793 - accuracy: 0.9527 - val_loss: 0.1374 - val_accuracy: 0.9596\n",
      "Epoch 140/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.3554 - accuracy: 0.9568 - val_loss: 0.1193 - val_accuracy: 0.9690\n",
      "Epoch 141/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.3697 - accuracy: 0.9546 - val_loss: 0.2124 - val_accuracy: 0.9507\n",
      "Epoch 142/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.3624 - accuracy: 0.9533 - val_loss: 0.2217 - val_accuracy: 0.9253\n",
      "Epoch 143/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.4224 - accuracy: 0.9491 - val_loss: 0.1547 - val_accuracy: 0.9587\n",
      "Epoch 144/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.3832 - accuracy: 0.9502 - val_loss: 0.3622 - val_accuracy: 0.8815\n",
      "Epoch 145/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.3551 - accuracy: 0.9545 - val_loss: 0.1452 - val_accuracy: 0.9618\n",
      "Epoch 146/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.3670 - accuracy: 0.9512 - val_loss: 0.1549 - val_accuracy: 0.9592\n",
      "Epoch 147/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.3676 - accuracy: 0.9554 - val_loss: 0.1520 - val_accuracy: 0.9581\n",
      "Epoch 148/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.3831 - accuracy: 0.9506 - val_loss: 0.1204 - val_accuracy: 0.9646\n",
      "Epoch 149/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.3537 - accuracy: 0.9525 - val_loss: 0.1229 - val_accuracy: 0.9688\n",
      "Epoch 150/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3595 - accuracy: 0.9548 - val_loss: 0.1434 - val_accuracy: 0.9603\n",
      "Epoch 151/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.3692 - accuracy: 0.9532 - val_loss: 0.1637 - val_accuracy: 0.9509\n",
      "Epoch 152/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3635 - accuracy: 0.9554 - val_loss: 0.1335 - val_accuracy: 0.9659\n",
      "Epoch 153/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3457 - accuracy: 0.9555 - val_loss: 0.2852 - val_accuracy: 0.9212\n",
      "Epoch 154/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.3659 - accuracy: 0.9525 - val_loss: 0.1713 - val_accuracy: 0.9555\n",
      "Epoch 155/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.3499 - accuracy: 0.9580 - val_loss: 0.1531 - val_accuracy: 0.9579\n",
      "Epoch 156/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3597 - accuracy: 0.9542 - val_loss: 0.1788 - val_accuracy: 0.9513\n",
      "Epoch 157/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3713 - accuracy: 0.9544 - val_loss: 0.1674 - val_accuracy: 0.9583\n",
      "Epoch 158/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3495 - accuracy: 0.9556 - val_loss: 0.2745 - val_accuracy: 0.9384\n",
      "Epoch 159/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.3450 - accuracy: 0.9557 - val_loss: 0.1799 - val_accuracy: 0.9491\n",
      "Epoch 160/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3363 - accuracy: 0.9568 - val_loss: 0.1394 - val_accuracy: 0.9596\n",
      "Epoch 161/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.3432 - accuracy: 0.9585 - val_loss: 0.1523 - val_accuracy: 0.9592\n",
      "Epoch 162/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3652 - accuracy: 0.9534 - val_loss: 0.1187 - val_accuracy: 0.9651\n",
      "Epoch 163/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2791 - accuracy: 0.9618 - val_loss: 0.1633 - val_accuracy: 0.9539\n",
      "Epoch 164/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3533 - accuracy: 0.9552 - val_loss: 0.1813 - val_accuracy: 0.9474\n",
      "Epoch 165/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3065 - accuracy: 0.9565 - val_loss: 0.1412 - val_accuracy: 0.9646\n",
      "Epoch 166/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3578 - accuracy: 0.9566 - val_loss: 0.2773 - val_accuracy: 0.9249\n",
      "Epoch 167/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3437 - accuracy: 0.9539 - val_loss: 0.3179 - val_accuracy: 0.9249\n",
      "Epoch 168/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3266 - accuracy: 0.9570 - val_loss: 0.1214 - val_accuracy: 0.9697\n",
      "Epoch 169/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.3451 - accuracy: 0.9554 - val_loss: 0.1441 - val_accuracy: 0.9603\n",
      "Epoch 170/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.3987 - accuracy: 0.9493 - val_loss: 0.2874 - val_accuracy: 0.9153\n",
      "Epoch 171/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3509 - accuracy: 0.9530 - val_loss: 0.6802 - val_accuracy: 0.8633\n",
      "Epoch 172/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3176 - accuracy: 0.9582 - val_loss: 0.4204 - val_accuracy: 0.9325\n",
      "Epoch 173/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.2982 - accuracy: 0.9600 - val_loss: 0.1236 - val_accuracy: 0.9673\n",
      "Epoch 174/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.4417 - accuracy: 0.9456 - val_loss: 0.1430 - val_accuracy: 0.9607\n",
      "Epoch 175/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3215 - accuracy: 0.9570 - val_loss: 0.1143 - val_accuracy: 0.9727\n",
      "Epoch 176/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3158 - accuracy: 0.9596 - val_loss: 0.1526 - val_accuracy: 0.9644\n",
      "Epoch 177/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3043 - accuracy: 0.9581 - val_loss: 0.1167 - val_accuracy: 0.9736\n",
      "Epoch 178/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.3095 - accuracy: 0.9603 - val_loss: 0.3756 - val_accuracy: 0.9286\n",
      "Epoch 179/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3259 - accuracy: 0.9582 - val_loss: 0.1205 - val_accuracy: 0.9640\n",
      "Epoch 180/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.3592 - accuracy: 0.9557 - val_loss: 0.2778 - val_accuracy: 0.9450\n",
      "Epoch 181/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.3390 - accuracy: 0.9570 - val_loss: 0.1355 - val_accuracy: 0.9668\n",
      "Epoch 182/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.3102 - accuracy: 0.9599 - val_loss: 0.1231 - val_accuracy: 0.9686\n",
      "Epoch 183/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.3138 - accuracy: 0.9613 - val_loss: 0.1237 - val_accuracy: 0.9673\n",
      "Epoch 184/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.3262 - accuracy: 0.9609 - val_loss: 0.1047 - val_accuracy: 0.9731\n",
      "Epoch 185/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.3246 - accuracy: 0.9613 - val_loss: 0.4254 - val_accuracy: 0.9288\n",
      "Epoch 186/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.3104 - accuracy: 0.9598 - val_loss: 0.1146 - val_accuracy: 0.9690\n",
      "Epoch 187/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.3322 - accuracy: 0.9581 - val_loss: 0.1337 - val_accuracy: 0.9670\n",
      "Epoch 188/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.3294 - accuracy: 0.9598 - val_loss: 0.1250 - val_accuracy: 0.9675\n",
      "Epoch 189/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.2934 - accuracy: 0.9609 - val_loss: 0.1298 - val_accuracy: 0.9657\n",
      "Epoch 190/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3322 - accuracy: 0.9566 - val_loss: 0.1216 - val_accuracy: 0.9712\n",
      "Epoch 191/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.2946 - accuracy: 0.9629 - val_loss: 0.3567 - val_accuracy: 0.9432\n",
      "Epoch 192/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.2786 - accuracy: 0.9652 - val_loss: 0.1225 - val_accuracy: 0.9670\n",
      "Epoch 193/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.2994 - accuracy: 0.9616 - val_loss: 0.1308 - val_accuracy: 0.9673\n",
      "Epoch 194/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.3172 - accuracy: 0.9582 - val_loss: 0.1230 - val_accuracy: 0.9703\n",
      "Epoch 195/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.3217 - accuracy: 0.9593 - val_loss: 0.1090 - val_accuracy: 0.9716\n",
      "Epoch 196/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.2897 - accuracy: 0.9636 - val_loss: 0.2333 - val_accuracy: 0.9461\n",
      "Epoch 197/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.2685 - accuracy: 0.9638 - val_loss: 0.1324 - val_accuracy: 0.9688\n",
      "Epoch 198/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.3016 - accuracy: 0.9610 - val_loss: 0.1723 - val_accuracy: 0.9581\n",
      "Epoch 199/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.3150 - accuracy: 0.9586 - val_loss: 0.1495 - val_accuracy: 0.9633\n",
      "Epoch 200/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.3015 - accuracy: 0.9608 - val_loss: 0.1229 - val_accuracy: 0.9718\n",
      "Epoch 201/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.3098 - accuracy: 0.9592 - val_loss: 0.1725 - val_accuracy: 0.9546\n",
      "Epoch 202/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.2879 - accuracy: 0.9613 - val_loss: 0.1506 - val_accuracy: 0.9622\n",
      "Epoch 203/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.2739 - accuracy: 0.9646 - val_loss: 0.1056 - val_accuracy: 0.9721\n",
      "Epoch 204/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.2945 - accuracy: 0.9622 - val_loss: 0.2223 - val_accuracy: 0.9514\n",
      "Epoch 205/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.2949 - accuracy: 0.9632 - val_loss: 0.1334 - val_accuracy: 0.9723\n",
      "Epoch 206/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.3025 - accuracy: 0.9604 - val_loss: 0.1705 - val_accuracy: 0.9594\n",
      "Epoch 207/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.2820 - accuracy: 0.9631 - val_loss: 0.3067 - val_accuracy: 0.9518\n",
      "Epoch 208/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.2840 - accuracy: 0.9642 - val_loss: 0.1361 - val_accuracy: 0.9668\n",
      "Epoch 209/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2710 - accuracy: 0.9639 - val_loss: 0.1232 - val_accuracy: 0.9690\n",
      "Epoch 210/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2821 - accuracy: 0.9647 - val_loss: 0.1375 - val_accuracy: 0.9653\n",
      "Epoch 211/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2908 - accuracy: 0.9639 - val_loss: 0.1621 - val_accuracy: 0.9631\n",
      "Epoch 212/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.2996 - accuracy: 0.9633 - val_loss: 0.1535 - val_accuracy: 0.9614\n",
      "Epoch 213/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.2959 - accuracy: 0.9627 - val_loss: 0.1162 - val_accuracy: 0.9662\n",
      "Epoch 214/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.2866 - accuracy: 0.9639 - val_loss: 0.1048 - val_accuracy: 0.9742\n",
      "Epoch 215/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.2702 - accuracy: 0.9640 - val_loss: 0.4064 - val_accuracy: 0.9378\n",
      "Epoch 216/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2760 - accuracy: 0.9652 - val_loss: 0.1129 - val_accuracy: 0.9762\n",
      "Epoch 217/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.2871 - accuracy: 0.9644 - val_loss: 0.1064 - val_accuracy: 0.9703\n",
      "Epoch 218/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.2696 - accuracy: 0.9638 - val_loss: 0.1734 - val_accuracy: 0.9596\n",
      "Epoch 219/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.2966 - accuracy: 0.9634 - val_loss: 0.1345 - val_accuracy: 0.9699\n",
      "Epoch 220/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.2810 - accuracy: 0.9644 - val_loss: 0.1202 - val_accuracy: 0.9721\n",
      "Epoch 221/600\n",
      "336/336 [==============================] - 35s 106ms/step - loss: 0.2722 - accuracy: 0.9647 - val_loss: 0.1142 - val_accuracy: 0.9718\n",
      "Epoch 222/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 37s 110ms/step - loss: 0.2866 - accuracy: 0.9627 - val_loss: 0.1213 - val_accuracy: 0.9729\n",
      "Epoch 223/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.2655 - accuracy: 0.9670 - val_loss: 0.1716 - val_accuracy: 0.9657\n",
      "Epoch 224/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.2614 - accuracy: 0.9660 - val_loss: 0.1174 - val_accuracy: 0.9766\n",
      "Epoch 225/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.2946 - accuracy: 0.9628 - val_loss: 0.1143 - val_accuracy: 0.9712\n",
      "Epoch 226/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.2695 - accuracy: 0.9652 - val_loss: 0.1477 - val_accuracy: 0.9655\n",
      "Epoch 227/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.2753 - accuracy: 0.9661 - val_loss: 0.1307 - val_accuracy: 0.9729\n",
      "Epoch 228/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.2624 - accuracy: 0.9654 - val_loss: 0.1280 - val_accuracy: 0.9679\n",
      "Epoch 229/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.2407 - accuracy: 0.9685 - val_loss: 0.2858 - val_accuracy: 0.9437\n",
      "Epoch 230/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.2607 - accuracy: 0.9681 - val_loss: 0.1286 - val_accuracy: 0.9681\n",
      "Epoch 231/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.2894 - accuracy: 0.9646 - val_loss: 0.1239 - val_accuracy: 0.9714\n",
      "Epoch 232/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.2679 - accuracy: 0.9666 - val_loss: 0.2555 - val_accuracy: 0.9467\n",
      "Epoch 233/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.2555 - accuracy: 0.9666 - val_loss: 0.1367 - val_accuracy: 0.9661\n",
      "Epoch 234/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.2780 - accuracy: 0.9643 - val_loss: 0.1176 - val_accuracy: 0.9718\n",
      "Epoch 235/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.2811 - accuracy: 0.9640 - val_loss: 0.1963 - val_accuracy: 0.9531\n",
      "Epoch 236/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.2583 - accuracy: 0.9656 - val_loss: 0.1522 - val_accuracy: 0.9585\n",
      "Epoch 237/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.2740 - accuracy: 0.9660 - val_loss: 0.1264 - val_accuracy: 0.9697\n",
      "Epoch 238/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.2839 - accuracy: 0.9633 - val_loss: 0.1922 - val_accuracy: 0.9561\n",
      "Epoch 239/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2541 - accuracy: 0.9646 - val_loss: 0.3710 - val_accuracy: 0.9398\n",
      "Epoch 240/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.2545 - accuracy: 0.9671 - val_loss: 0.1311 - val_accuracy: 0.9688\n",
      "Epoch 241/600\n",
      "336/336 [==============================] - 32s 94ms/step - loss: 0.2356 - accuracy: 0.9693 - val_loss: 0.1476 - val_accuracy: 0.9605\n",
      "Epoch 242/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.2855 - accuracy: 0.9642 - val_loss: 0.1112 - val_accuracy: 0.9721\n",
      "Epoch 243/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2416 - accuracy: 0.9683 - val_loss: 0.1068 - val_accuracy: 0.9725\n",
      "Epoch 244/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.2563 - accuracy: 0.9671 - val_loss: 0.1162 - val_accuracy: 0.9738\n",
      "Epoch 245/600\n",
      "336/336 [==============================] - 31s 93ms/step - loss: 0.2677 - accuracy: 0.9648 - val_loss: 0.2074 - val_accuracy: 0.9504\n",
      "Epoch 246/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2620 - accuracy: 0.9664 - val_loss: 0.1133 - val_accuracy: 0.9756\n",
      "Epoch 247/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2482 - accuracy: 0.9693 - val_loss: 0.3300 - val_accuracy: 0.9406\n",
      "Epoch 248/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.2503 - accuracy: 0.9664 - val_loss: 0.1159 - val_accuracy: 0.9745\n",
      "Epoch 249/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2141 - accuracy: 0.9718 - val_loss: 0.2531 - val_accuracy: 0.9522\n",
      "Epoch 250/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.2449 - accuracy: 0.9660 - val_loss: 0.0971 - val_accuracy: 0.9786\n",
      "Epoch 251/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.2669 - accuracy: 0.9666 - val_loss: 0.1092 - val_accuracy: 0.9725\n",
      "Epoch 252/600\n",
      "336/336 [==============================] - 32s 94ms/step - loss: 0.2548 - accuracy: 0.9686 - val_loss: 0.1147 - val_accuracy: 0.9727\n",
      "Epoch 253/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.2349 - accuracy: 0.9708 - val_loss: 0.1168 - val_accuracy: 0.9740\n",
      "Epoch 254/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.2542 - accuracy: 0.9664 - val_loss: 0.1184 - val_accuracy: 0.9723\n",
      "Epoch 255/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.2451 - accuracy: 0.9664 - val_loss: 0.1313 - val_accuracy: 0.9675\n",
      "Epoch 256/600\n",
      "336/336 [==============================] - 44s 132ms/step - loss: 0.2394 - accuracy: 0.9677 - val_loss: 0.3015 - val_accuracy: 0.9496\n",
      "Epoch 257/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.2289 - accuracy: 0.9699 - val_loss: 0.5515 - val_accuracy: 0.9267\n",
      "Epoch 258/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.2292 - accuracy: 0.9702 - val_loss: 0.1854 - val_accuracy: 0.9496\n",
      "Epoch 259/600\n",
      "336/336 [==============================] - 38s 113ms/step - loss: 0.2302 - accuracy: 0.9705 - val_loss: 0.2443 - val_accuracy: 0.9563\n",
      "Epoch 260/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.2438 - accuracy: 0.9699 - val_loss: 0.1129 - val_accuracy: 0.9751\n",
      "Epoch 261/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.2381 - accuracy: 0.9686 - val_loss: 0.1314 - val_accuracy: 0.9699\n",
      "Epoch 262/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.2497 - accuracy: 0.9666 - val_loss: 0.5386 - val_accuracy: 0.9117\n",
      "Epoch 263/600\n",
      "336/336 [==============================] - 45s 133ms/step - loss: 0.2450 - accuracy: 0.9686 - val_loss: 0.1165 - val_accuracy: 0.9716\n",
      "Epoch 264/600\n",
      "336/336 [==============================] - 41s 122ms/step - loss: 0.2575 - accuracy: 0.9655 - val_loss: 0.1810 - val_accuracy: 0.9609\n",
      "Epoch 265/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.2282 - accuracy: 0.9693 - val_loss: 0.1266 - val_accuracy: 0.9710\n",
      "Epoch 266/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.2319 - accuracy: 0.9689 - val_loss: 0.1547 - val_accuracy: 0.9710\n",
      "Epoch 267/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.2390 - accuracy: 0.9692 - val_loss: 0.1297 - val_accuracy: 0.9688\n",
      "Epoch 268/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.2242 - accuracy: 0.9730 - val_loss: 0.1990 - val_accuracy: 0.9579\n",
      "Epoch 269/600\n",
      "336/336 [==============================] - 34s 103ms/step - loss: 0.2247 - accuracy: 0.9689 - val_loss: 0.1371 - val_accuracy: 0.9703\n",
      "Epoch 270/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.2483 - accuracy: 0.9706 - val_loss: 0.2016 - val_accuracy: 0.9605\n",
      "Epoch 271/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.2202 - accuracy: 0.9711 - val_loss: 0.1249 - val_accuracy: 0.9694\n",
      "Epoch 272/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.2244 - accuracy: 0.9692 - val_loss: 0.2901 - val_accuracy: 0.9533\n",
      "Epoch 273/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.2351 - accuracy: 0.9683 - val_loss: 0.1281 - val_accuracy: 0.9716\n",
      "Epoch 274/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.2222 - accuracy: 0.9716 - val_loss: 0.1240 - val_accuracy: 0.9697\n",
      "Epoch 275/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.2315 - accuracy: 0.9693 - val_loss: 0.1641 - val_accuracy: 0.9659\n",
      "Epoch 276/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.2428 - accuracy: 0.9671 - val_loss: 0.1875 - val_accuracy: 0.9598\n",
      "Epoch 277/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 34s 102ms/step - loss: 0.2230 - accuracy: 0.9699 - val_loss: 0.1262 - val_accuracy: 0.9718\n",
      "Epoch 278/600\n",
      "336/336 [==============================] - 38s 114ms/step - loss: 0.2043 - accuracy: 0.9728 - val_loss: 0.1429 - val_accuracy: 0.9677\n",
      "Epoch 279/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.2354 - accuracy: 0.9697 - val_loss: 0.1228 - val_accuracy: 0.9705\n",
      "Epoch 280/600\n",
      "336/336 [==============================] - 38s 115ms/step - loss: 0.2539 - accuracy: 0.9699 - val_loss: 0.1389 - val_accuracy: 0.9668\n",
      "Epoch 281/600\n",
      "336/336 [==============================] - 42s 126ms/step - loss: 0.2231 - accuracy: 0.9680 - val_loss: 0.1040 - val_accuracy: 0.9764\n",
      "Epoch 282/600\n",
      "336/336 [==============================] - 36s 109ms/step - loss: 0.2283 - accuracy: 0.9725 - val_loss: 0.1016 - val_accuracy: 0.9745\n",
      "Epoch 283/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.2278 - accuracy: 0.9714 - val_loss: 0.1180 - val_accuracy: 0.9749\n",
      "Epoch 284/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.2118 - accuracy: 0.9729 - val_loss: 0.1003 - val_accuracy: 0.9721\n",
      "Epoch 285/600\n",
      "336/336 [==============================] - 39s 115ms/step - loss: 0.2112 - accuracy: 0.9732 - val_loss: 0.3337 - val_accuracy: 0.9483\n",
      "Epoch 286/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.2441 - accuracy: 0.9688 - val_loss: 0.0965 - val_accuracy: 0.9751\n",
      "Epoch 287/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.2209 - accuracy: 0.9716 - val_loss: 0.1120 - val_accuracy: 0.9729\n",
      "Epoch 288/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.2111 - accuracy: 0.9711 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 289/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.2313 - accuracy: 0.9726 - val_loss: 0.1363 - val_accuracy: 0.9701\n",
      "Epoch 290/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.2174 - accuracy: 0.9713 - val_loss: 0.1352 - val_accuracy: 0.9705\n",
      "Epoch 291/600\n",
      "336/336 [==============================] - 38s 113ms/step - loss: 0.2061 - accuracy: 0.9737 - val_loss: 0.3155 - val_accuracy: 0.9510\n",
      "Epoch 292/600\n",
      "336/336 [==============================] - 49s 147ms/step - loss: 0.2348 - accuracy: 0.9719 - val_loss: 0.1256 - val_accuracy: 0.9723\n",
      "Epoch 293/600\n",
      "336/336 [==============================] - 49s 145ms/step - loss: 0.2194 - accuracy: 0.9710 - val_loss: 0.2105 - val_accuracy: 0.9603\n",
      "Epoch 294/600\n",
      "336/336 [==============================] - 43s 128ms/step - loss: 0.2338 - accuracy: 0.9701 - val_loss: 0.0907 - val_accuracy: 0.9808\n",
      "Epoch 295/600\n",
      "336/336 [==============================] - 44s 132ms/step - loss: 0.2192 - accuracy: 0.9743 - val_loss: 0.1039 - val_accuracy: 0.9747\n",
      "Epoch 296/600\n",
      "336/336 [==============================] - 41s 123ms/step - loss: 0.2094 - accuracy: 0.9726 - val_loss: 0.1049 - val_accuracy: 0.9771\n",
      "Epoch 297/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.2052 - accuracy: 0.9726 - val_loss: 0.1303 - val_accuracy: 0.9736\n",
      "Epoch 298/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.2160 - accuracy: 0.9718 - val_loss: 0.2482 - val_accuracy: 0.9550\n",
      "Epoch 299/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.2031 - accuracy: 0.9741 - val_loss: 0.1701 - val_accuracy: 0.9629\n",
      "Epoch 300/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.2276 - accuracy: 0.9707 - val_loss: 0.2138 - val_accuracy: 0.9601\n",
      "Epoch 301/600\n",
      "336/336 [==============================] - 31s 94ms/step - loss: 0.1981 - accuracy: 0.9730 - val_loss: 0.1115 - val_accuracy: 0.9714\n",
      "Epoch 302/600\n",
      "336/336 [==============================] - 31s 93ms/step - loss: 0.2096 - accuracy: 0.9711 - val_loss: 0.1028 - val_accuracy: 0.9758\n",
      "Epoch 303/600\n",
      "336/336 [==============================] - 32s 94ms/step - loss: 0.1923 - accuracy: 0.9733 - val_loss: 0.1738 - val_accuracy: 0.9618\n",
      "Epoch 304/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.2218 - accuracy: 0.9730 - val_loss: 0.1122 - val_accuracy: 0.9705\n",
      "Epoch 305/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.2008 - accuracy: 0.9746 - val_loss: 0.2106 - val_accuracy: 0.9592\n",
      "Epoch 306/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.2023 - accuracy: 0.9747 - val_loss: 0.0982 - val_accuracy: 0.9797\n",
      "Epoch 307/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1897 - accuracy: 0.9756 - val_loss: 0.1182 - val_accuracy: 0.9740\n",
      "Epoch 308/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1924 - accuracy: 0.9745 - val_loss: 0.1432 - val_accuracy: 0.9649\n",
      "Epoch 309/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.2290 - accuracy: 0.9706 - val_loss: 0.1261 - val_accuracy: 0.9714\n",
      "Epoch 310/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.1820 - accuracy: 0.9749 - val_loss: 0.1517 - val_accuracy: 0.9644\n",
      "Epoch 311/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.2130 - accuracy: 0.9745 - val_loss: 0.1079 - val_accuracy: 0.9749\n",
      "Epoch 312/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.2210 - accuracy: 0.9724 - val_loss: 0.2901 - val_accuracy: 0.9577\n",
      "Epoch 313/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.2092 - accuracy: 0.9735 - val_loss: 0.1119 - val_accuracy: 0.9771\n",
      "Epoch 314/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.1982 - accuracy: 0.9744 - val_loss: 0.1625 - val_accuracy: 0.9659\n",
      "Epoch 315/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.2288 - accuracy: 0.9719 - val_loss: 0.1276 - val_accuracy: 0.9692\n",
      "Epoch 316/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.1895 - accuracy: 0.9747 - val_loss: 0.2470 - val_accuracy: 0.9557\n",
      "Epoch 317/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1906 - accuracy: 0.9736 - val_loss: 0.2390 - val_accuracy: 0.9533\n",
      "Epoch 318/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1998 - accuracy: 0.9750 - val_loss: 0.1251 - val_accuracy: 0.9699\n",
      "Epoch 319/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.2023 - accuracy: 0.9726 - val_loss: 0.1109 - val_accuracy: 0.9769\n",
      "Epoch 320/600\n",
      "336/336 [==============================] - 43s 129ms/step - loss: 0.2034 - accuracy: 0.9742 - val_loss: 0.1103 - val_accuracy: 0.9753\n",
      "Epoch 321/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.2161 - accuracy: 0.9736 - val_loss: 0.1357 - val_accuracy: 0.9705\n",
      "Epoch 322/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1866 - accuracy: 0.9758 - val_loss: 0.1037 - val_accuracy: 0.9766\n",
      "Epoch 323/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1854 - accuracy: 0.9758 - val_loss: 0.1191 - val_accuracy: 0.9749\n",
      "Epoch 324/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1970 - accuracy: 0.9744 - val_loss: 0.3404 - val_accuracy: 0.9443\n",
      "Epoch 325/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1901 - accuracy: 0.9753 - val_loss: 0.1235 - val_accuracy: 0.9745\n",
      "Epoch 326/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1925 - accuracy: 0.9747 - val_loss: 0.1244 - val_accuracy: 0.9756\n",
      "Epoch 327/600\n",
      "336/336 [==============================] - 39s 116ms/step - loss: 0.1913 - accuracy: 0.9744 - val_loss: 0.1004 - val_accuracy: 0.9777\n",
      "Epoch 328/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1936 - accuracy: 0.9748 - val_loss: 0.1152 - val_accuracy: 0.9738\n",
      "Epoch 329/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1996 - accuracy: 0.9749 - val_loss: 0.1057 - val_accuracy: 0.9773\n",
      "Epoch 330/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.2167 - accuracy: 0.9728 - val_loss: 0.0994 - val_accuracy: 0.9766\n",
      "Epoch 331/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1996 - accuracy: 0.9751 - val_loss: 0.1026 - val_accuracy: 0.9756\n",
      "Epoch 332/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 37s 109ms/step - loss: 0.2278 - accuracy: 0.9713 - val_loss: 0.1190 - val_accuracy: 0.9712\n",
      "Epoch 333/600\n",
      "336/336 [==============================] - 35s 106ms/step - loss: 0.2105 - accuracy: 0.9715 - val_loss: 0.1158 - val_accuracy: 0.9747\n",
      "Epoch 334/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1967 - accuracy: 0.9748 - val_loss: 0.2121 - val_accuracy: 0.9622\n",
      "Epoch 335/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.2068 - accuracy: 0.9737 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
      "Epoch 336/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1769 - accuracy: 0.9764 - val_loss: 0.1226 - val_accuracy: 0.9749\n",
      "Epoch 337/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1957 - accuracy: 0.9744 - val_loss: 0.1158 - val_accuracy: 0.9729\n",
      "Epoch 338/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1923 - accuracy: 0.9741 - val_loss: 0.0966 - val_accuracy: 0.9786\n",
      "Epoch 339/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1799 - accuracy: 0.9757 - val_loss: 0.1644 - val_accuracy: 0.9649\n",
      "Epoch 340/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1970 - accuracy: 0.9727 - val_loss: 0.1248 - val_accuracy: 0.9710\n",
      "Epoch 341/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.1937 - accuracy: 0.9750 - val_loss: 0.1324 - val_accuracy: 0.9727\n",
      "Epoch 342/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.1809 - accuracy: 0.9782 - val_loss: 0.1084 - val_accuracy: 0.9769\n",
      "Epoch 343/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1646 - accuracy: 0.9774 - val_loss: 0.0991 - val_accuracy: 0.9784\n",
      "Epoch 344/600\n",
      "336/336 [==============================] - 34s 103ms/step - loss: 0.1613 - accuracy: 0.9776 - val_loss: 0.1202 - val_accuracy: 0.9745\n",
      "Epoch 345/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1844 - accuracy: 0.9761 - val_loss: 0.1987 - val_accuracy: 0.9577\n",
      "Epoch 346/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.1830 - accuracy: 0.9760 - val_loss: 0.0919 - val_accuracy: 0.9795\n",
      "Epoch 347/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.2066 - accuracy: 0.9738 - val_loss: 0.1325 - val_accuracy: 0.9707\n",
      "Epoch 348/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1574 - accuracy: 0.9784 - val_loss: 0.0982 - val_accuracy: 0.9806\n",
      "Epoch 349/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.1815 - accuracy: 0.9759 - val_loss: 0.1079 - val_accuracy: 0.9776\n",
      "Epoch 350/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.2151 - accuracy: 0.9740 - val_loss: 0.1308 - val_accuracy: 0.9731\n",
      "Epoch 351/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1923 - accuracy: 0.9737 - val_loss: 0.0890 - val_accuracy: 0.9810\n",
      "Epoch 352/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1972 - accuracy: 0.9752 - val_loss: 0.1099 - val_accuracy: 0.9756\n",
      "Epoch 353/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1532 - accuracy: 0.9784 - val_loss: 1.0585 - val_accuracy: 0.8551\n",
      "Epoch 354/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1889 - accuracy: 0.9760 - val_loss: 0.1103 - val_accuracy: 0.9762\n",
      "Epoch 355/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1985 - accuracy: 0.9756 - val_loss: 0.0939 - val_accuracy: 0.9782\n",
      "Epoch 356/600\n",
      "336/336 [==============================] - 34s 103ms/step - loss: 0.1784 - accuracy: 0.9782 - val_loss: 0.1191 - val_accuracy: 0.9753\n",
      "Epoch 357/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1927 - accuracy: 0.9746 - val_loss: 0.1888 - val_accuracy: 0.9620\n",
      "Epoch 358/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1562 - accuracy: 0.9806 - val_loss: 0.1261 - val_accuracy: 0.9749\n",
      "Epoch 359/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1922 - accuracy: 0.9761 - val_loss: 0.1198 - val_accuracy: 0.9742\n",
      "Epoch 360/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1794 - accuracy: 0.9774 - val_loss: 0.0932 - val_accuracy: 0.9804\n",
      "Epoch 361/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1679 - accuracy: 0.9764 - val_loss: 0.0961 - val_accuracy: 0.9784\n",
      "Epoch 362/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1609 - accuracy: 0.9802 - val_loss: 0.1009 - val_accuracy: 0.9793\n",
      "Epoch 363/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1695 - accuracy: 0.9777 - val_loss: 0.1038 - val_accuracy: 0.9762\n",
      "Epoch 364/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1890 - accuracy: 0.9764 - val_loss: 0.1091 - val_accuracy: 0.9725\n",
      "Epoch 365/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.1601 - accuracy: 0.9783 - val_loss: 0.1060 - val_accuracy: 0.9780\n",
      "Epoch 366/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.1714 - accuracy: 0.9779 - val_loss: 0.1061 - val_accuracy: 0.9762\n",
      "Epoch 367/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1964 - accuracy: 0.9760 - val_loss: 0.1303 - val_accuracy: 0.9707\n",
      "Epoch 368/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.1836 - accuracy: 0.9763 - val_loss: 0.1025 - val_accuracy: 0.9782\n",
      "Epoch 369/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.1853 - accuracy: 0.9763 - val_loss: 0.1097 - val_accuracy: 0.9738\n",
      "Epoch 370/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.1654 - accuracy: 0.9790 - val_loss: 0.1314 - val_accuracy: 0.9692\n",
      "Epoch 371/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1652 - accuracy: 0.9768 - val_loss: 0.4078 - val_accuracy: 0.9349\n",
      "Epoch 372/600\n",
      "336/336 [==============================] - 32s 94ms/step - loss: 0.1513 - accuracy: 0.9794 - val_loss: 0.1480 - val_accuracy: 0.9664\n",
      "Epoch 373/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1623 - accuracy: 0.9778 - val_loss: 0.1118 - val_accuracy: 0.9753\n",
      "Epoch 374/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.1684 - accuracy: 0.9780 - val_loss: 0.1306 - val_accuracy: 0.9712\n",
      "Epoch 375/600\n",
      "336/336 [==============================] - 38s 113ms/step - loss: 0.1594 - accuracy: 0.9793 - val_loss: 0.1327 - val_accuracy: 0.9690\n",
      "Epoch 376/600\n",
      "336/336 [==============================] - 48s 143ms/step - loss: 0.1690 - accuracy: 0.9769 - val_loss: 0.1160 - val_accuracy: 0.9725\n",
      "Epoch 377/600\n",
      "336/336 [==============================] - 43s 127ms/step - loss: 0.1595 - accuracy: 0.9788 - val_loss: 0.1070 - val_accuracy: 0.9788\n",
      "Epoch 378/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1717 - accuracy: 0.9769 - val_loss: 0.0978 - val_accuracy: 0.9794\n",
      "Epoch 379/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.1623 - accuracy: 0.9771 - val_loss: 0.1094 - val_accuracy: 0.9780\n",
      "Epoch 380/600\n",
      "336/336 [==============================] - 38s 112ms/step - loss: 0.1623 - accuracy: 0.9794 - val_loss: 0.1194 - val_accuracy: 0.9758\n",
      "Epoch 381/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.1850 - accuracy: 0.9767 - val_loss: 0.1301 - val_accuracy: 0.9694\n",
      "Epoch 382/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.1644 - accuracy: 0.9766 - val_loss: 0.1449 - val_accuracy: 0.9690\n",
      "Epoch 383/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1530 - accuracy: 0.9802 - val_loss: 0.1203 - val_accuracy: 0.9734\n",
      "Epoch 384/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.1458 - accuracy: 0.9813 - val_loss: 0.1072 - val_accuracy: 0.9788\n",
      "Epoch 385/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.1586 - accuracy: 0.9792 - val_loss: 0.1179 - val_accuracy: 0.9751\n",
      "Epoch 386/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.1461 - accuracy: 0.9823 - val_loss: 0.0927 - val_accuracy: 0.9804\n",
      "Epoch 387/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 33s 97ms/step - loss: 0.1468 - accuracy: 0.9791 - val_loss: 0.1225 - val_accuracy: 0.9747\n",
      "Epoch 388/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.1583 - accuracy: 0.9783 - val_loss: 0.1043 - val_accuracy: 0.9771\n",
      "Epoch 389/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.1471 - accuracy: 0.9802 - val_loss: 0.1045 - val_accuracy: 0.9769\n",
      "Epoch 390/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.1553 - accuracy: 0.9791 - val_loss: 0.1193 - val_accuracy: 0.9760\n",
      "Epoch 391/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1512 - accuracy: 0.9787 - val_loss: 0.1270 - val_accuracy: 0.9760\n",
      "Epoch 392/600\n",
      "336/336 [==============================] - 33s 100ms/step - loss: 0.1493 - accuracy: 0.9795 - val_loss: 0.1260 - val_accuracy: 0.9740\n",
      "Epoch 393/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.1627 - accuracy: 0.9789 - val_loss: 0.1071 - val_accuracy: 0.9795\n",
      "Epoch 394/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.1543 - accuracy: 0.9793 - val_loss: 0.1028 - val_accuracy: 0.9797\n",
      "Epoch 395/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1707 - accuracy: 0.9786 - val_loss: 0.1014 - val_accuracy: 0.9799\n",
      "Epoch 396/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1392 - accuracy: 0.9815 - val_loss: 0.1207 - val_accuracy: 0.9707\n",
      "Epoch 397/600\n",
      "336/336 [==============================] - 38s 113ms/step - loss: 0.1581 - accuracy: 0.9796 - val_loss: 0.1045 - val_accuracy: 0.9810\n",
      "Epoch 398/600\n",
      "336/336 [==============================] - 38s 113ms/step - loss: 0.1483 - accuracy: 0.9806 - val_loss: 0.1140 - val_accuracy: 0.9782\n",
      "Epoch 399/600\n",
      "336/336 [==============================] - 39s 117ms/step - loss: 0.1567 - accuracy: 0.9809 - val_loss: 0.1107 - val_accuracy: 0.9782\n",
      "Epoch 400/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.1467 - accuracy: 0.9814 - val_loss: 0.1196 - val_accuracy: 0.9762\n",
      "Epoch 401/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1680 - accuracy: 0.9784 - val_loss: 0.1555 - val_accuracy: 0.9721\n",
      "Epoch 402/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1596 - accuracy: 0.9793 - val_loss: 0.1181 - val_accuracy: 0.9795\n",
      "Epoch 403/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1496 - accuracy: 0.9801 - val_loss: 0.1007 - val_accuracy: 0.9812\n",
      "Epoch 404/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1516 - accuracy: 0.9790 - val_loss: 0.1048 - val_accuracy: 0.9795\n",
      "Epoch 405/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.1251 - accuracy: 0.9834 - val_loss: 0.1811 - val_accuracy: 0.9686\n",
      "Epoch 406/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1684 - accuracy: 0.9778 - val_loss: 0.1136 - val_accuracy: 0.9745\n",
      "Epoch 407/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.1421 - accuracy: 0.9812 - val_loss: 0.0991 - val_accuracy: 0.9805\n",
      "Epoch 408/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1429 - accuracy: 0.9813 - val_loss: 0.1908 - val_accuracy: 0.9662\n",
      "Epoch 409/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1394 - accuracy: 0.9816 - val_loss: 0.1459 - val_accuracy: 0.9742\n",
      "Epoch 410/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1345 - accuracy: 0.9813 - val_loss: 0.1205 - val_accuracy: 0.9740\n",
      "Epoch 411/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.1476 - accuracy: 0.9805 - val_loss: 0.1306 - val_accuracy: 0.9734\n",
      "Epoch 412/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1529 - accuracy: 0.9819 - val_loss: 0.1189 - val_accuracy: 0.9769\n",
      "Epoch 413/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1528 - accuracy: 0.9817 - val_loss: 0.1957 - val_accuracy: 0.9633\n",
      "Epoch 414/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.1509 - accuracy: 0.9802 - val_loss: 0.1149 - val_accuracy: 0.9758\n",
      "Epoch 415/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.1466 - accuracy: 0.9807 - val_loss: 0.1252 - val_accuracy: 0.9751\n",
      "Epoch 416/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1463 - accuracy: 0.9818 - val_loss: 0.1083 - val_accuracy: 0.9756\n",
      "Epoch 417/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.1360 - accuracy: 0.9815 - val_loss: 0.1127 - val_accuracy: 0.9734\n",
      "Epoch 418/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.1578 - accuracy: 0.9799 - val_loss: 0.1070 - val_accuracy: 0.9771\n",
      "Epoch 419/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.1307 - accuracy: 0.9815 - val_loss: 0.1262 - val_accuracy: 0.9740\n",
      "Epoch 420/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1496 - accuracy: 0.9801 - val_loss: 0.1288 - val_accuracy: 0.9736\n",
      "Epoch 421/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1422 - accuracy: 0.9807 - val_loss: 0.1443 - val_accuracy: 0.9707\n",
      "Epoch 422/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.1346 - accuracy: 0.9823 - val_loss: 0.1664 - val_accuracy: 0.9710\n",
      "Epoch 423/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.1508 - accuracy: 0.9815 - val_loss: 0.1123 - val_accuracy: 0.9764\n",
      "Epoch 424/600\n",
      "336/336 [==============================] - 32s 94ms/step - loss: 0.1520 - accuracy: 0.9807 - val_loss: 0.1196 - val_accuracy: 0.9762\n",
      "Epoch 425/600\n",
      "336/336 [==============================] - 31s 93ms/step - loss: 0.1377 - accuracy: 0.9807 - val_loss: 0.1081 - val_accuracy: 0.9784\n",
      "Epoch 426/600\n",
      "336/336 [==============================] - 31s 93ms/step - loss: 0.1306 - accuracy: 0.9821 - val_loss: 0.0984 - val_accuracy: 0.9793\n",
      "Epoch 427/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.1440 - accuracy: 0.9790 - val_loss: 0.1061 - val_accuracy: 0.9773\n",
      "Epoch 428/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1335 - accuracy: 0.9818 - val_loss: 0.1070 - val_accuracy: 0.9795\n",
      "Epoch 429/600\n",
      "336/336 [==============================] - 40s 118ms/step - loss: 0.1395 - accuracy: 0.9810 - val_loss: 0.1105 - val_accuracy: 0.9780\n",
      "Epoch 430/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.1281 - accuracy: 0.9816 - val_loss: 0.1139 - val_accuracy: 0.9762\n",
      "Epoch 431/600\n",
      "336/336 [==============================] - 38s 112ms/step - loss: 0.1261 - accuracy: 0.9810 - val_loss: 0.1603 - val_accuracy: 0.9644\n",
      "Epoch 432/600\n",
      "336/336 [==============================] - 48s 143ms/step - loss: 0.1298 - accuracy: 0.9834 - val_loss: 0.1126 - val_accuracy: 0.9740\n",
      "Epoch 433/600\n",
      "336/336 [==============================] - 39s 117ms/step - loss: 0.1269 - accuracy: 0.9834 - val_loss: 0.1131 - val_accuracy: 0.9769\n",
      "Epoch 434/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.1296 - accuracy: 0.9834 - val_loss: 0.1074 - val_accuracy: 0.9780\n",
      "Epoch 435/600\n",
      "336/336 [==============================] - 41s 122ms/step - loss: 0.1319 - accuracy: 0.9810 - val_loss: 0.1129 - val_accuracy: 0.9775\n",
      "Epoch 436/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1222 - accuracy: 0.9830 - val_loss: 0.1030 - val_accuracy: 0.9811\n",
      "Epoch 437/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1297 - accuracy: 0.9826 - val_loss: 0.1120 - val_accuracy: 0.9766\n",
      "Epoch 438/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.1332 - accuracy: 0.9821 - val_loss: 0.1289 - val_accuracy: 0.9740\n",
      "Epoch 439/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1346 - accuracy: 0.9824 - val_loss: 0.1012 - val_accuracy: 0.9810\n",
      "Epoch 440/600\n",
      "336/336 [==============================] - 38s 114ms/step - loss: 0.1232 - accuracy: 0.9835 - val_loss: 0.1069 - val_accuracy: 0.9786\n",
      "Epoch 441/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.1385 - accuracy: 0.9843 - val_loss: 0.1197 - val_accuracy: 0.9769\n",
      "Epoch 442/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 37s 109ms/step - loss: 0.1417 - accuracy: 0.9807 - val_loss: 0.1225 - val_accuracy: 0.9736\n",
      "Epoch 443/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.1267 - accuracy: 0.9837 - val_loss: 0.1023 - val_accuracy: 0.9797\n",
      "Epoch 444/600\n",
      "336/336 [==============================] - 45s 134ms/step - loss: 0.1170 - accuracy: 0.9837 - val_loss: 0.1286 - val_accuracy: 0.9753\n",
      "Epoch 445/600\n",
      "336/336 [==============================] - 47s 140ms/step - loss: 0.1383 - accuracy: 0.9835 - val_loss: 0.1184 - val_accuracy: 0.9788\n",
      "Epoch 446/600\n",
      "336/336 [==============================] - 40s 118ms/step - loss: 0.1215 - accuracy: 0.9834 - val_loss: 0.1052 - val_accuracy: 0.9806\n",
      "Epoch 447/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.1265 - accuracy: 0.9828 - val_loss: 0.1015 - val_accuracy: 0.9795\n",
      "Epoch 448/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.1088 - accuracy: 0.9850 - val_loss: 0.1016 - val_accuracy: 0.9808\n",
      "Epoch 449/600\n",
      "336/336 [==============================] - 38s 114ms/step - loss: 0.1312 - accuracy: 0.9857 - val_loss: 0.1096 - val_accuracy: 0.9775\n",
      "Epoch 450/600\n",
      "336/336 [==============================] - 41s 122ms/step - loss: 0.1163 - accuracy: 0.9847 - val_loss: 0.1046 - val_accuracy: 0.9780\n",
      "Epoch 451/600\n",
      "336/336 [==============================] - 38s 114ms/step - loss: 0.1400 - accuracy: 0.9827 - val_loss: 0.1073 - val_accuracy: 0.9773\n",
      "Epoch 452/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.1242 - accuracy: 0.9841 - val_loss: 0.1091 - val_accuracy: 0.9793\n",
      "Epoch 453/600\n",
      "336/336 [==============================] - 39s 115ms/step - loss: 0.1290 - accuracy: 0.9822 - val_loss: 0.1135 - val_accuracy: 0.9775\n",
      "Epoch 454/600\n",
      "336/336 [==============================] - 40s 120ms/step - loss: 0.1311 - accuracy: 0.9842 - val_loss: 0.1112 - val_accuracy: 0.9788\n",
      "Epoch 455/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.1285 - accuracy: 0.9837 - val_loss: 0.1153 - val_accuracy: 0.9758\n",
      "Epoch 456/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.1307 - accuracy: 0.9832 - val_loss: 0.1120 - val_accuracy: 0.9777\n",
      "Epoch 457/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.1481 - accuracy: 0.9805 - val_loss: 0.1086 - val_accuracy: 0.9797\n",
      "Epoch 458/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1341 - accuracy: 0.9824 - val_loss: 0.1138 - val_accuracy: 0.9780\n",
      "Epoch 459/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.1223 - accuracy: 0.9842 - val_loss: 0.1097 - val_accuracy: 0.9784\n",
      "Epoch 460/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.1141 - accuracy: 0.9856 - val_loss: 0.1048 - val_accuracy: 0.9801\n",
      "Epoch 461/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.1362 - accuracy: 0.9826 - val_loss: 0.1181 - val_accuracy: 0.9782\n",
      "Epoch 462/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.1083 - accuracy: 0.9844 - val_loss: 0.1131 - val_accuracy: 0.9762\n",
      "Epoch 463/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.1166 - accuracy: 0.9842 - val_loss: 0.1160 - val_accuracy: 0.9762\n",
      "Epoch 464/600\n",
      "336/336 [==============================] - 34s 103ms/step - loss: 0.1202 - accuracy: 0.9837 - val_loss: 0.1092 - val_accuracy: 0.9784\n",
      "Epoch 465/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.1227 - accuracy: 0.9831 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 466/600\n",
      "336/336 [==============================] - 38s 112ms/step - loss: 0.1231 - accuracy: 0.9852 - val_loss: 0.2510 - val_accuracy: 0.9596\n",
      "Epoch 467/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1289 - accuracy: 0.9839 - val_loss: 0.1395 - val_accuracy: 0.9736\n",
      "Epoch 468/600\n",
      "336/336 [==============================] - 38s 112ms/step - loss: 0.1153 - accuracy: 0.9842 - val_loss: 0.1076 - val_accuracy: 0.9782\n",
      "Epoch 469/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1195 - accuracy: 0.9848 - val_loss: 0.1212 - val_accuracy: 0.9795\n",
      "Epoch 470/600\n",
      "336/336 [==============================] - 40s 120ms/step - loss: 0.1186 - accuracy: 0.9840 - val_loss: 0.1281 - val_accuracy: 0.9775\n",
      "Epoch 471/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.1118 - accuracy: 0.9839 - val_loss: 0.1220 - val_accuracy: 0.9793\n",
      "Epoch 472/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1176 - accuracy: 0.9844 - val_loss: 0.1113 - val_accuracy: 0.9801\n",
      "Epoch 473/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.1214 - accuracy: 0.9853 - val_loss: 0.1141 - val_accuracy: 0.9788\n",
      "Epoch 474/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.1289 - accuracy: 0.9832 - val_loss: 0.1144 - val_accuracy: 0.9784\n",
      "Epoch 475/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.1215 - accuracy: 0.9856 - val_loss: 0.1165 - val_accuracy: 0.9795\n",
      "Epoch 476/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.1227 - accuracy: 0.9846 - val_loss: 0.1152 - val_accuracy: 0.9817\n",
      "Epoch 477/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1304 - accuracy: 0.9825 - val_loss: 0.1111 - val_accuracy: 0.9790\n",
      "Epoch 478/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.1055 - accuracy: 0.9853 - val_loss: 0.1031 - val_accuracy: 0.9814\n",
      "Epoch 479/600\n",
      "336/336 [==============================] - 38s 112ms/step - loss: 0.1104 - accuracy: 0.9850 - val_loss: 0.1098 - val_accuracy: 0.9801\n",
      "Epoch 480/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.1105 - accuracy: 0.9849 - val_loss: 0.1146 - val_accuracy: 0.9810\n",
      "Epoch 481/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.1191 - accuracy: 0.9853 - val_loss: 0.1587 - val_accuracy: 0.9703\n",
      "Epoch 482/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.1063 - accuracy: 0.9865 - val_loss: 0.1189 - val_accuracy: 0.9788\n",
      "Epoch 483/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1121 - accuracy: 0.9857 - val_loss: 0.1118 - val_accuracy: 0.9795\n",
      "Epoch 484/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.0998 - accuracy: 0.9875 - val_loss: 0.1210 - val_accuracy: 0.9788\n",
      "Epoch 485/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1088 - accuracy: 0.9863 - val_loss: 0.1110 - val_accuracy: 0.9801\n",
      "Epoch 486/600\n",
      "336/336 [==============================] - 39s 117ms/step - loss: 0.1121 - accuracy: 0.9856 - val_loss: 0.1154 - val_accuracy: 0.9795\n",
      "Epoch 487/600\n",
      "336/336 [==============================] - 46s 136ms/step - loss: 0.1091 - accuracy: 0.9854 - val_loss: 0.1151 - val_accuracy: 0.9784\n",
      "Epoch 488/600\n",
      "336/336 [==============================] - 38s 112ms/step - loss: 0.1123 - accuracy: 0.9856 - val_loss: 0.1151 - val_accuracy: 0.9777\n",
      "Epoch 489/600\n",
      "336/336 [==============================] - 40s 120ms/step - loss: 0.1160 - accuracy: 0.9851 - val_loss: 0.1257 - val_accuracy: 0.9760\n",
      "Epoch 490/600\n",
      "336/336 [==============================] - 41s 123ms/step - loss: 0.0841 - accuracy: 0.9880 - val_loss: 0.1216 - val_accuracy: 0.9784\n",
      "Epoch 491/600\n",
      "336/336 [==============================] - 44s 130ms/step - loss: 0.1001 - accuracy: 0.9863 - val_loss: 0.2867 - val_accuracy: 0.9594\n",
      "Epoch 492/600\n",
      "336/336 [==============================] - 44s 132ms/step - loss: 0.0953 - accuracy: 0.9870 - val_loss: 0.1136 - val_accuracy: 0.9804\n",
      "Epoch 493/600\n",
      "336/336 [==============================] - 41s 121ms/step - loss: 0.1077 - accuracy: 0.9865 - val_loss: 0.1111 - val_accuracy: 0.9801\n",
      "Epoch 494/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.1206 - accuracy: 0.9833 - val_loss: 0.1098 - val_accuracy: 0.9809\n",
      "Epoch 495/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1074 - accuracy: 0.9865 - val_loss: 0.1144 - val_accuracy: 0.9797\n",
      "Epoch 496/600\n",
      "336/336 [==============================] - 38s 113ms/step - loss: 0.1064 - accuracy: 0.9860 - val_loss: 0.1787 - val_accuracy: 0.9666\n",
      "Epoch 497/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 38s 112ms/step - loss: 0.1052 - accuracy: 0.9867 - val_loss: 0.1210 - val_accuracy: 0.9760\n",
      "Epoch 498/600\n",
      "336/336 [==============================] - 38s 113ms/step - loss: 0.1013 - accuracy: 0.9859 - val_loss: 0.1187 - val_accuracy: 0.9797\n",
      "Epoch 499/600\n",
      "336/336 [==============================] - 38s 114ms/step - loss: 0.1159 - accuracy: 0.9855 - val_loss: 0.1233 - val_accuracy: 0.9795\n",
      "Epoch 500/600\n",
      "336/336 [==============================] - 39s 117ms/step - loss: 0.1106 - accuracy: 0.9857 - val_loss: 0.1235 - val_accuracy: 0.9747\n",
      "Epoch 501/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1036 - accuracy: 0.9857 - val_loss: 0.1256 - val_accuracy: 0.9782\n",
      "Epoch 502/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.1084 - accuracy: 0.9850 - val_loss: 0.1105 - val_accuracy: 0.9801\n",
      "Epoch 503/600\n",
      "336/336 [==============================] - 39s 117ms/step - loss: 0.1117 - accuracy: 0.9841 - val_loss: 0.1143 - val_accuracy: 0.9797\n",
      "Epoch 504/600\n",
      "336/336 [==============================] - 35s 106ms/step - loss: 0.0971 - accuracy: 0.9870 - val_loss: 0.1207 - val_accuracy: 0.9775\n",
      "Epoch 505/600\n",
      "336/336 [==============================] - 38s 114ms/step - loss: 0.1099 - accuracy: 0.9864 - val_loss: 0.1175 - val_accuracy: 0.9790\n",
      "Epoch 506/600\n",
      "336/336 [==============================] - 38s 113ms/step - loss: 0.1049 - accuracy: 0.9850 - val_loss: 0.1205 - val_accuracy: 0.9773\n",
      "Epoch 507/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1015 - accuracy: 0.9848 - val_loss: 0.1080 - val_accuracy: 0.9799\n",
      "Epoch 508/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.0963 - accuracy: 0.9863 - val_loss: 0.1139 - val_accuracy: 0.9799\n",
      "Epoch 509/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1204 - accuracy: 0.9839 - val_loss: 0.1124 - val_accuracy: 0.9773\n",
      "Epoch 510/600\n",
      "336/336 [==============================] - 38s 112ms/step - loss: 0.1176 - accuracy: 0.9840 - val_loss: 0.1061 - val_accuracy: 0.9797\n",
      "Epoch 511/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.0967 - accuracy: 0.9870 - val_loss: 0.1039 - val_accuracy: 0.9817\n",
      "Epoch 512/600\n",
      "336/336 [==============================] - 37s 111ms/step - loss: 0.1054 - accuracy: 0.9862 - val_loss: 0.1114 - val_accuracy: 0.9766\n",
      "Epoch 513/600\n",
      "336/336 [==============================] - 40s 118ms/step - loss: 0.1024 - accuracy: 0.9862 - val_loss: 0.1158 - val_accuracy: 0.9771\n",
      "Epoch 514/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.1160 - accuracy: 0.9849 - val_loss: 0.1065 - val_accuracy: 0.9788\n",
      "Epoch 515/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.0944 - accuracy: 0.9880 - val_loss: 0.1194 - val_accuracy: 0.9782\n",
      "Epoch 516/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.0980 - accuracy: 0.9862 - val_loss: 0.1141 - val_accuracy: 0.9777\n",
      "Epoch 517/600\n",
      "336/336 [==============================] - 42s 126ms/step - loss: 0.1078 - accuracy: 0.9864 - val_loss: 0.1786 - val_accuracy: 0.9662\n",
      "Epoch 518/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.0901 - accuracy: 0.9874 - val_loss: 0.1129 - val_accuracy: 0.9793\n",
      "Epoch 519/600\n",
      "336/336 [==============================] - 39s 115ms/step - loss: 0.0947 - accuracy: 0.9870 - val_loss: 0.1193 - val_accuracy: 0.9784\n",
      "Epoch 520/600\n",
      "336/336 [==============================] - 45s 133ms/step - loss: 0.0948 - accuracy: 0.9862 - val_loss: 0.1197 - val_accuracy: 0.9769\n",
      "Epoch 521/600\n",
      "336/336 [==============================] - 39s 115ms/step - loss: 0.0891 - accuracy: 0.9876 - val_loss: 0.1173 - val_accuracy: 0.9780\n",
      "Epoch 522/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.0997 - accuracy: 0.9870 - val_loss: 0.1177 - val_accuracy: 0.9780\n",
      "Epoch 523/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.0920 - accuracy: 0.9890 - val_loss: 0.1284 - val_accuracy: 0.9740\n",
      "Epoch 524/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.1204 - accuracy: 0.9847 - val_loss: 0.1883 - val_accuracy: 0.9651\n",
      "Epoch 525/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.0948 - accuracy: 0.9873 - val_loss: 0.1115 - val_accuracy: 0.9795\n",
      "Epoch 526/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.0931 - accuracy: 0.9885 - val_loss: 0.1096 - val_accuracy: 0.9812\n",
      "Epoch 527/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.1196 - accuracy: 0.9852 - val_loss: 0.1101 - val_accuracy: 0.9795\n",
      "Epoch 528/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.0952 - accuracy: 0.9872 - val_loss: 0.1155 - val_accuracy: 0.9801\n",
      "Epoch 529/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.0994 - accuracy: 0.9869 - val_loss: 0.1161 - val_accuracy: 0.9799\n",
      "Epoch 530/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.1036 - accuracy: 0.9860 - val_loss: 0.1203 - val_accuracy: 0.9793\n",
      "Epoch 531/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.0956 - accuracy: 0.9880 - val_loss: 0.1078 - val_accuracy: 0.9810\n",
      "Epoch 532/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.0904 - accuracy: 0.9877 - val_loss: 0.1126 - val_accuracy: 0.9801\n",
      "Epoch 533/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.1067 - accuracy: 0.9850 - val_loss: 0.1191 - val_accuracy: 0.9786\n",
      "Epoch 534/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.1003 - accuracy: 0.9879 - val_loss: 0.1112 - val_accuracy: 0.9793\n",
      "Epoch 535/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.0912 - accuracy: 0.9891 - val_loss: 0.1063 - val_accuracy: 0.9810\n",
      "Epoch 536/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.0964 - accuracy: 0.9863 - val_loss: 0.1167 - val_accuracy: 0.9780\n",
      "Epoch 537/600\n",
      "336/336 [==============================] - 46s 138ms/step - loss: 0.0892 - accuracy: 0.9869 - val_loss: 0.1036 - val_accuracy: 0.9806\n",
      "Epoch 538/600\n",
      "336/336 [==============================] - 40s 119ms/step - loss: 0.0959 - accuracy: 0.9886 - val_loss: 0.1074 - val_accuracy: 0.9812\n",
      "Epoch 539/600\n",
      "336/336 [==============================] - 40s 120ms/step - loss: 0.0919 - accuracy: 0.9867 - val_loss: 0.1075 - val_accuracy: 0.9801\n",
      "Epoch 540/600\n",
      "336/336 [==============================] - 42s 126ms/step - loss: 0.0925 - accuracy: 0.9877 - val_loss: 0.1107 - val_accuracy: 0.9804\n",
      "Epoch 541/600\n",
      "336/336 [==============================] - 38s 114ms/step - loss: 0.1035 - accuracy: 0.9865 - val_loss: 0.1542 - val_accuracy: 0.9707\n",
      "Epoch 542/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.0992 - accuracy: 0.9855 - val_loss: 0.1095 - val_accuracy: 0.9804\n",
      "Epoch 543/600\n",
      "336/336 [==============================] - 37s 109ms/step - loss: 0.0949 - accuracy: 0.9872 - val_loss: 0.1013 - val_accuracy: 0.9814\n",
      "Epoch 544/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.0912 - accuracy: 0.9869 - val_loss: 0.1059 - val_accuracy: 0.9808\n",
      "Epoch 545/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.0962 - accuracy: 0.9882 - val_loss: 0.1042 - val_accuracy: 0.9804\n",
      "Epoch 546/600\n",
      "336/336 [==============================] - 34s 103ms/step - loss: 0.0882 - accuracy: 0.9876 - val_loss: 0.1086 - val_accuracy: 0.9790\n",
      "Epoch 547/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1010 - accuracy: 0.9862 - val_loss: 0.1054 - val_accuracy: 0.9797\n",
      "Epoch 548/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1014 - accuracy: 0.9868 - val_loss: 0.1040 - val_accuracy: 0.9795\n",
      "Epoch 549/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.1004 - accuracy: 0.9864 - val_loss: 0.1089 - val_accuracy: 0.9793\n",
      "Epoch 550/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.0899 - accuracy: 0.9870 - val_loss: 0.1042 - val_accuracy: 0.9788\n",
      "Epoch 551/600\n",
      "336/336 [==============================] - 42s 125ms/step - loss: 0.0862 - accuracy: 0.9884 - val_loss: 0.1250 - val_accuracy: 0.9736\n",
      "Epoch 552/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 36s 107ms/step - loss: 0.0987 - accuracy: 0.9877 - val_loss: 0.1087 - val_accuracy: 0.9789\n",
      "Epoch 553/600\n",
      "336/336 [==============================] - 36s 108ms/step - loss: 0.0982 - accuracy: 0.9865 - val_loss: 0.1113 - val_accuracy: 0.9790\n",
      "Epoch 554/600\n",
      "336/336 [==============================] - 36s 107ms/step - loss: 0.0865 - accuracy: 0.9870 - val_loss: 0.1106 - val_accuracy: 0.9797\n",
      "Epoch 555/600\n",
      "336/336 [==============================] - 37s 110ms/step - loss: 0.0917 - accuracy: 0.9872 - val_loss: 0.1063 - val_accuracy: 0.9821\n",
      "Epoch 556/600\n",
      "336/336 [==============================] - 36s 106ms/step - loss: 0.0984 - accuracy: 0.9868 - val_loss: 0.1076 - val_accuracy: 0.9788\n",
      "Epoch 557/600\n",
      "336/336 [==============================] - 35s 103ms/step - loss: 0.0963 - accuracy: 0.9889 - val_loss: 0.0997 - val_accuracy: 0.9819\n",
      "Epoch 558/600\n",
      "336/336 [==============================] - 35s 104ms/step - loss: 0.0893 - accuracy: 0.9870 - val_loss: 0.1056 - val_accuracy: 0.9799\n",
      "Epoch 559/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.0828 - accuracy: 0.9888 - val_loss: 0.1074 - val_accuracy: 0.9795\n",
      "Epoch 560/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.0937 - accuracy: 0.9872 - val_loss: 0.1136 - val_accuracy: 0.9775\n",
      "Epoch 561/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.0900 - accuracy: 0.9884 - val_loss: 0.1164 - val_accuracy: 0.9782\n",
      "Epoch 562/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.0800 - accuracy: 0.9887 - val_loss: 0.1066 - val_accuracy: 0.9808\n",
      "Epoch 563/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.0838 - accuracy: 0.9887 - val_loss: 0.1010 - val_accuracy: 0.9821\n",
      "Epoch 564/600\n",
      "336/336 [==============================] - 40s 119ms/step - loss: 0.0865 - accuracy: 0.9885 - val_loss: 0.1089 - val_accuracy: 0.9790\n",
      "Epoch 565/600\n",
      "336/336 [==============================] - 35s 105ms/step - loss: 0.0790 - accuracy: 0.9891 - val_loss: 0.1059 - val_accuracy: 0.9806\n",
      "Epoch 566/600\n",
      "336/336 [==============================] - 34s 101ms/step - loss: 0.0984 - accuracy: 0.9876 - val_loss: 0.1071 - val_accuracy: 0.9793\n",
      "Epoch 567/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.0833 - accuracy: 0.9880 - val_loss: 0.1041 - val_accuracy: 0.9810\n",
      "Epoch 568/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.1007 - accuracy: 0.9872 - val_loss: 0.1026 - val_accuracy: 0.9801\n",
      "Epoch 569/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.0756 - accuracy: 0.9897 - val_loss: 0.1050 - val_accuracy: 0.9801\n",
      "Epoch 570/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.0775 - accuracy: 0.9906 - val_loss: 0.1179 - val_accuracy: 0.9760\n",
      "Epoch 571/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.0894 - accuracy: 0.9890 - val_loss: 0.1062 - val_accuracy: 0.9814\n",
      "Epoch 572/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.0881 - accuracy: 0.9892 - val_loss: 0.1044 - val_accuracy: 0.9806\n",
      "Epoch 573/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.0780 - accuracy: 0.9893 - val_loss: 0.1100 - val_accuracy: 0.9795\n",
      "Epoch 574/600\n",
      "336/336 [==============================] - 34s 103ms/step - loss: 0.0814 - accuracy: 0.9887 - val_loss: 0.1090 - val_accuracy: 0.9804\n",
      "Epoch 575/600\n",
      "336/336 [==============================] - 33s 100ms/step - loss: 0.0889 - accuracy: 0.9875 - val_loss: 0.1058 - val_accuracy: 0.9812\n",
      "Epoch 576/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.0717 - accuracy: 0.9893 - val_loss: 0.1060 - val_accuracy: 0.9817\n",
      "Epoch 577/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.0865 - accuracy: 0.9885 - val_loss: 0.1091 - val_accuracy: 0.9801\n",
      "Epoch 578/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.0902 - accuracy: 0.9880 - val_loss: 0.1086 - val_accuracy: 0.9804\n",
      "Epoch 579/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.0751 - accuracy: 0.9895 - val_loss: 0.1067 - val_accuracy: 0.9806\n",
      "Epoch 580/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.0853 - accuracy: 0.9900 - val_loss: 0.1119 - val_accuracy: 0.9801\n",
      "Epoch 581/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.0806 - accuracy: 0.9893 - val_loss: 0.1094 - val_accuracy: 0.9811\n",
      "Epoch 582/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.0867 - accuracy: 0.9896 - val_loss: 0.1071 - val_accuracy: 0.9812\n",
      "Epoch 583/600\n",
      "336/336 [==============================] - 32s 94ms/step - loss: 0.0916 - accuracy: 0.9884 - val_loss: 0.1044 - val_accuracy: 0.9814\n",
      "Epoch 584/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.0875 - accuracy: 0.9872 - val_loss: 0.1069 - val_accuracy: 0.9814\n",
      "Epoch 585/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.0843 - accuracy: 0.9894 - val_loss: 0.1043 - val_accuracy: 0.9817\n",
      "Epoch 586/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.0804 - accuracy: 0.9895 - val_loss: 0.1052 - val_accuracy: 0.9810\n",
      "Epoch 587/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.0801 - accuracy: 0.9899 - val_loss: 0.1058 - val_accuracy: 0.9812\n",
      "Epoch 588/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.0798 - accuracy: 0.9899 - val_loss: 0.1082 - val_accuracy: 0.9812\n",
      "Epoch 589/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.0788 - accuracy: 0.9897 - val_loss: 0.1056 - val_accuracy: 0.9814\n",
      "Epoch 590/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.0720 - accuracy: 0.9901 - val_loss: 0.1073 - val_accuracy: 0.9812\n",
      "Epoch 591/600\n",
      "336/336 [==============================] - 33s 99ms/step - loss: 0.0798 - accuracy: 0.9886 - val_loss: 0.1065 - val_accuracy: 0.9817\n",
      "Epoch 592/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.0841 - accuracy: 0.9893 - val_loss: 0.1052 - val_accuracy: 0.9812\n",
      "Epoch 593/600\n",
      "336/336 [==============================] - 34s 102ms/step - loss: 0.0855 - accuracy: 0.9892 - val_loss: 0.1059 - val_accuracy: 0.9821\n",
      "Epoch 594/600\n",
      "336/336 [==============================] - 34s 100ms/step - loss: 0.0791 - accuracy: 0.9901 - val_loss: 0.1040 - val_accuracy: 0.9828\n",
      "Epoch 595/600\n",
      "336/336 [==============================] - 32s 97ms/step - loss: 0.0858 - accuracy: 0.9885 - val_loss: 0.1049 - val_accuracy: 0.9821\n",
      "Epoch 596/600\n",
      "336/336 [==============================] - 33s 98ms/step - loss: 0.0772 - accuracy: 0.9897 - val_loss: 0.1059 - val_accuracy: 0.9817\n",
      "Epoch 597/600\n",
      "336/336 [==============================] - 33s 97ms/step - loss: 0.0920 - accuracy: 0.9891 - val_loss: 0.1060 - val_accuracy: 0.9814\n",
      "Epoch 598/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.0761 - accuracy: 0.9888 - val_loss: 0.1054 - val_accuracy: 0.9817\n",
      "Epoch 599/600\n",
      "336/336 [==============================] - 32s 96ms/step - loss: 0.0805 - accuracy: 0.9901 - val_loss: 0.1055 - val_accuracy: 0.9812\n",
      "Epoch 600/600\n",
      "336/336 [==============================] - 32s 95ms/step - loss: 0.0793 - accuracy: 0.9898 - val_loss: 0.1057 - val_accuracy: 0.9814\n"
     ]
    }
   ],
   "source": [
    "# train the head for few epochs\n",
    "H = model.fit_generator(\n",
    "    trainGen.generator(),\n",
    "    steps_per_epoch=trainGen.numImages//batch_size,\n",
    "    validation_data=valGen.generator(),\n",
    "    validation_steps=valGen.numImages//batch_size,\n",
    "    epochs=epoch_num,\n",
    "    max_queue_size=10,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=classWeight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wW96qUuDVf9D"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(f\"{dbBase}//model_mvcnn_color_roi_10class_28px1px_255_minvgg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "0kofqlYIVf9b",
    "outputId": "a91c9d60-1a01-4eab-9b7f-75ccd0a77494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       194\n",
      "           1       0.92      0.95      0.93       464\n",
      "           2       0.97      0.92      0.94       288\n",
      "           3       1.00      1.00      1.00       263\n",
      "           4       0.98      0.99      0.98       554\n",
      "           5       0.99      1.00      1.00       317\n",
      "           6       1.00      1.00      1.00      1157\n",
      "           7       0.99      1.00      1.00       342\n",
      "           8       0.99      0.98      0.99       796\n",
      "           9       0.97      0.92      0.94       238\n",
      "\n",
      "    accuracy                           0.98      4613\n",
      "   macro avg       0.98      0.98      0.98      4613\n",
      "weighted avg       0.98      0.98      0.98      4613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the classification report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "validDB = h5py.File(dbValidPath, mode=\"r\")\n",
    "testx = validDB[\"images\"][:]\n",
    "testy = to_categorical(validDB[\"labels\"][:], class_num)\n",
    "preds = model.predict(testx, batch_size=batch_size)\n",
    "print(classification_report(testy.argmax(axis=1),\n",
    "                            preds.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "muzPuaCcVf9k",
    "outputId": "192e19c4-eac4-45be-904a-917594b7a575"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "labels = list(trainFile[\"label_names\"])\n",
    "labels = [label.decode() for label in labels]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testy.argmax(axis=1),\n",
    "                    preds.argmax(axis=1),\n",
    "                    )\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='viridis')\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "print_confusion_matrix(cm, class_names=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CSEz_RnHfkIK"
   },
   "outputs": [],
   "source": [
    "## load the model\n",
    "loaded_model = load_model(f\"{dbBase}//model_mvcnn_color_roi_10class_28px1px_255_minvgg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001EDF2C9FE48>\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001EDF2C616A0>\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001EDF2C61668>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001EDF20CA7F0>\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001EDF231A390>\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001EDF231A9B0>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001EDF2326978>\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x000001EDF2464C18>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001EDF24A9E48>\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001EDF25BAC88>\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001EDF25E7EB8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001EDF2621208>\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001EDF2825EF0>\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001EDF26246A0>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001EDF288E208>\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x000001EDF29C6BE0>\n",
      "<tensorflow.python.keras.layers.core.Flatten object at 0x000001EDF29F5048>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001EDF29C69B0>\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001EDF2ACBA58>\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001EDF2ACBEF0>\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x000001EDF1FD3DA0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001EDF24A9048>\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001EDF2127E10>\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_input (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "=================================================================\n",
      "Total params: 65,760\n",
      "Trainable params: 65,376\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "flatten_layer = loaded_model.layers[16]\n",
    "retrieval_model = Model(inputs=loaded_model.input, outputs=flatten_layer.output)\n",
    "retrieval_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mvcnn_10class_28px1px_color_roi_minvgg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}