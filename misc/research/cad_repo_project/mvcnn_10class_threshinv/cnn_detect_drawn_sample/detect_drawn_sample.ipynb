{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from cv2 import cv2\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "dir = r\"C:\\Users\\mhasa\\Desktop\\mvcnn_gray_roi_28px\"\n",
    "image_paths = list(paths.list_images(dir))\n",
    "categories = np.unique([p.split(os.path.sep)[-2] for p in image_paths])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,679,082\n",
      "Trainable params: 1,677,674\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def load_trained_cnn(model_name):\n",
    "    data_dir = r\"C:\\Users\\mhasa\\GDrive\\mvcnn\"\n",
    "    # load the model\n",
    "    loaded_model = load_model(f\"{data_dir}//{model_name}\")\n",
    "    print(loaded_model.summary())\n",
    "    return loaded_model\n",
    "cnn_model = load_trained_cnn(\"model_mvcnn_color_roi_10class_28px1px_255_minvgg.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# read the image and create signature\n",
    "def load_and_preprocess_image(image_name, preprocess=True):\n",
    "\n",
    "    thresh = 180\n",
    "    max_val = 255\n",
    "    target_image_size = 28\n",
    "\n",
    "    data_dir = r\"C:\\Users\\mhasa\\Desktop\\draw_samples\"\n",
    "    img = cv2.imread(f\"{data_dir}//{image_name}.JPG\", cv2.IMREAD_GRAYSCALE)\n",
    "    resizedROI = img\n",
    "\n",
    "\n",
    "    if preprocess == True:\n",
    "        # do inverse thresholding\n",
    "        th, dst_bin = cv2.threshold(img.copy(),\n",
    "                                    thresh=thresh,\n",
    "                                    maxval=max_val,\n",
    "                                    type=cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # find all contours in the image\n",
    "        contours, hierarchy = cv2.findContours(dst_bin,\n",
    "                                               cv2.RETR_EXTERNAL,\n",
    "                                               cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        # then find bounding box ROI\n",
    "        #new_image = dst_bin.copy()\n",
    "        new_image = img.copy()\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            # extract the ROI\n",
    "            pad = 10\n",
    "            roi = new_image[y - pad:y + h + pad, x - pad:x + w + pad]\n",
    "\n",
    "            # resize the ROI\n",
    "            # resizedROI = aap.preprocess(roi)\n",
    "            resizedROI = cv2.resize(roi, (target_image_size, target_image_size))\n",
    "\n",
    "    return resizedROI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# predict the image\n",
    "def predict_image_content(processed_image, model):\n",
    "\n",
    "    processed_image = processed_image / 255.0\n",
    "    # channel dim and batch dim since we doing feature extraction\n",
    "    processed_image = np.expand_dims(processed_image, axis=-1)\n",
    "    processed_image = np.expand_dims(processed_image, axis=0)\n",
    "    return model.predict(processed_image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x16e4d4224a8>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = load_and_preprocess_image(\"gasket\", preprocess=True)\n",
    "plt.imshow(img, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O-Rings\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_image_content(img, cnn_model)\n",
    "detected_part = categories[np.argmax(prediction)]\n",
    "print(detected_part)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}