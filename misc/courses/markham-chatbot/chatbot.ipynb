{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:28.078409Z",
     "start_time": "2025-05-04T02:30:27.998377Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# objects to build workflow using graphs\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "\n",
    "# in memory checkpointer that enables the app\n",
    "# to remember past conversations\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "ret = load_dotenv()\n",
    "\n",
    "# returns True if .env loaded successfully\n",
    "print(ret)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:40.137340Z",
     "start_time": "2025-05-04T02:30:28.832663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "model_response = model.invoke(\"Tell me about Dexcom Stelo\")\n",
    "print(model_response)"
   ],
   "id": "bfe3bafcb8e5fcaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='As of my last update in October 2023, Dexcom Stelo is a continuous glucose monitoring (CGM) system developed by Dexcom, which is a well-known company in the diabetes management technology field. The Stelo system is designed to help individuals with diabetes manage their blood glucose levels more effectively by providing real-time glucose readings and trends.\\n\\nKey features of Dexcom Stelo typically include:\\n\\n1. **Real-Time Monitoring**: Stelo continuously measures glucose levels and displays the data on a connected device, like a smartphone or smartwatch.\\n\\n2. **Alerts and Notifications**: The system can send alerts when glucose levels are too high or too low, helping users take timely action to avoid dangerous situations.\\n\\n3. **Easy Integration**: Stelo is often designed to integrate with various diabetes management apps and devices, allowing for a comprehensive view of diabetes-related data.\\n\\n4. **User-Friendly Design**: The Stelo system is generally designed to be easy to use, with simple insertion procedures and clear displays.\\n\\n5. **Data Sharing**: Users may have the option to share their glucose data with healthcare providers or family members for better support and management.\\n\\n6. **Improved Accuracy**: Dexcom is known for developing systems with high accuracy, which is essential for effective diabetes management.\\n\\nPlease check the official Dexcom website or other reliable sources for the most current information, as details about product features, availability, and FDA approvals may have changed since my last update.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 296, 'prompt_tokens': 14, 'total_tokens': 310, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None} id='run-fb757e7c-62db-4141-aa5c-c9427c0aae53-0' usage_metadata={'input_tokens': 14, 'output_tokens': 296, 'total_tokens': 310, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:43.407463Z",
     "start_time": "2025-05-04T02:30:43.397024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    # state = current state of the graph, which is a list of messages\n",
    "    # state[\"messages\"] is a list of all historical messages\n",
    "    updated_messages = model.invoke(state[\"messages\"])\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}"
   ],
   "id": "7f487748c7b42acc",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:44.393068Z",
     "start_time": "2025-05-04T02:30:44.378929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# workflow is a stategraph, keeps track of the state of the application\n",
    "# we need to use a schema, MessagesState helps to keep track a list\n",
    "# of messages. in other words, we are saying the state the worflow\n",
    "# gonna keep track of is a list of messages\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# nodes take as input the current state of the graph\n",
    "# they do something and then they update the state\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "\n",
    "# after START, run the model node which calls the model\n",
    "# add an edge from the START node to the model node\n",
    "# edges determine which node to execute next, based on current state\n",
    "workflow.add_edge(START, \"model_node\")"
   ],
   "id": "b4112da7945a6d1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x274eb14af00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:44.879968Z",
     "start_time": "2025-05-04T02:30:44.871967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# real apps will use Postgres or SQlite checkpointers\n",
    "# for experimentation use in memory checkpointer\n",
    "# checkpointers store snapshots of past conversation\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "3e80023bf7187004",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:51.798512Z",
     "start_time": "2025-05-04T02:30:50.942817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# app is now a runnable object so has invoke method\n",
    "# because schema used is MessagesState, input expected\n",
    "# is dict of {'messages': \"\"}\n",
    "\n",
    "chat1 = {'configurable': {'thread_id': 1}}\n",
    "app.invoke({\"messages\": \"Hi My name is Mahmud!\"}, config=chat1)"
   ],
   "id": "838a8b368f1de90e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi My name is Mahmud!', additional_kwargs={}, response_metadata={}, id='1d7649b1-a1c8-42c3-83e3-78893b37f699'),\n",
       "  AIMessage(content='Hi Mahmud! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 14, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None}, id='run-32306904-4535-4905-a7ff-2c2ab97ba71d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 12, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:55.067948Z",
     "start_time": "2025-05-04T02:30:54.255319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# look at the reply. the whole conversation is here\n",
    "app.invoke({\"messages\": \"What is my name!\"}, config=chat1)"
   ],
   "id": "8815c59bc40ddd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi My name is Mahmud!', additional_kwargs={}, response_metadata={}, id='1d7649b1-a1c8-42c3-83e3-78893b37f699'),\n",
       "  AIMessage(content='Hi Mahmud! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 14, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None}, id='run-32306904-4535-4905-a7ff-2c2ab97ba71d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 12, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='What is my name!', additional_kwargs={}, response_metadata={}, id='ba600d4b-9ccf-4b7b-b359-1fd0eda9ea48'),\n",
       "  AIMessage(content='Your name is Mahmud! How can I help you further?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 38, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-464d4cd2-13e8-4de2-bd21-3edc2ad4d9e9-0', usage_metadata={'input_tokens': 38, 'output_tokens': 14, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:58.941880Z",
     "start_time": "2025-05-04T02:30:58.934829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = app.invoke(None, config=chat1)\n",
    "for message in output[\"messages\"]:\n",
    "    message.pretty_print()"
   ],
   "id": "8543780c1a19c48c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hi My name is Mahmud!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hi Mahmud! How can I assist you today?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is my name!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Your name is Mahmud! How can I help you further?\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:31:04.495483Z",
     "start_time": "2025-05-04T02:31:03.790070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# can the app support multiple independant conversations?\n",
    "chat2 = {'configurable': {'thread_id': 2}}\n",
    "app.invoke({\"messages\": \"What is my name!\"}, config=chat2)[\"messages\"][-1].content"
   ],
   "id": "ae646e4a1b914437",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. If you tell me, I can use it in our conversation!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This time the app doesnt know my name confirming this is an entirely different chat",
   "id": "e9a748714965aef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:31:13.482369Z",
     "start_time": "2025-05-04T02:31:13.471320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make the app more interactive\n",
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")\n"
   ],
   "id": "2f41d290a69d8b78",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:32:08.832128Z",
     "start_time": "2025-05-04T02:31:17.899983Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot(2)",
   "id": "a6a6bee8f637f5c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "Nice to meet you, Mahmud Hasan! How can I assist you today?\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "Las Vegas is famous for a variety of reasons, including:\n",
      "\n",
      "1. **Casinos and Gambling**: Las Vegas is known as the gambling capital of the world, with numerous casinos offering a wide range of gaming options.\n",
      "\n",
      "2. **Entertainment**: The city is renowned for its entertainment options, including world-class shows, concerts, magic acts, and performances by famous artists.\n",
      "\n",
      "3. **Nightlife**: Las Vegas boasts a vibrant nightlife scene, with many nightclubs, bars, and lounges that attract visitors from around the globe.\n",
      "\n",
      "4. **Resorts and Hotels**: The Strip is lined with extravagant hotels and resorts, each offering unique themes and attractions, such as the Bellagio, Caesars Palace, and The Venetian.\n",
      "\n",
      "5. **Dining**: Las Vegas offers a diverse culinary scene, with numerous fine dining restaurants run by celebrity chefs, buffets, and international cuisine.\n",
      "\n",
      "6. **Shopping**: The city features luxury shopping experiences, including high-end boutiques and outlet malls.\n",
      "\n",
      "7. **Conventions and Events**: Las Vegas hosts numerous conventions, trade shows, and events throughout the year, making it a popular destination for business travelers.\n",
      "\n",
      "8. **Themed Attractions**: There are many attractions that reflect different cultures and themes, such as the Eiffel Tower at Paris Las Vegas, canals at The Venetian, and the Colosseum at Caesars Palace.\n",
      "\n",
      "9. **Natural Beauty**: Beyond the city, Las Vegas is close to beautiful natural attractions like Red Rock Canyon and the Hoover Dam, offering outdoor recreation options.\n",
      "\n",
      "10. **Weddings**: Las Vegas is a popular destination for quick and often themed weddings, with many chapels available for couples looking to tie the knot.\n",
      "\n",
      "These elements combine to make Las Vegas a unique and popular destination for millions of visitors each year.\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding a system prompt",
   "id": "f584b9e0536a32e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:35:14.960982Z",
     "start_time": "2025-05-04T02:35:14.953229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# System messages are used to direct the behavior of the LLM.We will use chat prompt templates to send system messages\n",
    "\n",
    "# ChatPromptTemplate =  a reusable structure for creating prompts for chat apps\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ],
   "id": "afd6c2544da979c9",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:38:13.825511Z",
     "start_time": "2025-05-04T02:38:13.794840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tuples of message types and messages\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"Limit all of your responses to two sentences\"),\n",
    "        (\"placeholder\", \"{messages}\")  # telling the prompt template\n",
    "        # is expected to get a variable messages when invoked. this variable will\n",
    "        # come from the state that is passed to the call function\n",
    "    ]\n",
    ")"
   ],
   "id": "503aa98620db6f88",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:39:51.395792Z",
     "start_time": "2025-05-04T02:39:51.387516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# state is a dict with key messages and value a list of HumanMessages\n",
    "state = {\"messages\": [\"What is the history of Delta Airlines\"]}"
   ],
   "id": "19c7a19de35dc4e9",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:40:30.098611Z",
     "start_time": "2025-05-04T02:40:30.077026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prompt also has a invoke model\n",
    "prompt.invoke(state)"
   ],
   "id": "60f3d6e97c1dc7b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Limit all of your responses to two sentences', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the history of Delta Airlines', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:41:17.787410Z",
     "start_time": "2025-05-04T02:41:16.219400Z"
    }
   },
   "cell_type": "code",
   "source": "model.invoke(prompt.invoke(state))",
   "id": "240c9c1a2269e636",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Delta Airlines was founded in 1925 as a crop-dusting service called Huff Daland Dusters. It transitioned to passenger airline operations in 1929 and expanded significantly through mergers and acquisitions, becoming one of the largest airlines in the world.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 26, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-cc016ee3-1218-4449-95ea-ca0ed750b1fa-0', usage_metadata={'input_tokens': 26, 'output_tokens': 50, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chaining multiple actions",
   "id": "7c720e094641f0fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:43:40.198244Z",
     "start_time": "2025-05-04T02:43:38.311800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this is a chain of actions = model.invoke(prompt.invoke(state))\n",
    "# run the steps in order from left to right\n",
    "# chains are like scikit learn pipelines\n",
    "chain = prompt | model\n",
    "chain.invoke(state)"
   ],
   "id": "1ab92c629ee767ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Delta Airlines was founded in 1924 as a crop-dusting operation called Huff Daland Dusters and later transitioned to passenger flights in 1929. Over the decades, it expanded through numerous mergers and acquisitions, becoming one of the largest and most significant airlines in the world.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 26, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-ea74da98-d0d2-47c4-978b-9efbfa21f748-0', usage_metadata={'input_tokens': 26, 'output_tokens': 57, 'total_tokens': 83, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Integrating prompt in workflow code",
   "id": "b00bc5c17f4d211a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:47:30.215300Z",
     "start_time": "2025-05-04T02:47:30.209479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    # state = current state of the graph, which is a list of messages\n",
    "    # state[\"messages\"] is a list of all historical messages\n",
    "    chain = prompt | model\n",
    "    updated_messages = chain.invoke(state)\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}"
   ],
   "id": "40019631f5ee7fa5",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:47:54.163857Z",
     "start_time": "2025-05-04T02:47:54.157845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "487e217f6ad1d384",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:50:37.971547Z",
     "start_time": "2025-05-04T02:48:54.223298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we have a chatbot that onyl gives short answerss\n",
    "chatbot(2)"
   ],
   "id": "4847d01fd07367de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "Mahmud Hasan may refer to various individuals; could you specify which one or provide more context? Notable figures with that name could include politicians, academics, or athletes.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "Mahmud Hasan is a prominent Bangladeshi politician and a member of the Awami League party. He has been involved in various political activities and has served in different capacities within the government.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "The Awami League is one of the major political parties in Bangladesh, founded in 1949. It played a significant role in the country's struggle for independence and is known for advocating secularism, socialism, and democracy.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "The Bangladesh Nationalist Party (BNP) is a major political party in Bangladesh, founded in 1978 by former President Ziaur Rahman. The party is known for its nationalist ideology and has been a significant political rival to the Awami League, often advocating for conservative and pro-Islamist policies.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "If you have any more questions in the future, feel free to ask. Have a great day!\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "Exiting now. Take care!\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "It seems there was no further request. If you need assistance later, just let me know!\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# now we have a chatbot that onyl gives short answerss\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mchatbot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[26], line 7\u001B[0m, in \u001B[0;36mchatbot\u001B[1;34m(chat_id)\u001B[0m\n\u001B[0;32m      4\u001B[0m config \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigurable\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthread_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: chat_id}}\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m----> 7\u001B[0m     user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mUser: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m user_input \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquit\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGoodbye\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\GoogleDrive\\GitHub\\DeepLearning\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\GoogleDrive\\GitHub\\DeepLearning\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4bc62017787290bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Translation to Spanish",
   "id": "411bdf40498a29af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:56:00.124390Z",
     "start_time": "2025-05-04T02:55:58.547806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# change in the prompt\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"Translate the input from English to Spanish\"),\n",
    "        (\"placeholder\", \"{messages}\")  # telling the prompt template\n",
    "        # is expected to get a variable messages when invoked. this variable will\n",
    "        # come from the state that is passed to the call function\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    # state = current state of the graph, which is a list of messages\n",
    "    # state[\"messages\"] is a list of all historical messages\n",
    "    chain = prompt | model\n",
    "    updated_messages = chain.invoke(state)\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "ce11390c776686cc",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:56:43.694056Z",
     "start_time": "2025-05-04T02:56:11.980164Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot(3)",
   "id": "e2fa3fa3357d28e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "hola\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "¿Cuál es tu nombre?\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "¿Dónde está México?\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T03:13:34.407115Z",
     "start_time": "2025-05-04T03:13:33.668174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# translate to any language\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# change in the prompt\n",
    "# add a variable called language to the prompt template\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"Translate the input from English to {language}\"),\n",
    "        (\"placeholder\", \"{messages}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# %% ##################################################################\n",
    "# MessagesStae objects only have a single key called mesages\n",
    "# we need to extend this class to also add another key language\n",
    "# which will be passed to app.invoke eventually\n",
    "class CustomState(MessagesState):\n",
    "    language: str\n",
    "\n",
    "\n",
    "# %% ##################################################################\n",
    "\n",
    "def call_model(state: CustomState):\n",
    "    chain = prompt | model\n",
    "    updated_messages = chain.invoke(state)\n",
    "    return {\"messages\": updated_messages}\n",
    "\n",
    "\n",
    "workflow = StateGraph(CustomState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "c341e0423c4813ee",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T03:13:36.493712Z",
     "start_time": "2025-05-04T03:13:36.484902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translatebot(language: str):\n",
    "    # since there is no notion of conversation for translatebot\n",
    "    # we will just set the chatid to a fixed number\n",
    "    config = {\"configurable\": {\"thread_id\": 999}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input, \"language\": language},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")"
   ],
   "id": "2957edf27b2e5d9f",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T03:14:24.317117Z",
     "start_time": "2025-05-04T03:13:45.866051Z"
    }
   },
   "cell_type": "code",
   "source": "translatebot(\"Bengali\")",
   "id": "42f07212ccbbb140",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "হ্যালো\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "তুমি কেমন আছো?\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "আমি দুঃখিত, কিন্তু আমি এই বিষয়ে সহায়তা করতে পারবো না।\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "হ্যালো! কেমন আছো?\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "154eac880f810dbd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
