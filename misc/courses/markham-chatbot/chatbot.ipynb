{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-05T22:38:15.542713Z",
     "start_time": "2025-05-05T22:38:13.269490Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# objects to build workflow using graphs\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "\n",
    "# in memory checkpointer that enables the app\n",
    "# to remember past conversations\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "ret = load_dotenv()\n",
    "\n",
    "# returns True if .env loaded successfully\n",
    "print(ret)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:38:20.675715Z",
     "start_time": "2025-05-05T22:38:15.755623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "model_response = model.invoke(\"Tell me about Dexcom Stelo\")\n",
    "print(model_response)"
   ],
   "id": "bfe3bafcb8e5fcaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='As of my last knowledge update in October 2021, Dexcom had not yet released a product specifically named \"Dexcom Stelo.\" However, it’s possible that developments may have occurred after that date, including new products, expansions, or updates from Dexcom, a company known for its continuous glucose monitoring (CGM) systems for people with diabetes.\\n\\nDexcom is widely recognized for its CGM systems, which provide real-time glucose readings that help users manage their diabetes more effectively. Their products typically include features such as smartphone compatibility, alarms for high or low blood glucose levels, and data sharing capabilities with caregivers or family members.\\n\\nFor the most accurate and current information regarding the Dexcom Stelo or any other new product releases, I recommend checking the official Dexcom website or consulting recent news articles and press releases from the company.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 168, 'prompt_tokens': 14, 'total_tokens': 182, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'finish_reason': 'stop', 'logprobs': None} id='run--f4a465fa-646c-47b1-bad8-84bc262eb88f-0' usage_metadata={'input_tokens': 14, 'output_tokens': 168, 'total_tokens': 182, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:43.407463Z",
     "start_time": "2025-05-04T02:30:43.397024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    # state = current state of the graph, which is a list of messages\n",
    "    # state[\"messages\"] is a list of all historical messages\n",
    "    updated_messages = model.invoke(state[\"messages\"])\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}"
   ],
   "id": "7f487748c7b42acc",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:44.393068Z",
     "start_time": "2025-05-04T02:30:44.378929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# workflow is a stategraph, keeps track of the state of the application\n",
    "# we need to use a schema, MessagesState helps to keep track a list\n",
    "# of messages. in other words, we are saying the state the worflow\n",
    "# gonna keep track of is a list of messages\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# nodes take as input the current state of the graph\n",
    "# they do something and then they update the state\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "\n",
    "# after START, run the model node which calls the model\n",
    "# add an edge from the START node to the model node\n",
    "# edges determine which node to execute next, based on current state\n",
    "workflow.add_edge(START, \"model_node\")"
   ],
   "id": "b4112da7945a6d1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x274eb14af00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:44.879968Z",
     "start_time": "2025-05-04T02:30:44.871967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# real apps will use Postgres or SQlite checkpointers\n",
    "# for experimentation use in memory checkpointer\n",
    "# checkpointers store snapshots of past conversation\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "3e80023bf7187004",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:51.798512Z",
     "start_time": "2025-05-04T02:30:50.942817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# app is now a runnable object so has invoke method\n",
    "# because schema used is MessagesState, input expected\n",
    "# is dict of {'messages': \"\"}\n",
    "\n",
    "chat1 = {'configurable': {'thread_id': 1}}\n",
    "app.invoke({\"messages\": \"Hi My name is Mahmud!\"}, config=chat1)"
   ],
   "id": "838a8b368f1de90e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi My name is Mahmud!', additional_kwargs={}, response_metadata={}, id='1d7649b1-a1c8-42c3-83e3-78893b37f699'),\n",
       "  AIMessage(content='Hi Mahmud! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 14, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None}, id='run-32306904-4535-4905-a7ff-2c2ab97ba71d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 12, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:55.067948Z",
     "start_time": "2025-05-04T02:30:54.255319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# look at the reply. the whole conversation is here\n",
    "app.invoke({\"messages\": \"What is my name!\"}, config=chat1)"
   ],
   "id": "8815c59bc40ddd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi My name is Mahmud!', additional_kwargs={}, response_metadata={}, id='1d7649b1-a1c8-42c3-83e3-78893b37f699'),\n",
       "  AIMessage(content='Hi Mahmud! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 14, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None}, id='run-32306904-4535-4905-a7ff-2c2ab97ba71d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 12, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='What is my name!', additional_kwargs={}, response_metadata={}, id='ba600d4b-9ccf-4b7b-b359-1fd0eda9ea48'),\n",
       "  AIMessage(content='Your name is Mahmud! How can I help you further?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 38, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-464d4cd2-13e8-4de2-bd21-3edc2ad4d9e9-0', usage_metadata={'input_tokens': 38, 'output_tokens': 14, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:58.941880Z",
     "start_time": "2025-05-04T02:30:58.934829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = app.invoke(None, config=chat1)\n",
    "for message in output[\"messages\"]:\n",
    "    message.pretty_print()"
   ],
   "id": "8543780c1a19c48c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hi My name is Mahmud!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hi Mahmud! How can I assist you today?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is my name!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Your name is Mahmud! How can I help you further?\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:31:04.495483Z",
     "start_time": "2025-05-04T02:31:03.790070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# can the app support multiple independant conversations?\n",
    "chat2 = {'configurable': {'thread_id': 2}}\n",
    "app.invoke({\"messages\": \"What is my name!\"}, config=chat2)[\"messages\"][-1].content"
   ],
   "id": "ae646e4a1b914437",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. If you tell me, I can use it in our conversation!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This time the app doesnt know my name confirming this is an entirely different chat",
   "id": "e9a748714965aef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:31:13.482369Z",
     "start_time": "2025-05-04T02:31:13.471320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make the app more interactive\n",
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")\n"
   ],
   "id": "2f41d290a69d8b78",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:32:08.832128Z",
     "start_time": "2025-05-04T02:31:17.899983Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot(2)",
   "id": "a6a6bee8f637f5c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "Nice to meet you, Mahmud Hasan! How can I assist you today?\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "Las Vegas is famous for a variety of reasons, including:\n",
      "\n",
      "1. **Casinos and Gambling**: Las Vegas is known as the gambling capital of the world, with numerous casinos offering a wide range of gaming options.\n",
      "\n",
      "2. **Entertainment**: The city is renowned for its entertainment options, including world-class shows, concerts, magic acts, and performances by famous artists.\n",
      "\n",
      "3. **Nightlife**: Las Vegas boasts a vibrant nightlife scene, with many nightclubs, bars, and lounges that attract visitors from around the globe.\n",
      "\n",
      "4. **Resorts and Hotels**: The Strip is lined with extravagant hotels and resorts, each offering unique themes and attractions, such as the Bellagio, Caesars Palace, and The Venetian.\n",
      "\n",
      "5. **Dining**: Las Vegas offers a diverse culinary scene, with numerous fine dining restaurants run by celebrity chefs, buffets, and international cuisine.\n",
      "\n",
      "6. **Shopping**: The city features luxury shopping experiences, including high-end boutiques and outlet malls.\n",
      "\n",
      "7. **Conventions and Events**: Las Vegas hosts numerous conventions, trade shows, and events throughout the year, making it a popular destination for business travelers.\n",
      "\n",
      "8. **Themed Attractions**: There are many attractions that reflect different cultures and themes, such as the Eiffel Tower at Paris Las Vegas, canals at The Venetian, and the Colosseum at Caesars Palace.\n",
      "\n",
      "9. **Natural Beauty**: Beyond the city, Las Vegas is close to beautiful natural attractions like Red Rock Canyon and the Hoover Dam, offering outdoor recreation options.\n",
      "\n",
      "10. **Weddings**: Las Vegas is a popular destination for quick and often themed weddings, with many chapels available for couples looking to tie the knot.\n",
      "\n",
      "These elements combine to make Las Vegas a unique and popular destination for millions of visitors each year.\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding a system prompt",
   "id": "f584b9e0536a32e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:35:14.960982Z",
     "start_time": "2025-05-04T02:35:14.953229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# System messages are used to direct the behavior of the LLM.We will use chat prompt templates to send system messages\n",
    "\n",
    "# ChatPromptTemplate =  a reusable structure for creating prompts for chat apps\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ],
   "id": "afd6c2544da979c9",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:38:13.825511Z",
     "start_time": "2025-05-04T02:38:13.794840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tuples of message types and messages\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"Limit all of your responses to two sentences\"),\n",
    "        (\"placeholder\", \"{messages}\")  # telling the prompt template\n",
    "        # is expected to get a variable messages when invoked. this variable will\n",
    "        # come from the state that is passed to the call function\n",
    "    ]\n",
    ")"
   ],
   "id": "503aa98620db6f88",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:39:51.395792Z",
     "start_time": "2025-05-04T02:39:51.387516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# state is a dict with key messages and value a list of HumanMessages\n",
    "state = {\"messages\": [\"What is the history of Delta Airlines\"]}"
   ],
   "id": "19c7a19de35dc4e9",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:40:30.098611Z",
     "start_time": "2025-05-04T02:40:30.077026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prompt also has a invoke model\n",
    "prompt.invoke(state)"
   ],
   "id": "60f3d6e97c1dc7b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Limit all of your responses to two sentences', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the history of Delta Airlines', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:41:17.787410Z",
     "start_time": "2025-05-04T02:41:16.219400Z"
    }
   },
   "cell_type": "code",
   "source": "model.invoke(prompt.invoke(state))",
   "id": "240c9c1a2269e636",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Delta Airlines was founded in 1925 as a crop-dusting service called Huff Daland Dusters. It transitioned to passenger airline operations in 1929 and expanded significantly through mergers and acquisitions, becoming one of the largest airlines in the world.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 26, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-cc016ee3-1218-4449-95ea-ca0ed750b1fa-0', usage_metadata={'input_tokens': 26, 'output_tokens': 50, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chaining multiple actions",
   "id": "7c720e094641f0fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:43:40.198244Z",
     "start_time": "2025-05-04T02:43:38.311800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this is a chain of actions = model.invoke(prompt.invoke(state))\n",
    "# run the steps in order from left to right\n",
    "# chains are like scikit learn pipelines\n",
    "chain = prompt | model\n",
    "chain.invoke(state)"
   ],
   "id": "1ab92c629ee767ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Delta Airlines was founded in 1924 as a crop-dusting operation called Huff Daland Dusters and later transitioned to passenger flights in 1929. Over the decades, it expanded through numerous mergers and acquisitions, becoming one of the largest and most significant airlines in the world.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 26, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-ea74da98-d0d2-47c4-978b-9efbfa21f748-0', usage_metadata={'input_tokens': 26, 'output_tokens': 57, 'total_tokens': 83, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Integrating prompt in workflow code",
   "id": "b00bc5c17f4d211a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:47:30.215300Z",
     "start_time": "2025-05-04T02:47:30.209479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    # state = current state of the graph, which is a list of messages\n",
    "    # state[\"messages\"] is a list of all historical messages\n",
    "    chain = prompt | model\n",
    "    updated_messages = chain.invoke(state)\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}"
   ],
   "id": "40019631f5ee7fa5",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:47:54.163857Z",
     "start_time": "2025-05-04T02:47:54.157845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "487e217f6ad1d384",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:50:37.971547Z",
     "start_time": "2025-05-04T02:48:54.223298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we have a chatbot that onyl gives short answerss\n",
    "chatbot(2)"
   ],
   "id": "4847d01fd07367de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "Mahmud Hasan may refer to various individuals; could you specify which one or provide more context? Notable figures with that name could include politicians, academics, or athletes.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "Mahmud Hasan is a prominent Bangladeshi politician and a member of the Awami League party. He has been involved in various political activities and has served in different capacities within the government.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "The Awami League is one of the major political parties in Bangladesh, founded in 1949. It played a significant role in the country's struggle for independence and is known for advocating secularism, socialism, and democracy.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "The Bangladesh Nationalist Party (BNP) is a major political party in Bangladesh, founded in 1978 by former President Ziaur Rahman. The party is known for its nationalist ideology and has been a significant political rival to the Awami League, often advocating for conservative and pro-Islamist policies.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "If you have any more questions in the future, feel free to ask. Have a great day!\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "Exiting now. Take care!\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "It seems there was no further request. If you need assistance later, just let me know!\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# now we have a chatbot that onyl gives short answerss\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mchatbot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[26], line 7\u001B[0m, in \u001B[0;36mchatbot\u001B[1;34m(chat_id)\u001B[0m\n\u001B[0;32m      4\u001B[0m config \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigurable\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthread_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: chat_id}}\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m----> 7\u001B[0m     user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mUser: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m user_input \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquit\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGoodbye\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\GoogleDrive\\GitHub\\DeepLearning\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\GoogleDrive\\GitHub\\DeepLearning\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4bc62017787290bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Translation to Spanish",
   "id": "411bdf40498a29af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:56:00.124390Z",
     "start_time": "2025-05-04T02:55:58.547806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# change in the prompt\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"Translate the input from English to Spanish\"),\n",
    "        (\"placeholder\", \"{messages}\")  # telling the prompt template\n",
    "        # is expected to get a variable messages when invoked. this variable will\n",
    "        # come from the state that is passed to the call function\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    # state = current state of the graph, which is a list of messages\n",
    "    # state[\"messages\"] is a list of all historical messages\n",
    "    chain = prompt | model\n",
    "    updated_messages = chain.invoke(state)\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "ce11390c776686cc",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:56:43.694056Z",
     "start_time": "2025-05-04T02:56:11.980164Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot(3)",
   "id": "e2fa3fa3357d28e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "hola\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "¿Cuál es tu nombre?\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "¿Dónde está México?\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T03:13:34.407115Z",
     "start_time": "2025-05-04T03:13:33.668174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# translate to any language\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# change in the prompt\n",
    "# add a variable called language to the prompt template\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"Translate the input from English to {language}\"),\n",
    "        (\"placeholder\", \"{messages}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# %% ##################################################################\n",
    "# MessagesState objects only have a single key called mesages\n",
    "# we need to extend this class to also add another key language\n",
    "# which will be passed to app.invoke eventually\n",
    "class CustomState(MessagesState):\n",
    "    language: str\n",
    "\n",
    "\n",
    "# %% ##################################################################\n",
    "\n",
    "def call_model(state: CustomState):\n",
    "    chain = prompt | model\n",
    "    updated_messages = chain.invoke(state)\n",
    "    return {\"messages\": updated_messages}\n",
    "\n",
    "\n",
    "workflow = StateGraph(CustomState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "c341e0423c4813ee",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T03:18:34.321922Z",
     "start_time": "2025-05-04T03:18:34.300933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translatebot(language: str):\n",
    "    # since there is no notion of conversation for translatebot\n",
    "    # we will just set the chatid to a fixed number\n",
    "    config = {\"configurable\": {\"thread_id\": 999}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input, \"language\": language},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")"
   ],
   "id": "2957edf27b2e5d9f",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T03:19:19.925072Z",
     "start_time": "2025-05-04T03:18:35.078771Z"
    }
   },
   "cell_type": "code",
   "source": "translatebot(\"Bengali\")",
   "id": "42f07212ccbbb140",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "আমি ইমুকে ভালোবাসি!\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "তুমি কোথায় ইমু? দয়া করে আমার কাছে এসো!!!\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "154eac880f810dbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Updating App with real time search",
   "id": "56522d0099f4b828"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:41:53.346994Z",
     "start_time": "2025-05-05T22:41:53.337943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def call_model(state: MessagesState):\n",
    "    updated_messages = model.invoke(state[\"messages\"])\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}"
   ],
   "id": "a53b53bbcdfbd62",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:41:54.159116Z",
     "start_time": "2025-05-05T22:41:54.153122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")"
   ],
   "id": "cf0880d85b2adac8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Tools allow LLMs to perform actions and retrieve data from external sources. Tools is what we use to extend the capabilities of Langchain based apps. First tool we use is tavily-search. Search engine for LLMs. We need to create an account in Tavily and create API-key.\n",
    "\n",
    "You tell the model that this tool is availabel for use, and you'll tell the model whatthe tool does. for a given input to the model, the model itself decides if it has to use the tool."
   ],
   "id": "9628379bfeca5cc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:42:03.322527Z",
     "start_time": "2025-05-05T22:42:03.305951Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "5a4a3c33289b39fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:42:06.021346Z",
     "start_time": "2025-05-05T22:42:05.604909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=5)\n",
    "tool_list = [search]"
   ],
   "id": "d3cb20990903f71a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:42:08.026022Z",
     "start_time": "2025-05-05T22:42:07.345711Z"
    }
   },
   "cell_type": "code",
   "source": "model = ChatOpenAI(model_name=\"gpt-4o-mini\").bind_tools(tool_list)",
   "id": "2ab863d75b593d1a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:42:09.550100Z",
     "start_time": "2025-05-05T22:42:09.491076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "call_tool = ToolNode(tool_list)"
   ],
   "id": "90aeffef5b41c67d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:42:10.918202Z",
     "start_time": "2025-05-05T22:42:10.909050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_node(\"tools\", call_tool)\n",
    "\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "workflow.add_conditional_edges(\"model_node\", tools_condition)\n",
    "workflow.add_edge(\"tools\", \"model_node\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "a2c9e3ebaf4ef992",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:42:41.555352Z",
     "start_time": "2025-05-05T22:42:12.903386Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot(4)",
   "id": "4872635b6eaf221d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "[{\"title\": \"OceanGate - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/OceanGate\", \"content\": \"OceanGate Inc. is an American privately owned company based in Everett, Washington, that provided crewed submersibles for tourism, industry, research, and exploration. The company was founded in 2009 by Stockton Rush and Guillermo Söhnlein. [...] OceanGate was initiated by Guillermo Söhnlein and Stockton Rush in Seattle in 2009.[17][18][19][20] According to Söhnlein, the company was founded with the intention of creating a small fleet of 5-person commercial submersibles that could be leased by any organization or group of individuals. In 2023 he told Sky News, \\\"The whole intent was to create a small fleet of work submersibles. And in that way, as our tagline was in the early days, 'Open the oceans for all of humanity.'\\\"[21] [...] The company acquired a submersible vessel, Antipodes, and later built two of its own: Cyclops 1 and Titan. In 2021, OceanGate began taking paying tourists in Titan to visit the wreck of the Titanic. In 2022, the price to be a passenger on an OceanGate expedition to the Titanic shipwreck was $250,000 per person.[1]\", \"score\": 0.9145431}, {\"title\": \"Titan submersible implosion - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Titan_submersible_implosion\", \"content\": \"OceanGate was a private company, initiated in 2009 by Stockton Rush and Guillermo Söhnlein. From 2010 until the loss of the Titan submersible, OceanGate transported paying customers in leased commercial submersibles off the coast of California, in the Gulf of Mexico, and in the Atlantic Ocean.[3] The company was based in Everett, Washington, US.[4] [...] On 18 June 2023, Titan, a submersible operated by the American tourism and expeditions company OceanGate, imploded during an expedition to view the wreck of the Titanic in the North Atlantic Ocean off the coast of Newfoundland, Canada. Aboard the submersible were Stockton Rush, the American chief executive officer of OceanGate; Paul-Henri Nargeolet, a French deep-sea explorer and Titanic expert; Hamish Harding, a British businessman; Shahzada Dawood, a Pakistani-British businessman; and [...] Formerly known as Cyclops 2,[11] Titan was a five-person submersible vessel operated by OceanGate Inc. The 6.7-metre-long (22 ft), 10,432 kg (23,000 lb) vessel was constructed from carbon fibre and titanium.[12] The entire pressure vessel consisted of two titanium hemispheres (domes) with matching titanium interface rings bonded to the 142 cm (56 in) internal diameter, 2.4-metre-long (7.9 ft) carbon fibre-wound cylinder.[13] One of the titanium hemispherical end caps could be detached to\", \"score\": 0.88799405}, {\"title\": \"OceanGate Expeditions (@oceangateexped) - Instagram\", \"url\": \"https://www.instagram.com/oceangateexped/?hl=en\", \"content\": \"We're a team of ocean explorers, scientists, and filmmakers dedicated to manned exploration of the deep. Learn how you can join us ⬇️.\", \"score\": 0.6366926}, {\"title\": \"US Coast Guard releases suspected audio recording of Titan ... - CNN\", \"url\": \"https://www.cnn.com/2025/02/12/us/titan-submersible-implosion-audio-coast-guard\", \"content\": \"On an expedition to the Titanic shipwreck, the Titan imploded on June 18, 2023. The five passengers aboard were all confirmed deceased following the discovery of the wreckage.\\n\\nThe passengers were Stockton Rush, the founder and CEO of OceanGate; businessman Shahzada Dawood and his 19-year-old son, Suleman Dawood; businessman Hamish Harding; and French diver Paul-Henri Nargeolet. [...] The audio released Tuesday by the Coast Guard’s Marine Board of Investigation is part of an ongoing investigation into OceanGate, the vessel’s operator, and the Titan implosion.\\n\\nFor approximately two weeks in September, the Coast Guard and the National Transportation Safety Board held an extensive investigation into the implosion with several witnesses and experts.\", \"score\": 0.60861784}, {\"title\": \"OceanGate Home\", \"url\": \"https://oceangate.com/\", \"content\": \"OceanGate has suspended all exploration and commercial operations.\", \"score\": 0.5504388}]OceanGate Inc. is a privately-owned American company based in Everett, Washington, founded in 2009 by Stockton Rush and Guillermo Söhnlein. The company specializes in providing crewed submersibles for various purposes, including tourism, industry, research, and exploration. The goal of OceanGate was to create a fleet of small, 5-person commercial submersibles for lease, enabling broader access to the ocean for exploration.\n",
      "\n",
      "OceanGate acquired a submersible named Antipodes and developed two additional vessels: Cyclops 1 and Titan. Notably, in 2021, they began offering expeditions for paying tourists to visit the Titanic wreck, with tickets priced at around $250,000 per person.\n",
      "\n",
      "However, tragedy struck on June 18, 2023, when the Titan submersible imploded during an expedition to the Titanic site, resulting in the loss of all five people on board, including Stockton Rush. This incident has since led to investigations into the company's operations and safety protocols.\n",
      "\n",
      "For detailed information, you can refer to [OceanGate's Wikipedia page](https://en.wikipedia.org/wiki/OceanGate).\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:42:48.570560Z",
     "start_time": "2025-05-05T22:42:48.562002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "import json\n",
    "\n",
    "\n",
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                if isinstance(chunk, AIMessage):\n",
    "                    print(chunk.content, end=\"\", flush=True)\n",
    "                if isinstance(chunk, ToolMessage):\n",
    "                    result_list = json.loads(chunk.content)\n",
    "                    print(result_list[0])\n",
    "            print(\"\\n\")"
   ],
   "id": "974ac366f97a216d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAG\n",
    "It is a method of providing LLM with data that it was not trained on, in order to improve its results. This could be the case when we want to give the model data that occurred after its training cutoff date. Training cutoff of gopt-4 mini is October 2023"
   ],
   "id": "572d8439ef7e5f09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:42:51.380797Z",
     "start_time": "2025-05-05T22:42:51.330688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.python.org/3/whatsnew/3.13.html\")"
   ],
   "id": "70f974a30bf3a447",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:43:57.311565Z",
     "start_time": "2025-05-05T22:43:55.712362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# docs is a list of one document corresponding to one url\n",
    "docs = loader.load()"
   ],
   "id": "a291a2b6cb9fb49b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:44:09.417534Z",
     "start_time": "2025-05-05T22:44:09.407716Z"
    }
   },
   "cell_type": "code",
   "source": "docs[0].metadata",
   "id": "f1e530c63c645874",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://docs.python.org/3/whatsnew/3.13.html',\n",
       " 'title': 'What’s New In Python 3.13 — Python 3.13.3 documentation',\n",
       " 'description': 'Editors, Adam Turner and Thomas Wouters,. This article explains the new features in Python 3.13, compared to 3.12. Python 3.13 was released on October 7, 2024. For full details, see the changelog. ...',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:45:08.115662Z",
     "start_time": "2025-05-05T22:45:08.105855Z"
    }
   },
   "cell_type": "code",
   "source": "print(docs[0].page_content[:2500])",
   "id": "7ddeffdf056e398b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What’s New In Python 3.13 — Python 3.13.3 documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Theme\n",
      "    \n",
      "Auto\n",
      "Light\n",
      "Dark\n",
      "\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "What’s New In Python 3.13\n",
      "Summary – Release Highlights\n",
      "New Features\n",
      "A better interactive interpreter\n",
      "Improved error messages\n",
      "Free-threaded CPython\n",
      "An experimental just-in-time (JIT) compiler\n",
      "Defined mutation semantics for locals()\n",
      "Support for mobile platforms\n",
      "\n",
      "\n",
      "Other Language Changes\n",
      "New Modules\n",
      "Improved Modules\n",
      "argparse\n",
      "array\n",
      "ast\n",
      "asyncio\n",
      "base64\n",
      "compileall\n",
      "concurrent.futures\n",
      "configparser\n",
      "copy\n",
      "ctypes\n",
      "dbm\n",
      "dis\n",
      "doctest\n",
      "email\n",
      "enum\n",
      "fractions\n",
      "glob\n",
      "importlib\n",
      "io\n",
      "ipaddress\n",
      "itertools\n",
      "marshal\n",
      "math\n",
      "mimetypes\n",
      "mmap\n",
      "multiprocessing\n",
      "os\n",
      "os.path\n",
      "pathlib\n",
      "pdb\n",
      "queue\n",
      "random\n",
      "re\n",
      "shutil\n",
      "site\n",
      "sqlite3\n",
      "ssl\n",
      "statistics\n",
      "subprocess\n",
      "sys\n",
      "tempfile\n",
      "time\n",
      "tkinter\n",
      "traceback\n",
      "types\n",
      "typing\n",
      "unicodedata\n",
      "venv\n",
      "warnings\n",
      "xml\n",
      "zipimport\n",
      "\n",
      "\n",
      "Optimizations\n",
      "Removed Modules And APIs\n",
      "PEP 594: Remove “dead batteries” from the standard library\n",
      "2to3\n",
      "builtins\n",
      "configparser\n",
      "importlib.metadata\n",
      "locale\n",
      "opcode\n",
      "optparse\n",
      "pathlib\n",
      "re\n",
      "tkinter.tix\n",
      "turtle\n",
      "typing\n",
      "unittest\n",
      "urllib\n",
      "webbrowser\n",
      "\n",
      "\n",
      "New Deprecations\n",
      "Pending Removal in Python 3.14\n",
      "Pending Removal in Python 3.15\n",
      "Pending removal in Python 3.16\n",
      "Pending Removal in Future Versions\n",
      "\n",
      "\n",
      "CPython Bytecode Changes\n",
      "C API Changes\n",
      "New Features\n",
      "Changed C APIs\n",
      "Limited C API Changes\n",
      "Removed C APIs\n",
      "Deprecated C APIs\n",
      "Pending Removal in Python 3.14\n",
      "Pending Removal in Python 3.15\n",
      "Pending Removal in Future Versions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Build Changes\n",
      "Porting to Python 3.13\n",
      "Changes in the Python API\n",
      "Changes in the C API\n",
      "\n",
      "\n",
      "Regression Test Changes\n",
      "Notable changes in 3.13.1\n",
      "sys\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Previous topic\n",
      "What’s New in Python\n",
      "\n",
      "\n",
      "Next topic\n",
      "What’s New In Python 3.12\n",
      "\n",
      "\n",
      "This Page\n",
      "\n",
      "Report a Bug\n",
      "\n",
      "Show Source\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Navigation\n",
      "\n",
      "\n",
      "index\n",
      "\n",
      "modules |\n",
      "\n",
      "next |\n",
      "\n",
      "previous |\n",
      "\n",
      "Python »\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.13.3 Documentation »\n",
      "    \n",
      "What’s New in Python »\n",
      "What’s New In Python 3.13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                     |\n",
      "                \n",
      "\n",
      "\n",
      "    Theme\n",
      "    \n",
      "Auto\n",
      "Light\n",
      "Dark\n",
      "\n",
      " |\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What’s New In Python 3.13¶\n",
      "\n",
      "Editors:\n",
      "Adam Turner and Thomas Wouters\n",
      "\n",
      "\n",
      "This article explains the new features in Python 3.13, compared to 3.12.\n",
      "Python 3.13 was released on October 7, 2024.\n",
      "For full details, see the changelog.\n",
      "\n",
      "See also\n",
      "PEP 719 – Python 3.13 Release Schedule\n",
      "\n",
      "\n",
      "Summary – Release Highlights¶\n",
      "Python 3.13 is the latest stable release of the Python programming\n",
      "language, with a mix of changes to the language, the implementation\n",
      "and the standard library.\n",
      "The biggest changes include a new interact\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:48:55.645109Z",
     "start_time": "2025-05-05T22:48:55.593260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RAG splitting\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# chunk size are in characters\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ],
   "id": "a8c6a4ff6fb68b2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:49:45.688753Z",
     "start_time": "2025-05-05T22:49:45.663879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunks = text_splitter.split_documents(docs)\n",
    "len(chunks)"
   ],
   "id": "9e6eef28bc4f8a29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T22:50:53.431567Z",
     "start_time": "2025-05-05T22:50:53.423149Z"
    }
   },
   "cell_type": "code",
   "source": "print(chunks[0].page_content)",
   "id": "95f196888d01ab55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What’s New In Python 3.13 — Python 3.13.3 documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Theme\n",
      "    \n",
      "Auto\n",
      "Light\n",
      "Dark\n",
      "\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "What’s New In Python 3.13\n",
      "Summary – Release Highlights\n",
      "New Features\n",
      "A better interactive interpreter\n",
      "Improved error messages\n",
      "Free-threaded CPython\n",
      "An experimental just-in-time (JIT) compiler\n",
      "Defined mutation semantics for locals()\n",
      "Support for mobile platforms\n",
      "\n",
      "\n",
      "Other Language Changes\n",
      "New Modules\n",
      "Improved Modules\n",
      "argparse\n",
      "array\n",
      "ast\n",
      "asyncio\n",
      "base64\n",
      "compileall\n",
      "concurrent.futures\n",
      "configparser\n",
      "copy\n",
      "ctypes\n",
      "dbm\n",
      "dis\n",
      "doctest\n",
      "email\n",
      "enum\n",
      "fractions\n",
      "glob\n",
      "importlib\n",
      "io\n",
      "ipaddress\n",
      "itertools\n",
      "marshal\n",
      "math\n",
      "mimetypes\n",
      "mmap\n",
      "multiprocessing\n",
      "os\n",
      "os.path\n",
      "pathlib\n",
      "pdb\n",
      "queue\n",
      "random\n",
      "re\n",
      "shutil\n",
      "site\n",
      "sqlite3\n",
      "ssl\n",
      "statistics\n",
      "subprocess\n",
      "sys\n",
      "tempfile\n",
      "time\n",
      "tkinter\n",
      "traceback\n",
      "types\n",
      "typing\n",
      "unicodedata\n",
      "venv\n",
      "warnings\n",
      "xml\n",
      "zipimport\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:11:27.171861Z",
     "start_time": "2025-05-05T23:11:26.333585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# embed the chunks into vectors\n",
    "# embeddings are fixed length array of numbers\n",
    "# this length is defined by the embedding model\n",
    "# the embedding model puts documents/chunks with similar meanings in the same location\n",
    "# we can calculate the semantic similarity between pairs of docs using math\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ],
   "id": "5a27451fdf0de433",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:11:30.511143Z",
     "start_time": "2025-05-05T23:11:27.909517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for now we will use an in memoery vector store which will not persist\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore.from_documents(chunks, embedding_model)"
   ],
   "id": "3fd7b0343262e44a",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:13:36.629816Z",
     "start_time": "2025-05-05T23:13:33.481832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lets create the retriever\n",
    "retriever = vector_store.as_retriever()\n",
    "results = retriever.invoke(\"new interactive interpreter\")"
   ],
   "id": "d31d72093c8f2b5",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:13:41.175686Z",
     "start_time": "2025-05-05T23:13:41.169179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# by default returns 4 chunks but can be configured\n",
    "len(results)"
   ],
   "id": "a8c04e66da155400",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:14:26.417080Z",
     "start_time": "2025-05-05T23:14:26.403443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-----\")"
   ],
   "id": "aa72e810a6faa71f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiline editing with history preservation.\n",
      "Direct support for REPL-specific commands like help, exit,\n",
      "and quit, without the need to call them as functions.\n",
      "Prompts and tracebacks with color enabled by default.\n",
      "Interactive help browsing using F1 with a separate command\n",
      "history.\n",
      "History browsing using F2 that skips output as well as the\n",
      ">>> and … prompts.\n",
      "“Paste mode” with F3 that makes pasting larger blocks of code\n",
      "easier (press F3 again to return to the regular prompt).\n",
      "\n",
      "To disable the new interactive shell,\n",
      "set the PYTHON_BASIC_REPL environment variable.\n",
      "For more on interactive mode, see Interactive Mode.\n",
      "(Contributed by Pablo Galindo Salgado, Łukasz Langa, and\n",
      "Lysandros Nikolaou in gh-111201 based on code from the PyPy project.\n",
      "Windows support contributed by Dino Viehland and Anthony Shaw.)\n",
      "\n",
      "\n",
      "Improved error messages¶\n",
      "-----\n",
      "Release schedule changes:\n",
      "PEP 602 (“Annual Release Cycle for Python”) has been updated\n",
      "to extend the full support (‘bugfix’) period for new releases to two years.\n",
      "This updated policy means that:\n",
      "\n",
      "Python 3.9–3.12 have one and a half years of full support,\n",
      "followed by three and a half years of security fixes.\n",
      "Python 3.13 and later have two years of full support,\n",
      "followed by three years of security fixes.\n",
      "\n",
      "\n",
      "\n",
      "New Features¶\n",
      "\n",
      "A better interactive interpreter¶\n",
      "Python now uses a new interactive shell by default, based on code\n",
      "from the PyPy project.\n",
      "When the user starts the REPL from an interactive terminal,\n",
      "the following new features are now supported:\n",
      "-----\n",
      "Interpreter improvements:\n",
      "\n",
      "A greatly improved interactive interpreter and\n",
      "improved error messages.\n",
      "PEP 667: The locals() builtin now has\n",
      "defined semantics when mutating the\n",
      "returned mapping. Python debuggers and similar tools may now more reliably\n",
      "update local variables in optimized scopes even during concurrent code\n",
      "execution.\n",
      "PEP 703: CPython 3.13 has experimental support for running with the\n",
      "global interpreter lock disabled. See Free-threaded CPython for more details.\n",
      "PEP 744: A basic JIT compiler was added.\n",
      "It is currently disabled by default (though we may turn it on later).\n",
      "Performance improvements are modest – we expect to improve this\n",
      "over the next few releases.\n",
      "Color support in the new interactive interpreter,\n",
      "as well as in tracebacks\n",
      "and doctest output.\n",
      "This can be disabled through the PYTHON_COLORS and NO_COLOR\n",
      "environment variables.\n",
      "\n",
      "Python data model improvements:\n",
      "-----\n",
      "Improved error messages¶\n",
      "\n",
      "The interpreter now uses color by default when displaying tracebacks in the\n",
      "terminal. This feature can be controlled\n",
      "via the new PYTHON_COLORS environment variable as well as\n",
      "the canonical NO_COLOR and FORCE_COLOR environment variables.\n",
      "(Contributed by Pablo Galindo Salgado in gh-112730.)\n",
      "\n",
      "\n",
      "A common mistake is to write a script with the same name as a\n",
      "standard library module. When this results in errors, we now\n",
      "display a more helpful error message:\n",
      "$ python random.py\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/me/random.py\", line 1, in <module>\n",
      "    import random\n",
      "  File \"/home/me/random.py\", line 3, in <module>\n",
      "    print(random.randint(5))\n",
      "          ^^^^^^^^^^^^^^\n",
      "AttributeError: module 'random' has no attribute 'randint' (consider renaming '/home/me/random.py' since it has the same name as the standard library module named 'random' and prevents importing that standard library module)\n",
      "-----\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:23:25.951471Z",
     "start_time": "2025-05-05T23:23:25.944232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever, \"python_3_13_update_retriever\",\n",
    "                                       \"A retriever that returns relevant documents from the What's New page of the Python 3.13 documentation. \"\n",
    "                                       \"Useful when you need to answer questions about the features, enhancements, removals, deprecations, and \"\n",
    "                                       \"others changes introduced in this version of Python.\"\n",
    "                                       )"
   ],
   "id": "94e43abc58024274",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# incorporate the retriever",
   "id": "c92d42ad948af6b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:48:11.129609Z",
     "start_time": "2025-05-05T23:48:11.121608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "import json"
   ],
   "id": "d9d6c0875c503d57",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:48:11.700407Z",
     "start_time": "2025-05-05T23:48:11.694841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def call_model(state: MessagesState):\n",
    "    updated_messages = model.invoke(state[\"messages\"])\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}"
   ],
   "id": "80480b0dcf544906",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:48:12.333713Z",
     "start_time": "2025-05-05T23:48:12.327845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")"
   ],
   "id": "63e7bfd096c76b4b",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:48:13.004139Z",
     "start_time": "2025-05-05T23:48:12.997273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                if isinstance(chunk, AIMessage):\n",
    "                    print(chunk.content, end=\"\", flush=True)\n",
    "                if isinstance(chunk, ToolMessage):\n",
    "                    result_list = json.loads(chunk.content)\n",
    "                    print(result_list[0])\n",
    "            print(\"\\n\")"
   ],
   "id": "b98a2008760eb103",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:48:13.687209Z",
     "start_time": "2025-05-05T23:48:13.667894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                if isinstance(chunk, AIMessage):\n",
    "                    print(chunk.content, end=\"\", flush=True)\n",
    "                if isinstance(chunk, ToolMessage):\n",
    "                    if chunk.name == 'tavily_search_results_json':\n",
    "                        print(\"Using Tavily search tool\")\n",
    "                        result_list = json.loads(chunk.content)\n",
    "                        urls = [result[\"url\"] for result in result_list]\n",
    "                        print(urls, end=\"\\n\\n\")\n",
    "                    if chunk.name == 'python_3_13_update_retriever':\n",
    "                        print(\"Checking Python documentation using RAG...\", end=\"\\n\\n\")\n",
    "            print(\"\\n\")"
   ],
   "id": "2913f81bc73789e0",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:48:17.603069Z",
     "start_time": "2025-05-05T23:48:14.691437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.linkedin.com/in/tasneemfatema/\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = InMemoryVectorStore.from_documents(chunks, embedding_model)\n",
    "retriever = vector_store.as_retriever()\n",
    "retriever_tool = create_retriever_tool(retriever, \"python_3_13_update_retriever\",\n",
    "                                       \"A retriever that returns relevant documents from the What's New page of the Python 3.13 documentation. \"\n",
    "                                       \"Useful when you need to answer questions about the features, enhancements, removals, deprecations, and \"\n",
    "                                       \"others changes introduced in this version of Python.\"\n",
    "                                       )\n",
    "\n",
    "search = TavilySearchResults(max_results=5)\n",
    "tool_list = [retriever_tool, search]\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\").bind_tools(tool_list)\n",
    "call_tool = ToolNode(tool_list)\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_node(\"tools\", call_tool)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "workflow.add_conditional_edges(\"model_node\", tools_condition)\n",
    "workflow.add_edge(\"tools\", \"model_node\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "37b029f5c4cf2a3a",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T23:59:53.832976Z",
     "start_time": "2025-05-05T23:59:27.125699Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot(99_999)",
   "id": "c584f5c05640a2ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "Using Tavily search tool\n",
      "['https://bd.linkedin.com/in/nafe-muhtasim-hye', 'https://orcid.org/0009-0005-7978-4622', 'https://www.researchgate.net/profile/Nafe-Hye', 'https://ieeexplore.ieee.org/author/37089820409', 'https://aust.academia.edu/NafeMuhtasimHye']\n",
      "\n",
      "Nafe Muhtasim Hye is a professional with a background in electrical and electronics engineering. He obtained his BSc degree from Ahsanullah University of Science and Technology (AUST) in 2021. His work focuses on addressing critical challenges in the biomedical field through the integration of artificial intelligence and machine learning.\n",
      "\n",
      "He has been involved in significant projects, including being part of Bangladesh's pioneering MARS Rover team during his studies. Currently, he serves as the Chief Operating Officer at Consel Health.\n",
      "\n",
      "For more detailed information, you can check his [LinkedIn profile](https://bd.linkedin.com/in/nafe-muhtasim-hye) or [ORCID page](https://orcid.org/0009-0005-7978-4622).\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af93a276f0b94413"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
