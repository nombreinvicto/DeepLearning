{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-05T02:28:37.181501Z",
     "start_time": "2025-05-05T02:28:25.613317Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# objects to build workflow using graphs\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "\n",
    "# in memory checkpointer that enables the app\n",
    "# to remember past conversations\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "ret = load_dotenv()\n",
    "\n",
    "# returns True if .env loaded successfully\n",
    "print(ret)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T02:28:53.288Z",
     "start_time": "2025-05-05T02:28:49.543181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "model_response = model.invoke(\"Tell me about Dexcom Stelo\")\n",
    "print(model_response)"
   ],
   "id": "bfe3bafcb8e5fcaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='As of my last knowledge update in October 2021, Dexcom had announced the Dexcom G7 continuous glucose monitoring (CGM) system, but there was no specific information available about a product called \"Dexcom Stelo.\" It’s possible that \"Dexcom Stelo\" could refer to a new product or innovation that has been introduced after that date or could be a misunderstanding or miscommunication of another product name.\\n\\nDexcom is known for its advancements in CGM technology, which helps people with diabetes monitor their glucose levels in real-time. The devices typically consist of a small sensor inserted under the skin that measures glucose levels and transmits the data to a smartphone or other device.\\n\\nIf \"Dexcom Stelo\" is a recent development, I recommend checking the official Dexcom website or credible news sources for the most accurate and up-to-date information. Please let me know if there\\'s something specific you would like to know!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 187, 'prompt_tokens': 14, 'total_tokens': 201, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None} id='run--c530eaca-52d8-413e-9e32-938d655b8d86-0' usage_metadata={'input_tokens': 14, 'output_tokens': 187, 'total_tokens': 201, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:43.407463Z",
     "start_time": "2025-05-04T02:30:43.397024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    # state = current state of the graph, which is a list of messages\n",
    "    # state[\"messages\"] is a list of all historical messages\n",
    "    updated_messages = model.invoke(state[\"messages\"])\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}"
   ],
   "id": "7f487748c7b42acc",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:44.393068Z",
     "start_time": "2025-05-04T02:30:44.378929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# workflow is a stategraph, keeps track of the state of the application\n",
    "# we need to use a schema, MessagesState helps to keep track a list\n",
    "# of messages. in other words, we are saying the state the worflow\n",
    "# gonna keep track of is a list of messages\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# nodes take as input the current state of the graph\n",
    "# they do something and then they update the state\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "\n",
    "# after START, run the model node which calls the model\n",
    "# add an edge from the START node to the model node\n",
    "# edges determine which node to execute next, based on current state\n",
    "workflow.add_edge(START, \"model_node\")"
   ],
   "id": "b4112da7945a6d1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x274eb14af00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:44.879968Z",
     "start_time": "2025-05-04T02:30:44.871967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# real apps will use Postgres or SQlite checkpointers\n",
    "# for experimentation use in memory checkpointer\n",
    "# checkpointers store snapshots of past conversation\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "3e80023bf7187004",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:51.798512Z",
     "start_time": "2025-05-04T02:30:50.942817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# app is now a runnable object so has invoke method\n",
    "# because schema used is MessagesState, input expected\n",
    "# is dict of {'messages': \"\"}\n",
    "\n",
    "chat1 = {'configurable': {'thread_id': 1}}\n",
    "app.invoke({\"messages\": \"Hi My name is Mahmud!\"}, config=chat1)"
   ],
   "id": "838a8b368f1de90e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi My name is Mahmud!', additional_kwargs={}, response_metadata={}, id='1d7649b1-a1c8-42c3-83e3-78893b37f699'),\n",
       "  AIMessage(content='Hi Mahmud! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 14, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None}, id='run-32306904-4535-4905-a7ff-2c2ab97ba71d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 12, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:55.067948Z",
     "start_time": "2025-05-04T02:30:54.255319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# look at the reply. the whole conversation is here\n",
    "app.invoke({\"messages\": \"What is my name!\"}, config=chat1)"
   ],
   "id": "8815c59bc40ddd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi My name is Mahmud!', additional_kwargs={}, response_metadata={}, id='1d7649b1-a1c8-42c3-83e3-78893b37f699'),\n",
       "  AIMessage(content='Hi Mahmud! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 14, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None}, id='run-32306904-4535-4905-a7ff-2c2ab97ba71d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 12, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='What is my name!', additional_kwargs={}, response_metadata={}, id='ba600d4b-9ccf-4b7b-b359-1fd0eda9ea48'),\n",
       "  AIMessage(content='Your name is Mahmud! How can I help you further?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 38, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-464d4cd2-13e8-4de2-bd21-3edc2ad4d9e9-0', usage_metadata={'input_tokens': 38, 'output_tokens': 14, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:30:58.941880Z",
     "start_time": "2025-05-04T02:30:58.934829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = app.invoke(None, config=chat1)\n",
    "for message in output[\"messages\"]:\n",
    "    message.pretty_print()"
   ],
   "id": "8543780c1a19c48c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hi My name is Mahmud!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hi Mahmud! How can I assist you today?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is my name!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Your name is Mahmud! How can I help you further?\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:31:04.495483Z",
     "start_time": "2025-05-04T02:31:03.790070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# can the app support multiple independant conversations?\n",
    "chat2 = {'configurable': {'thread_id': 2}}\n",
    "app.invoke({\"messages\": \"What is my name!\"}, config=chat2)[\"messages\"][-1].content"
   ],
   "id": "ae646e4a1b914437",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. If you tell me, I can use it in our conversation!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This time the app doesnt know my name confirming this is an entirely different chat",
   "id": "e9a748714965aef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:31:13.482369Z",
     "start_time": "2025-05-04T02:31:13.471320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make the app more interactive\n",
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")\n"
   ],
   "id": "2f41d290a69d8b78",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:32:08.832128Z",
     "start_time": "2025-05-04T02:31:17.899983Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot(2)",
   "id": "a6a6bee8f637f5c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "Nice to meet you, Mahmud Hasan! How can I assist you today?\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "Las Vegas is famous for a variety of reasons, including:\n",
      "\n",
      "1. **Casinos and Gambling**: Las Vegas is known as the gambling capital of the world, with numerous casinos offering a wide range of gaming options.\n",
      "\n",
      "2. **Entertainment**: The city is renowned for its entertainment options, including world-class shows, concerts, magic acts, and performances by famous artists.\n",
      "\n",
      "3. **Nightlife**: Las Vegas boasts a vibrant nightlife scene, with many nightclubs, bars, and lounges that attract visitors from around the globe.\n",
      "\n",
      "4. **Resorts and Hotels**: The Strip is lined with extravagant hotels and resorts, each offering unique themes and attractions, such as the Bellagio, Caesars Palace, and The Venetian.\n",
      "\n",
      "5. **Dining**: Las Vegas offers a diverse culinary scene, with numerous fine dining restaurants run by celebrity chefs, buffets, and international cuisine.\n",
      "\n",
      "6. **Shopping**: The city features luxury shopping experiences, including high-end boutiques and outlet malls.\n",
      "\n",
      "7. **Conventions and Events**: Las Vegas hosts numerous conventions, trade shows, and events throughout the year, making it a popular destination for business travelers.\n",
      "\n",
      "8. **Themed Attractions**: There are many attractions that reflect different cultures and themes, such as the Eiffel Tower at Paris Las Vegas, canals at The Venetian, and the Colosseum at Caesars Palace.\n",
      "\n",
      "9. **Natural Beauty**: Beyond the city, Las Vegas is close to beautiful natural attractions like Red Rock Canyon and the Hoover Dam, offering outdoor recreation options.\n",
      "\n",
      "10. **Weddings**: Las Vegas is a popular destination for quick and often themed weddings, with many chapels available for couples looking to tie the knot.\n",
      "\n",
      "These elements combine to make Las Vegas a unique and popular destination for millions of visitors each year.\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding a system prompt",
   "id": "f584b9e0536a32e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:35:14.960982Z",
     "start_time": "2025-05-04T02:35:14.953229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# System messages are used to direct the behavior of the LLM.We will use chat prompt templates to send system messages\n",
    "\n",
    "# ChatPromptTemplate =  a reusable structure for creating prompts for chat apps\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ],
   "id": "afd6c2544da979c9",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:38:13.825511Z",
     "start_time": "2025-05-04T02:38:13.794840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tuples of message types and messages\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"Limit all of your responses to two sentences\"),\n",
    "        (\"placeholder\", \"{messages}\")  # telling the prompt template\n",
    "        # is expected to get a variable messages when invoked. this variable will\n",
    "        # come from the state that is passed to the call function\n",
    "    ]\n",
    ")"
   ],
   "id": "503aa98620db6f88",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:39:51.395792Z",
     "start_time": "2025-05-04T02:39:51.387516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# state is a dict with key messages and value a list of HumanMessages\n",
    "state = {\"messages\": [\"What is the history of Delta Airlines\"]}"
   ],
   "id": "19c7a19de35dc4e9",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:40:30.098611Z",
     "start_time": "2025-05-04T02:40:30.077026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prompt also has a invoke model\n",
    "prompt.invoke(state)"
   ],
   "id": "60f3d6e97c1dc7b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Limit all of your responses to two sentences', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the history of Delta Airlines', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:41:17.787410Z",
     "start_time": "2025-05-04T02:41:16.219400Z"
    }
   },
   "cell_type": "code",
   "source": "model.invoke(prompt.invoke(state))",
   "id": "240c9c1a2269e636",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Delta Airlines was founded in 1925 as a crop-dusting service called Huff Daland Dusters. It transitioned to passenger airline operations in 1929 and expanded significantly through mergers and acquisitions, becoming one of the largest airlines in the world.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 26, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-cc016ee3-1218-4449-95ea-ca0ed750b1fa-0', usage_metadata={'input_tokens': 26, 'output_tokens': 50, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chaining multiple actions",
   "id": "7c720e094641f0fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:43:40.198244Z",
     "start_time": "2025-05-04T02:43:38.311800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this is a chain of actions = model.invoke(prompt.invoke(state))\n",
    "# run the steps in order from left to right\n",
    "# chains are like scikit learn pipelines\n",
    "chain = prompt | model\n",
    "chain.invoke(state)"
   ],
   "id": "1ab92c629ee767ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Delta Airlines was founded in 1924 as a crop-dusting operation called Huff Daland Dusters and later transitioned to passenger flights in 1929. Over the decades, it expanded through numerous mergers and acquisitions, becoming one of the largest and most significant airlines in the world.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 26, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-ea74da98-d0d2-47c4-978b-9efbfa21f748-0', usage_metadata={'input_tokens': 26, 'output_tokens': 57, 'total_tokens': 83, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Integrating prompt in workflow code",
   "id": "b00bc5c17f4d211a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:47:30.215300Z",
     "start_time": "2025-05-04T02:47:30.209479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    # state = current state of the graph, which is a list of messages\n",
    "    # state[\"messages\"] is a list of all historical messages\n",
    "    chain = prompt | model\n",
    "    updated_messages = chain.invoke(state)\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}"
   ],
   "id": "40019631f5ee7fa5",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:47:54.163857Z",
     "start_time": "2025-05-04T02:47:54.157845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "487e217f6ad1d384",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:50:37.971547Z",
     "start_time": "2025-05-04T02:48:54.223298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we have a chatbot that onyl gives short answerss\n",
    "chatbot(2)"
   ],
   "id": "4847d01fd07367de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "Mahmud Hasan may refer to various individuals; could you specify which one or provide more context? Notable figures with that name could include politicians, academics, or athletes.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "Mahmud Hasan is a prominent Bangladeshi politician and a member of the Awami League party. He has been involved in various political activities and has served in different capacities within the government.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "The Awami League is one of the major political parties in Bangladesh, founded in 1949. It played a significant role in the country's struggle for independence and is known for advocating secularism, socialism, and democracy.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "The Bangladesh Nationalist Party (BNP) is a major political party in Bangladesh, founded in 1978 by former President Ziaur Rahman. The party is known for its nationalist ideology and has been a significant political rival to the Awami League, often advocating for conservative and pro-Islamist policies.\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "If you have any more questions in the future, feel free to ask. Have a great day!\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "Exiting now. Take care!\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "It seems there was no further request. If you need assistance later, just let me know!\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# now we have a chatbot that onyl gives short answerss\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mchatbot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[26], line 7\u001B[0m, in \u001B[0;36mchatbot\u001B[1;34m(chat_id)\u001B[0m\n\u001B[0;32m      4\u001B[0m config \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigurable\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthread_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: chat_id}}\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m----> 7\u001B[0m     user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mUser: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m user_input \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquit\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGoodbye\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\GoogleDrive\\GitHub\\DeepLearning\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\GoogleDrive\\GitHub\\DeepLearning\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4bc62017787290bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Translation to Spanish",
   "id": "411bdf40498a29af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:56:00.124390Z",
     "start_time": "2025-05-04T02:55:58.547806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# change in the prompt\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"Translate the input from English to Spanish\"),\n",
    "        (\"placeholder\", \"{messages}\")  # telling the prompt template\n",
    "        # is expected to get a variable messages when invoked. this variable will\n",
    "        # come from the state that is passed to the call function\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    # state = current state of the graph, which is a list of messages\n",
    "    # state[\"messages\"] is a list of all historical messages\n",
    "    chain = prompt | model\n",
    "    updated_messages = chain.invoke(state)\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "ce11390c776686cc",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T02:56:43.694056Z",
     "start_time": "2025-05-04T02:56:11.980164Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot(3)",
   "id": "e2fa3fa3357d28e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "hola\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "¿Cuál es tu nombre?\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "¿Dónde está México?\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T03:13:34.407115Z",
     "start_time": "2025-05-04T03:13:33.668174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# translate to any language\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# change in the prompt\n",
    "# add a variable called language to the prompt template\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"Translate the input from English to {language}\"),\n",
    "        (\"placeholder\", \"{messages}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# %% ##################################################################\n",
    "# MessagesState objects only have a single key called mesages\n",
    "# we need to extend this class to also add another key language\n",
    "# which will be passed to app.invoke eventually\n",
    "class CustomState(MessagesState):\n",
    "    language: str\n",
    "\n",
    "\n",
    "# %% ##################################################################\n",
    "\n",
    "def call_model(state: CustomState):\n",
    "    chain = prompt | model\n",
    "    updated_messages = chain.invoke(state)\n",
    "    return {\"messages\": updated_messages}\n",
    "\n",
    "\n",
    "workflow = StateGraph(CustomState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "c341e0423c4813ee",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T03:18:34.321922Z",
     "start_time": "2025-05-04T03:18:34.300933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translatebot(language: str):\n",
    "    # since there is no notion of conversation for translatebot\n",
    "    # we will just set the chatid to a fixed number\n",
    "    config = {\"configurable\": {\"thread_id\": 999}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input, \"language\": language},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")"
   ],
   "id": "2957edf27b2e5d9f",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T03:19:19.925072Z",
     "start_time": "2025-05-04T03:18:35.078771Z"
    }
   },
   "cell_type": "code",
   "source": "translatebot(\"Bengali\")",
   "id": "42f07212ccbbb140",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "আমি ইমুকে ভালোবাসি!\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "তুমি কোথায় ইমু? দয়া করে আমার কাছে এসো!!!\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "154eac880f810dbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Updating App with real time search",
   "id": "169814bc177e3a9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T02:33:44.678636Z",
     "start_time": "2025-05-05T02:33:44.655531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def call_model(state: MessagesState):\n",
    "    updated_messages = model.invoke(state[\"messages\"])\n",
    "\n",
    "    # models response appended to the existing list of messages\n",
    "    return {\"messages\": updated_messages}"
   ],
   "id": "a53b53bbcdfbd62",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T02:33:45.910007Z",
     "start_time": "2025-05-05T02:33:45.897545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")"
   ],
   "id": "cf0880d85b2adac8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Tools allow LLMs to perform actions and retrieve data from external sources. Tools is what we use to extend the capabilities of Langchain based apps. First tool we use is tavily-search. Search engine for LLMs. We need to create an account in Tavily and create API-key.\n",
    "\n",
    "You tell the model that this tool is availabel for use, and you'll tell the model whatthe tool does. for a given input to the model, the model itself decides if it has to use the tool."
   ],
   "id": "9628379bfeca5cc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T02:33:47.719726Z",
     "start_time": "2025-05-05T02:33:47.694592Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "5a4a3c33289b39fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T02:33:48.851185Z",
     "start_time": "2025-05-05T02:33:48.839199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "search = TavilySearchResults(max_results=5)\n",
    "tool_list = [search]"
   ],
   "id": "d3cb20990903f71a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T02:33:51.229287Z",
     "start_time": "2025-05-05T02:33:50.478218Z"
    }
   },
   "cell_type": "code",
   "source": "model = ChatOpenAI(model_name=\"gpt-4o-mini\").bind_tools(tool_list)",
   "id": "2ab863d75b593d1a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T02:33:52.744051Z",
     "start_time": "2025-05-05T02:33:52.733561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "call_tool = ToolNode(tool_list)"
   ],
   "id": "90aeffef5b41c67d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T02:36:06.418676Z",
     "start_time": "2025-05-05T02:36:06.379501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_node(\"tools\",call_tool)\n",
    "\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "workflow.add_conditional_edges(\"model_node\", tools_condition)\n",
    "workflow.add_edge(\"tools\", \"model_node\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ],
   "id": "a2c9e3ebaf4ef992",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T04:26:39.559824Z",
     "start_time": "2025-05-05T04:25:03.050292Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot(4)",
   "id": "4872635b6eaf221d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot reply:\n",
      "\n",
      "The first five U.S. presidents are:\n",
      "\n",
      "1. George Washington (1789-1797)\n",
      "2. John Adams (1797-1801)\n",
      "3. Thomas Jefferson (1801-1809)\n",
      "4. James Madison (1809-1817)\n",
      "5. James Monroe (1817-1825)\n",
      "\n",
      "Chatbot reply:\n",
      "\n",
      "[{\"title\": \"Premarket Approval (PMA) - FDA\", \"url\": \"https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfpma/pma.cfm?ID=P120005S091\", \"content\": \"approved in the original PMA.  Be sure to look at theoriginal PMArecord for more information.DeviceG5 Mobile Continuous Glucose Monitoring System, G6 Continuous Glucose Monitoring System, G7 Continuous Glucose MonitorinGeneric NameSensor, glucose, invasiveApplicantDEXCOM, INC.6340 SEQUENCE DRSAN DIEGO, CA 92121PMA NumberP120005Supplement NumberS091Date Received11/15/2023Decision Date01/09/2024Product CodeMDSAdvisory CommitteeClinical ChemistrySupplement TypeNormal 180 Day Track No User [...] approved in the original PMA.  Be sure to look at theoriginal PMArecord for more information.DeviceG5 Mobile Continuous Glucose Monitoring System, G6 Continuous Glucose Monitoring System, G7 Continuous Glucose MonitorinGeneric NameSensor, glucose, invasiveApplicantDEXCOM, INC.6340 SEQUENCE DRSAN DIEGO, CA 92121PMA NumberP120005Supplement NumberS091Date Received11/15/2023Decision Date01/09/2024Product CodeMDSAdvisory CommitteeClinical ChemistrySupplement TypeNormal 180 Day Track No User [...] approved in the original PMA.  Be sure to look at theoriginal PMArecord for more information. |  | Device | G5 Mobile Continuous Glucose Monitoring System, G6 Continuous Glucose Monitoring System, G7 Continuous Glucose Monitorin | Generic Name | Sensor, glucose, invasive | Applicant | DEXCOM, INC.6340 SEQUENCE DRSAN DIEGO, CA 92121 | PMA Number | P120005 | Supplement Number | S091 | Date Received | 11/15/2023 | Decision Date | 01/09/2024 | Product Code | MDS | Advisory Committee | Clinical\", \"score\": 0.8674071}, {\"title\": \"Dexcom G7 15 Day Receives FDA Clearance: the Longest Lasting ...\", \"url\": \"https://finance.yahoo.com/news/dexcom-g7-15-day-receives-123000824.html\", \"content\": \"1 Dexcom, Data on File, 2025. 2 Dexcom, Data on File, 2023. 3 Garg SK, et al. Diabetes Technol Ther. 2025. doi: 10.1089/dia.2025.0139. Epub ahead of print. 4 Beck RW, et al. JAMA. 2017;317(4):371-378. 5 Beck RW, et al. Ann Intern Med. 2017;167(6):365-374. 6 Martens T, et al. JAMA. 2021;325(22):2262-2272. 7 Laffel LM, et al. JAMA. 2020;323(23):2388-2396. 8 Welsh JB, et al. J Diabetes Sci Technol. 2024;18(1):143-7. 9 Polonsky WH, et al. Diabetes Technol Ther. 2021;23(3):195-202. [...] \\\"The approval of Dexcom G7 15 Day marks another major innovation for Dexcom,\\\" said Jake Leach, executive vice president and chief operating officer at Dexcom. \\\"By listening to the needs of our users, we’re proud to offer the longest lasting wearable and most accurate CGM, giving people the knowledge to better control their diabetes with our best-in-class technology. This milestone sets a new standard in CGM and is a testament to our continued leadership in glucose biosensing. We look forward to [...] SAN DIEGO, April 10, 2025--(BUSINESS WIRE)--DexCom, Inc. (NASDAQ:DXCM), the global leader in glucose biosensing, announced today the FDA has cleared the Dexcom G7 15 Day Continuous Glucose Monitoring System for people over the age of 18 with diabetes in the United States. With an overall MARD of 8.0%,3 Dexcom G7 15 Day builds on the performance of Dexcom CGM, which is clinically proven to lower A1C, reduce hyper- and hypoglycemia and increase time in range.4-8\", \"score\": 0.65359193}, {\"title\": \"FDA Clears New Dexcom G7 15 Day Continuous Glucose ...\", \"url\": \"https://www.drugtopics.com/view/fda-clears-new-dexcom-g7-15-day-continuous-glucose-monitoring-system\", \"content\": \"“The approval of Dexcom G7 15 Day marks another major innovation for Dexcom,” Jake Leach, executive vice president and chief operating officer at Dexcom, said in a news release.1 “By listening to the needs of our users, we’re proud to offer the longest lasting wearable and most accurate CGM, giving people the knowledge to better control their diabetes with our best-in-class technology. This milestone sets a new standard in CGM and is a testament to our continued leadership in glucose [...] The FDA cleared the new Dexcom G7 15 Day Continuous Glucose Monitoring (CGM) System for patients 18 years and older with diabetes. The device builds on the performance of other Dexcom CGMs and has an overall mean absolute relative difference (MARD) of 8%, which increases the accuracy over other CGMs.1\\n\\nPharmacists have positive impacts on health outcomes for diabetes and patients using CGM devices, including reductions in A1c. | Image Credit: Dulin - stock.adobe.com\", \"score\": 0.586926}, {\"title\": \"FDA Clears Dexcom G7 15 Day, Marking the Longest-Lasting CGM ...\", \"url\": \"https://www.pharmacytimes.com/view/fda-clears-dexcom-g7-15-day-marking-the-longest-lasting-cgm-system\", \"content\": \"The now-approved Dexcom G7 15 Day system furthers the significant progress made in the diabetes technology space. Like the Dexcom G7, the 15 Day system is the only waterproof CGM available. The sensor can be connected directly to users’ Apple Watches, and it provides simplified meal logging and medication logging, as well as the ability to remotely share glucose numbers with caregivers.1 [...] 1. Dexcom G7 15 Day Receives FDA Clearance: the Longest Lasting Wearable and Most Accurate CGM System. News release. Dexcom. April 10, 2025. Accessed April 10, 2025. https://investors.dexcom.com/news/news-details/2025/Dexcom-G7-15-Day-Receives-FDA-Clearance-the-Longest-Lasting-Wearable-and-Most-Accurate-CGM-System/default.aspx\", \"score\": 0.5167668}, {\"title\": \"Dexcom G7 15 Day Receives FDA Clearance: the Longest Lasting ...\", \"url\": \"https://investors.dexcom.com/news/news-details/2025/Dexcom-G7-15-Day-Receives-FDA-Clearance-the-Longest-Lasting-Wearable-and-Most-Accurate-CGM-System/default.aspx\", \"content\": \"Dexcom G7 15 Day is now cleared in the US for people age 18 years and above with diabetes. “The approval of Dexcom G7 15 Day marks another\", \"score\": 0.47373086}]Yes, Dexcom recently received FDA clearance for the Dexcom G7 15 Day Continuous Glucose Monitoring (CGM) System. This system is designed for individuals aged 18 and older with diabetes and offers the longest-lasting wearable CGM available. It is known for its accuracy, with an overall mean absolute relative difference (MARD) of 8.0%.\n",
      "\n",
      "For more details, you can check the following sources:\n",
      "1. [FDA Clearance Announcement](https://finance.yahoo.com/news/dexcom-g7-15-day-receives-123000824.html)\n",
      "2. [Detailed Overview on Innovation](https://www.drugtopics.com/view/fda-clears-new-dexcom-g7-15-day-continuous-glucose-monitoring-system) \n",
      "\n",
      "The new product aims to further enhance diabetes management by providing users more reliable glucose monitoring capabilities.\n",
      "\n",
      "Goodbye\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.messages import AIMessage,ToolMessage\n",
    "import json\n",
    "\n",
    "def chatbot(chat_id: int):\n",
    "    # this config dict is required because we are using a checkpointer\n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"Goodbye\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Chatbot reply:\\n\")\n",
    "            for chunk, metadata in app.stream({'messages': user_input},\n",
    "                                              config=config,\n",
    "                                              stream_mode=\"messages\"):\n",
    "                if isinstance(chunk, AIMessage):\n",
    "                    print(chunk.content, end=\"\", flush=True)\n",
    "                if isinstance(chunk, ToolMessage):\n",
    "                    result_list = json.loads(chunk.content)\n",
    "                    print(result_list[0])\n",
    "            print(\"\\n\")"
   ],
   "id": "974ac366f97a216d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
