{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from cv2 import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.axes._axes as axes\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# import the necessary keras packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from loader_util.preprocessing import ImageToArrayPreprocessor, AspectAwarePreprocessor\n",
    "from loader_util.datasets import SimpleDatasetLoader\n",
    "from loader_util.nn.conv import FCHeadNet\n",
    "##\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "from imutils import paths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# import scoring and utility functions from sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, ShuffleSplit\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "#\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import NearestNeighbors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114458, 3136)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_input (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "=================================================================\n",
      "Total params: 65,760\n",
      "Trainable params: 65,376\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the hdf5 dataset\n",
    "data_dir = r\"C:\\Users\\mhasa\\GDrive\\mvcnn\"\n",
    "signature_db = h5py.File(name=f\"{data_dir}//data_sig_col_roi_28px_255.hdf5\",\n",
    "                         mode=\"r\")\n",
    "extracted_features = signature_db['extracted_features'][:]\n",
    "print(extracted_features.shape)\n",
    "\n",
    "# load the model\n",
    "loaded_model = load_model(f\"{data_dir}//model_mvcnn_color_roi_10class_28px1px_255_minvgg.h5\")\n",
    "flatten_layer = loaded_model.layers[16]\n",
    "retrieval_model = Model(inputs=loaded_model.input, outputs=flatten_layer.output)\n",
    "retrieval_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# do kdtree nn\n",
    "nn = NearestNeighbors(n_neighbors=5,\n",
    "                      algorithm='kd_tree').fit(extracted_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# read the sample image and get its signature\n",
    "img = cv2.imread(f\"{data_dir}//sample_gasket.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img = img.astype('float32')\n",
    "img = img / 255.0\n",
    "\n",
    "# channel dim and batch dim since we doing feature extraction\n",
    "img = np.expand_dims(img, axis=-1)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "source_part_sig = retrieval_model.predict(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "dist, index = nn.kneighbors(source_part_sig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    " # get he neighbor names\n",
    "indices = np.sort(index)[0]\n",
    "neighbor_names = signature_db['label_names'][indices]\n",
    "neighbor_names = np.array([n.decode() for n in neighbor_names])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "target_dir = r\"C:\\Users\\mhasa\\Desktop\\neighbors\"\n",
    "\n",
    "pristine_retrieve_models_dir = r\"C:\\Users\\mhasa\\Desktop\\retrieval_models\"\n",
    "image_paths = list(paths.list_images(pristine_retrieve_models_dir))\n",
    "\n",
    "for path in image_paths:\n",
    "    image_name = path.split(os.path.sep)[-1]\n",
    "\n",
    "    if image_name in list(neighbor_names):\n",
    "        shutil.copy2(src=path,\n",
    "                     dst=f\"{target_dir}//{image_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}