{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "mvcnn_10class_28px1px_color_roi_minvgg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgFKbnZ-Vnlp",
        "outputId": "d8d05fb7-bd57-4f8b-ef91-f70c56db65cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mfwVKYtUqam",
        "outputId": "568d7f5a-f1b8-4fff-fd65-96058f471ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip \"/content/drive/My Drive/loader_util.zip\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/loader_util.zip\n",
            "   creating: loader_util/\n",
            "   creating: loader_util/callbacks/\n",
            "  inflating: loader_util/callbacks/epochcheckpoint.py  \n",
            "  inflating: loader_util/callbacks/trainingmonitor.py  \n",
            "  inflating: loader_util/callbacks/__init__.py  \n",
            "   creating: loader_util/callbacks/__pycache__/\n",
            "  inflating: loader_util/callbacks/__pycache__/epochcheckpoint.cpython-36.pyc  \n",
            "  inflating: loader_util/callbacks/__pycache__/trainingmonitor.cpython-36.pyc  \n",
            "  inflating: loader_util/callbacks/__pycache__/__init__.cpython-36.pyc  \n",
            "   creating: loader_util/datasets/\n",
            "  inflating: loader_util/datasets/simpledatasetloader.py  \n",
            "  inflating: loader_util/datasets/torch_dataset_loader.py  \n",
            "  inflating: loader_util/datasets/torch_train_test_split.py  \n",
            "  inflating: loader_util/datasets/__init__.py  \n",
            "   creating: loader_util/datasets/__pycache__/\n",
            "  inflating: loader_util/datasets/__pycache__/simpledatasetloader.cpython-36.pyc  \n",
            "  inflating: loader_util/datasets/__pycache__/torch_dataset_loader.cpython-36.pyc  \n",
            "  inflating: loader_util/datasets/__pycache__/torch_train_test_split.cpython-36.pyc  \n",
            "  inflating: loader_util/datasets/__pycache__/__init__.cpython-36.pyc  \n",
            "   creating: loader_util/deepgooglenet/\n",
            "  inflating: loader_util/deepgooglenet/build_tiny_imagenet.py  \n",
            "   creating: loader_util/deepgooglenet/config/\n",
            "  inflating: loader_util/deepgooglenet/config/tiny_imagenet_config.py  \n",
            " extracting: loader_util/deepgooglenet/config/__init__.py  \n",
            "   creating: loader_util/deepgooglenet/config/__pycache__/\n",
            "  inflating: loader_util/deepgooglenet/config/__pycache__/tiny_imagenet_config.cpython-36.pyc  \n",
            "  inflating: loader_util/deepgooglenet/config/__pycache__/__init__.cpython-36.pyc  \n",
            "   creating: loader_util/deepgooglenet/output/\n",
            "   creating: loader_util/deepgooglenet/output/checkpoints/\n",
            " extracting: loader_util/deepgooglenet/output/checkpoints/__init__.py  \n",
            " extracting: loader_util/deepgooglenet/output/tiny-image-net-200-mean.json  \n",
            " extracting: loader_util/deepgooglenet/output/__init__.py  \n",
            " extracting: loader_util/deepgooglenet/rank_accuracy.py  \n",
            " extracting: loader_util/deepgooglenet/train.py  \n",
            "   creating: loader_util/dogs_vs_cats/\n",
            "  inflating: loader_util/dogs_vs_cats/build_dogs_vs_cats.py  \n",
            "   creating: loader_util/dogs_vs_cats/config/\n",
            "  inflating: loader_util/dogs_vs_cats/config/dog_vs_cats_config.py  \n",
            " extracting: loader_util/dogs_vs_cats/config/__init__.py  \n",
            "   creating: loader_util/dogs_vs_cats/config/__pycache__/\n",
            "  inflating: loader_util/dogs_vs_cats/config/__pycache__/dog_vs_cats_config.cpython-36.pyc  \n",
            "  inflating: loader_util/dogs_vs_cats/config/__pycache__/__init__.cpython-36.pyc  \n",
            "   creating: loader_util/dogs_vs_cats/output/\n",
            " extracting: loader_util/dogs_vs_cats/output/__init__.py  \n",
            " extracting: loader_util/dogs_vs_cats/__init__.py  \n",
            "   creating: loader_util/dogs_vs_cats/__pycache__/\n",
            "  inflating: loader_util/dogs_vs_cats/__pycache__/__init__.cpython-36.pyc  \n",
            "   creating: loader_util/io/\n",
            "  inflating: loader_util/io/hdf5datasetgenerator.py  \n",
            "  inflating: loader_util/io/hdf5_dataset_writer.py  \n",
            "  inflating: loader_util/io/hdf5_dataset_writer_research_nlp.py  \n",
            "  inflating: loader_util/io/__init__.py  \n",
            "   creating: loader_util/io/__pycache__/\n",
            "  inflating: loader_util/io/__pycache__/hdf5datasetgenerator.cpython-36.pyc  \n",
            "  inflating: loader_util/io/__pycache__/hdf5_dataset_writer.cpython-36.pyc  \n",
            "  inflating: loader_util/io/__pycache__/hdf5_dataset_writer_research_nlp.cpython-36.pyc  \n",
            "  inflating: loader_util/io/__pycache__/__init__.cpython-36.pyc  \n",
            "   creating: loader_util/nn/\n",
            "   creating: loader_util/nn/conv/\n",
            "  inflating: loader_util/nn/conv/alexnet.py  \n",
            "  inflating: loader_util/nn/conv/deepergooglenet.py  \n",
            "  inflating: loader_util/nn/conv/fcheadnet.py  \n",
            "  inflating: loader_util/nn/conv/lenet.py  \n",
            "  inflating: loader_util/nn/conv/lenet_batchnorm.py  \n",
            "  inflating: loader_util/nn/conv/lenet_torch.py  \n",
            "  inflating: loader_util/nn/conv/minigooglenet.py  \n",
            "  inflating: loader_util/nn/conv/minvggnet.py  \n",
            "  inflating: loader_util/nn/conv/resnet.py  \n",
            "  inflating: loader_util/nn/conv/shallownet.py  \n",
            "  inflating: loader_util/nn/conv/shallownet_torch.py  \n",
            "  inflating: loader_util/nn/conv/__init__.py  \n",
            "   creating: loader_util/nn/conv/__pycache__/\n",
            "  inflating: loader_util/nn/conv/__pycache__/alexnet.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/deepergooglenet.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/fcheadnet.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/lenet.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/lenet.cpython-37.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/lenet_batchnorm.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/minigooglenet.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/minvggnet.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/minvggnet.cpython-37.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/resnet.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/shallownet.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/shallownet.cpython-37.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/shallownet_torch.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/conv/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: loader_util/nn/perceptron.py  \n",
            " extracting: loader_util/nn/__init__.py  \n",
            "   creating: loader_util/nn/__pycache__/\n",
            "  inflating: loader_util/nn/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: loader_util/nn/__pycache__/__init__.cpython-37.pyc  \n",
            "   creating: loader_util/preprocessing/\n",
            "  inflating: loader_util/preprocessing/aspect_aware_preprocessing.py  \n",
            "  inflating: loader_util/preprocessing/croppreprocessor.py  \n",
            "  inflating: loader_util/preprocessing/imagetoarraypreprocesor.py  \n",
            "  inflating: loader_util/preprocessing/meanpreprocessor.py  \n",
            "  inflating: loader_util/preprocessing/mean_subtraction_legacy.py  \n",
            "  inflating: loader_util/preprocessing/patchpreprocessor.py  \n",
            "  inflating: loader_util/preprocessing/simplepreprocesor.py  \n",
            "  inflating: loader_util/preprocessing/__init__.py  \n",
            "   creating: loader_util/preprocessing/__pycache__/\n",
            "  inflating: loader_util/preprocessing/__pycache__/aspect_aware_preprocessing.cpython-36.pyc  \n",
            "  inflating: loader_util/preprocessing/__pycache__/croppreprocessor.cpython-36.pyc  \n",
            "  inflating: loader_util/preprocessing/__pycache__/imagetoarraypreprocesor.cpython-36.pyc  \n",
            "  inflating: loader_util/preprocessing/__pycache__/meanpreprocessor.cpython-36.pyc  \n",
            "  inflating: loader_util/preprocessing/__pycache__/mean_subtraction_legacy.cpython-36.pyc  \n",
            "  inflating: loader_util/preprocessing/__pycache__/patchpreprocessor.cpython-36.pyc  \n",
            "  inflating: loader_util/preprocessing/__pycache__/simplepreprocesor.cpython-36.pyc  \n",
            "  inflating: loader_util/preprocessing/__pycache__/__init__.cpython-36.pyc  \n",
            "   creating: loader_util/utils/\n",
            "  inflating: loader_util/utils/captchahelper.py  \n",
            "  inflating: loader_util/utils/ranked.py  \n",
            "  inflating: loader_util/utils/simple_obj_det.py  \n",
            "  inflating: loader_util/utils/__init__.py  \n",
            "   creating: loader_util/utils/__pycache__/\n",
            "  inflating: loader_util/utils/__pycache__/captchahelper.cpython-36.pyc  \n",
            "  inflating: loader_util/utils/__pycache__/ranked.cpython-36.pyc  \n",
            "  inflating: loader_util/utils/__pycache__/__init__.cpython-36.pyc  \n",
            " extracting: loader_util/__init__.py  \n",
            "   creating: loader_util/__pycache__/\n",
            "  inflating: loader_util/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: loader_util/__pycache__/__init__.cpython-37.pyc  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RJyGj7uWVf7D"
      },
      "source": [
        "import os\n",
        "import h5py\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.figure import Figure\n",
        "import matplotlib.axes._axes as axes\n",
        "sns.set()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yx_fpkmVVf7L"
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from loader_util.preprocessing import ImageToArrayPreprocessor, \\\n",
        "    AspectAwarePreprocessor, MeanSubtractionPreProcessor, SimplePreProcessor, PatchPreprocessor\n",
        "from loader_util.datasets import SimpleDatasetLoader\n",
        "from loader_util.io import HDF5DatasetGenerator\n",
        "from loader_util.nn.conv import FCHeadNet, LeNet, AlexNet, MinVGGNet, MiniGoogleNet, DeeperGoogleNet\n",
        "from loader_util.callbacks import TrainingMonitor, EpochCheckpoint\n",
        "##\n",
        "from tensorflow.keras.layers import Conv2D, Activation, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mo1e-wTDVf7T"
      },
      "source": [
        "# construct the train image generator\n",
        "aug = ImageDataGenerator(rotation_range=20,\n",
        "                         zoom_range=0.15,\n",
        "                         width_shift_range=0.2,\n",
        "                         height_shift_range=0.2,\n",
        "                         shear_range=0.15,\n",
        "                         horizontal_flip=True,\n",
        "                         fill_mode='nearest')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_qA3Q3m_Vf7Y"
      },
      "source": [
        "batch_size = 32\n",
        "epoch_num = 600\n",
        "image_size = 28\n",
        "\n",
        "# initialise the image preprocessors\n",
        "sp = SimplePreProcessor(width=image_size, height=image_size)\n",
        "pp = PatchPreprocessor(image_size, image_size)\n",
        "iap = ImageToArrayPreprocessor()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNiE_Qk7Vf7c",
        "outputId": "30665c8b-788c-4068-f10c-bfec176bb54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# initialise the data paths\n",
        "\n",
        "dbBase = r\"/content/drive/My Drive\"\n",
        "dbTrainPath = f\"{dbBase}//train_mvcnn_color_roi_10class_32px1px_255.hdf5\"\n",
        "dbValidPath = f\"{dbBase}//test_mvcnn_color_roi_10class_32px1px_255.hdf5\"\n",
        "\n",
        "# get the no. of classes\n",
        "trainFile = h5py.File(name=dbTrainPath, mode=\"r\")\n",
        "class_num = len(list(np.unique(trainFile[\"labels\"])))\n",
        "print(f\"Total no. of classes in dataset: {class_num}\")\n",
        "\n",
        "# get unique labels\n",
        "labels = list(trainFile[\"label_names\"])\n",
        "labels = [label.decode() for label in labels]\n",
        "print(f\"Unique Labels: {labels}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of classes in dataset: 10\n",
            "Unique Labels: ['Brackets', 'Bulky', 'Cylindrical', 'Gasket', 'HeadlessScrews', 'Nuts', 'O-Rings', 'Pipes', 'Springs', 'Toothy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mb8F-N5rVf7o",
        "outputId": "d65af195-46f8-4f78-aaee-58e6f6b41459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# consider class weight discrepency\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(trainFile[\"labels\"])\n",
        "encoded_labels = to_categorical(labels)\n",
        "\n",
        "classLabels = le.classes_\n",
        "classTotals = encoded_labels.sum(axis=0) # type: np.ndarray\n",
        "classWeight = classTotals.max() / classTotals\n",
        "\n",
        "print(f\"ClassLabels: {classLabels}\")\n",
        "print(f\"ClassWeights: {classWeight}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ClassLabels: [0 1 2 3 4 5 6 7 8 9]\n",
            "ClassWeights: [5.9427314 2.48893   4.014881  4.401305  2.0850077 3.6508796 1.\n",
            " 3.3809524 1.4536638 4.870036 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xPSO7MX-Vf8H"
      },
      "source": [
        "# initialise the train and valid generators\n",
        "trainGen = HDF5DatasetGenerator(dbPath=dbTrainPath,\n",
        "                                batchSize=batch_size,\n",
        "                                preprocessors=[pp, iap],\n",
        "                                classes=class_num,\n",
        "                                aug=aug)\n",
        "\n",
        "valGen = HDF5DatasetGenerator(dbPath=dbValidPath,\n",
        "                              batchSize=batch_size,\n",
        "                              preprocessors=[sp, iap],\n",
        "                              classes=class_num)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD7EEC8NVf8U"
      },
      "source": [
        "# define the Learning Rate Scheduler\n",
        "\n",
        "initial_rate = 5e-3\n",
        "\n",
        "def poly_decay(epoch):\n",
        "    max_epochs = epoch_num\n",
        "    baseLR = initial_rate\n",
        "    power = 1.0\n",
        "    \n",
        "    alpha = baseLR * (1 - (epoch / float(max_epochs))) ** power\n",
        "    return alpha"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpfi-74uVf8c"
      },
      "source": [
        "# model = AlexNet.build(width=32, height=32, depth=3, classes=class_num)\n",
        "# model = LeNet.build(width=28,\n",
        "#                     height=28,\n",
        "#                     depth=1,\n",
        "#                     classes=len(classLabels))\n",
        "\n",
        "model = MinVGGNet.build(width=28,\n",
        "                    height=28,\n",
        "                    depth=1,\n",
        "                    classes=len(classLabels))\n",
        "\n",
        "# model = MiniGoogleNet.build(width=28, height=28, depth=1, classes=class_num)\n",
        "#model =DeeperGoogleNet.build(width=image_size, height=image_size, depth=1, classes=class_num)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loYIuA7HVf8i",
        "outputId": "cb6d1ee6-bc40-45a4-f563-933d60c0766d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,679,082\n",
            "Trainable params: 1,677,674\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vqpseYGHVf8m"
      },
      "source": [
        "# compile and optimise model\n",
        "opt = Adam(lr=initial_rate)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# construct callbacks\n",
        "path = os.path.sep.join([dbBase, f'{os.getpid()}.png'])\n",
        "callbacks = [TrainingMonitor(path),\n",
        "             LearningRateScheduler(poly_decay),]\n",
        "             #EpochCheckpoint(outputPath=dbBase)]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w731F5-aL_Z",
        "outputId": "6b90ed9b-d2c2-45ee-fc64-63d2993009c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "classWeight = {i : classWeight[i] for i in range(len(classWeight))}\n",
        "classWeight"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 5.9427314,\n",
              " 1: 2.48893,\n",
              " 2: 4.014881,\n",
              " 3: 4.401305,\n",
              " 4: 2.0850077,\n",
              " 5: 3.6508796,\n",
              " 6: 1.0,\n",
              " 7: 3.3809524,\n",
              " 8: 1.4536638,\n",
              " 9: 4.870036}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "scrolled": true,
        "id": "AVP3yaj8Vf8u",
        "outputId": "91e8d969-acc4-4ff5-9da7-937d37f27388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the head for few epochs\n",
        "H = model.fit_generator(\n",
        "    trainGen.generator(),\n",
        "    steps_per_epoch=trainGen.numImages//batch_size,\n",
        "    validation_data=valGen.generator(),\n",
        "    validation_steps=valGen.numImages//batch_size,\n",
        "    epochs=epoch_num,\n",
        "    max_queue_size=10,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=classWeight\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-c848dd28d46a>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 4.7112 - accuracy: 0.4289 - val_loss: 5.4327 - val_accuracy: 0.1131\n",
            "Epoch 2/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 3.2485 - accuracy: 0.5641 - val_loss: 1.7269 - val_accuracy: 0.4824\n",
            "Epoch 3/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 2.9551 - accuracy: 0.6022 - val_loss: 1.1192 - val_accuracy: 0.5940\n",
            "Epoch 4/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 2.7259 - accuracy: 0.6255 - val_loss: 1.4131 - val_accuracy: 0.4826\n",
            "Epoch 5/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 2.2901 - accuracy: 0.6829 - val_loss: 0.6527 - val_accuracy: 0.7732\n",
            "Epoch 6/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 2.3174 - accuracy: 0.6839 - val_loss: 2.0533 - val_accuracy: 0.5230\n",
            "Epoch 7/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 2.1667 - accuracy: 0.7015 - val_loss: 3.3271 - val_accuracy: 0.4102\n",
            "Epoch 8/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 2.1278 - accuracy: 0.7114 - val_loss: 0.8324 - val_accuracy: 0.6760\n",
            "Epoch 9/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.9835 - accuracy: 0.7297 - val_loss: 0.6243 - val_accuracy: 0.7875\n",
            "Epoch 10/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.7212 - accuracy: 0.7609 - val_loss: 0.4831 - val_accuracy: 0.8333\n",
            "Epoch 11/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.6544 - accuracy: 0.7782 - val_loss: 0.9775 - val_accuracy: 0.6630\n",
            "Epoch 12/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.6753 - accuracy: 0.7711 - val_loss: 0.4007 - val_accuracy: 0.8542\n",
            "Epoch 13/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.5776 - accuracy: 0.7897 - val_loss: 0.7595 - val_accuracy: 0.7812\n",
            "Epoch 14/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 1.4523 - accuracy: 0.8016 - val_loss: 0.4098 - val_accuracy: 0.8557\n",
            "Epoch 15/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.4633 - accuracy: 0.8007 - val_loss: 0.4860 - val_accuracy: 0.8388\n",
            "Epoch 16/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.3878 - accuracy: 0.8082 - val_loss: 0.4128 - val_accuracy: 0.8672\n",
            "Epoch 17/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.3390 - accuracy: 0.8165 - val_loss: 0.4270 - val_accuracy: 0.8487\n",
            "Epoch 18/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.3029 - accuracy: 0.8266 - val_loss: 2.1318 - val_accuracy: 0.5605\n",
            "Epoch 19/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.2786 - accuracy: 0.8281 - val_loss: 0.4732 - val_accuracy: 0.8349\n",
            "Epoch 20/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.3285 - accuracy: 0.8163 - val_loss: 0.3331 - val_accuracy: 0.8754\n",
            "Epoch 21/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.1923 - accuracy: 0.8424 - val_loss: 0.3820 - val_accuracy: 0.8678\n",
            "Epoch 22/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.2513 - accuracy: 0.8303 - val_loss: 0.7635 - val_accuracy: 0.7439\n",
            "Epoch 23/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.2303 - accuracy: 0.8359 - val_loss: 0.2831 - val_accuracy: 0.9026\n",
            "Epoch 24/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.1331 - accuracy: 0.8461 - val_loss: 0.2502 - val_accuracy: 0.9104\n",
            "Epoch 25/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.1167 - accuracy: 0.8489 - val_loss: 0.3347 - val_accuracy: 0.8928\n",
            "Epoch 26/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.0566 - accuracy: 0.8604 - val_loss: 0.2565 - val_accuracy: 0.9086\n",
            "Epoch 27/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 1.0430 - accuracy: 0.8558 - val_loss: 0.2531 - val_accuracy: 0.9093\n",
            "Epoch 28/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.0024 - accuracy: 0.8653 - val_loss: 0.2907 - val_accuracy: 0.9067\n",
            "Epoch 29/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 1.1213 - accuracy: 0.8514 - val_loss: 0.3483 - val_accuracy: 0.8809\n",
            "Epoch 30/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 1.0175 - accuracy: 0.8650 - val_loss: 0.2421 - val_accuracy: 0.9197\n",
            "Epoch 31/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.9944 - accuracy: 0.8696 - val_loss: 0.3840 - val_accuracy: 0.8702\n",
            "Epoch 32/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.9845 - accuracy: 0.8682 - val_loss: 0.2078 - val_accuracy: 0.9314\n",
            "Epoch 33/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.9256 - accuracy: 0.8784 - val_loss: 0.2313 - val_accuracy: 0.9219\n",
            "Epoch 34/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.9048 - accuracy: 0.8798 - val_loss: 0.3836 - val_accuracy: 0.8770\n",
            "Epoch 35/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.0338 - accuracy: 0.8614 - val_loss: 0.2623 - val_accuracy: 0.9104\n",
            "Epoch 36/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.0911 - accuracy: 0.8529 - val_loss: 0.3058 - val_accuracy: 0.9017\n",
            "Epoch 37/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 1.0015 - accuracy: 0.8666 - val_loss: 0.2747 - val_accuracy: 0.9069\n",
            "Epoch 38/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.9187 - accuracy: 0.8832 - val_loss: 0.1953 - val_accuracy: 0.9355\n",
            "Epoch 39/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.8695 - accuracy: 0.8843 - val_loss: 0.2139 - val_accuracy: 0.9273\n",
            "Epoch 40/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.8515 - accuracy: 0.8849 - val_loss: 0.3395 - val_accuracy: 0.9028\n",
            "Epoch 41/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.8304 - accuracy: 0.8878 - val_loss: 0.7619 - val_accuracy: 0.8359\n",
            "Epoch 42/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.8502 - accuracy: 0.8850 - val_loss: 0.2323 - val_accuracy: 0.9225\n",
            "Epoch 43/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.8768 - accuracy: 0.8842 - val_loss: 0.2433 - val_accuracy: 0.9097\n",
            "Epoch 44/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.8178 - accuracy: 0.8862 - val_loss: 0.3145 - val_accuracy: 0.9167\n",
            "Epoch 45/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.8239 - accuracy: 0.8923 - val_loss: 0.1910 - val_accuracy: 0.9412\n",
            "Epoch 46/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.8095 - accuracy: 0.8920 - val_loss: 0.3348 - val_accuracy: 0.8980\n",
            "Epoch 47/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.8026 - accuracy: 0.8925 - val_loss: 0.1844 - val_accuracy: 0.9403\n",
            "Epoch 48/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7768 - accuracy: 0.8932 - val_loss: 0.2051 - val_accuracy: 0.9366\n",
            "Epoch 49/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7980 - accuracy: 0.8957 - val_loss: 0.1628 - val_accuracy: 0.9490\n",
            "Epoch 50/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7829 - accuracy: 0.8969 - val_loss: 0.1723 - val_accuracy: 0.9484\n",
            "Epoch 51/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7482 - accuracy: 0.9001 - val_loss: 0.4333 - val_accuracy: 0.8880\n",
            "Epoch 52/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7435 - accuracy: 0.8995 - val_loss: 0.2011 - val_accuracy: 0.9423\n",
            "Epoch 53/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7730 - accuracy: 0.8958 - val_loss: 0.2342 - val_accuracy: 0.9232\n",
            "Epoch 54/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.9052 - accuracy: 0.8785 - val_loss: 0.1886 - val_accuracy: 0.9399\n",
            "Epoch 55/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7940 - accuracy: 0.8969 - val_loss: 0.1674 - val_accuracy: 0.9479\n",
            "Epoch 56/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7406 - accuracy: 0.9035 - val_loss: 0.1496 - val_accuracy: 0.9544\n",
            "Epoch 57/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7260 - accuracy: 0.9036 - val_loss: 0.1673 - val_accuracy: 0.9449\n",
            "Epoch 58/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.6926 - accuracy: 0.9084 - val_loss: 0.1560 - val_accuracy: 0.9510\n",
            "Epoch 59/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.7050 - accuracy: 0.9068 - val_loss: 0.2104 - val_accuracy: 0.9327\n",
            "Epoch 60/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.7169 - accuracy: 0.9021 - val_loss: 0.2804 - val_accuracy: 0.9199\n",
            "Epoch 61/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.7109 - accuracy: 0.9066 - val_loss: 0.2021 - val_accuracy: 0.9355\n",
            "Epoch 62/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6863 - accuracy: 0.9088 - val_loss: 0.1345 - val_accuracy: 0.9586\n",
            "Epoch 63/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6692 - accuracy: 0.9087 - val_loss: 0.2209 - val_accuracy: 0.9347\n",
            "Epoch 64/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6761 - accuracy: 0.9096 - val_loss: 0.2290 - val_accuracy: 0.9262\n",
            "Epoch 65/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.6870 - accuracy: 0.9094 - val_loss: 0.1530 - val_accuracy: 0.9546\n",
            "Epoch 66/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6518 - accuracy: 0.9128 - val_loss: 0.3342 - val_accuracy: 0.8987\n",
            "Epoch 67/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6622 - accuracy: 0.9135 - val_loss: 0.3389 - val_accuracy: 0.9099\n",
            "Epoch 68/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6402 - accuracy: 0.9155 - val_loss: 0.1968 - val_accuracy: 0.9412\n",
            "Epoch 69/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6464 - accuracy: 0.9149 - val_loss: 0.1563 - val_accuracy: 0.9477\n",
            "Epoch 70/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6619 - accuracy: 0.9130 - val_loss: 0.1489 - val_accuracy: 0.9520\n",
            "Epoch 71/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6044 - accuracy: 0.9195 - val_loss: 0.1782 - val_accuracy: 0.9481\n",
            "Epoch 72/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.6329 - accuracy: 0.9163 - val_loss: 0.4012 - val_accuracy: 0.8921\n",
            "Epoch 73/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.6758 - accuracy: 0.9129 - val_loss: 0.1655 - val_accuracy: 0.9514\n",
            "Epoch 74/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6519 - accuracy: 0.9140 - val_loss: 0.1460 - val_accuracy: 0.9531\n",
            "Epoch 75/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.6371 - accuracy: 0.9158 - val_loss: 0.1608 - val_accuracy: 0.9414\n",
            "Epoch 76/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5910 - accuracy: 0.9225 - val_loss: 0.1970 - val_accuracy: 0.9258\n",
            "Epoch 77/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.6330 - accuracy: 0.9144 - val_loss: 0.1448 - val_accuracy: 0.9520\n",
            "Epoch 78/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.6308 - accuracy: 0.9161 - val_loss: 0.4023 - val_accuracy: 0.9052\n",
            "Epoch 79/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5956 - accuracy: 0.9228 - val_loss: 0.1667 - val_accuracy: 0.9457\n",
            "Epoch 80/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5926 - accuracy: 0.9200 - val_loss: 0.1910 - val_accuracy: 0.9431\n",
            "Epoch 81/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5859 - accuracy: 0.9221 - val_loss: 0.1471 - val_accuracy: 0.9523\n",
            "Epoch 82/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5946 - accuracy: 0.9194 - val_loss: 0.1326 - val_accuracy: 0.9570\n",
            "Epoch 83/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5793 - accuracy: 0.9228 - val_loss: 0.1517 - val_accuracy: 0.9464\n",
            "Epoch 84/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5804 - accuracy: 0.9219 - val_loss: 0.2213 - val_accuracy: 0.9303\n",
            "Epoch 85/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5946 - accuracy: 0.9207 - val_loss: 0.9121 - val_accuracy: 0.7743\n",
            "Epoch 86/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5948 - accuracy: 0.9227 - val_loss: 0.1367 - val_accuracy: 0.9546\n",
            "Epoch 87/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5854 - accuracy: 0.9233 - val_loss: 0.1886 - val_accuracy: 0.9405\n",
            "Epoch 88/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5910 - accuracy: 0.9257 - val_loss: 0.1451 - val_accuracy: 0.9566\n",
            "Epoch 89/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5323 - accuracy: 0.9281 - val_loss: 0.2170 - val_accuracy: 0.9371\n",
            "Epoch 90/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5767 - accuracy: 0.9253 - val_loss: 0.1736 - val_accuracy: 0.9479\n",
            "Epoch 91/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5424 - accuracy: 0.9281 - val_loss: 0.1183 - val_accuracy: 0.9627\n",
            "Epoch 92/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5515 - accuracy: 0.9281 - val_loss: 0.1207 - val_accuracy: 0.9629\n",
            "Epoch 93/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5607 - accuracy: 0.9299 - val_loss: 0.1754 - val_accuracy: 0.9332\n",
            "Epoch 94/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5531 - accuracy: 0.9276 - val_loss: 0.1257 - val_accuracy: 0.9640\n",
            "Epoch 95/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5319 - accuracy: 0.9304 - val_loss: 0.1396 - val_accuracy: 0.9559\n",
            "Epoch 96/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.5523 - accuracy: 0.9268 - val_loss: 0.2408 - val_accuracy: 0.9403\n",
            "Epoch 97/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5856 - accuracy: 0.9263 - val_loss: 0.1529 - val_accuracy: 0.9462\n",
            "Epoch 98/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5791 - accuracy: 0.9231 - val_loss: 0.1353 - val_accuracy: 0.9577\n",
            "Epoch 99/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5009 - accuracy: 0.9341 - val_loss: 0.1201 - val_accuracy: 0.9657\n",
            "Epoch 100/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5181 - accuracy: 0.9282 - val_loss: 0.2323 - val_accuracy: 0.9212\n",
            "Epoch 101/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5288 - accuracy: 0.9286 - val_loss: 0.1526 - val_accuracy: 0.9527\n",
            "Epoch 102/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5334 - accuracy: 0.9289 - val_loss: 0.1541 - val_accuracy: 0.9533\n",
            "Epoch 103/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5159 - accuracy: 0.9320 - val_loss: 0.1764 - val_accuracy: 0.9401\n",
            "Epoch 104/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5196 - accuracy: 0.9301 - val_loss: 0.1717 - val_accuracy: 0.9533\n",
            "Epoch 105/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5177 - accuracy: 0.9306 - val_loss: 0.1562 - val_accuracy: 0.9503\n",
            "Epoch 106/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5465 - accuracy: 0.9254 - val_loss: 0.1569 - val_accuracy: 0.9479\n",
            "Epoch 107/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5368 - accuracy: 0.9305 - val_loss: 0.1328 - val_accuracy: 0.9564\n",
            "Epoch 108/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5092 - accuracy: 0.9297 - val_loss: 0.1434 - val_accuracy: 0.9557\n",
            "Epoch 109/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4924 - accuracy: 0.9335 - val_loss: 0.1520 - val_accuracy: 0.9512\n",
            "Epoch 110/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5166 - accuracy: 0.9283 - val_loss: 0.1278 - val_accuracy: 0.9633\n",
            "Epoch 111/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5348 - accuracy: 0.9285 - val_loss: 0.1379 - val_accuracy: 0.9575\n",
            "Epoch 112/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.5050 - accuracy: 0.9349 - val_loss: 0.1288 - val_accuracy: 0.9629\n",
            "Epoch 113/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.5120 - accuracy: 0.9295 - val_loss: 0.2216 - val_accuracy: 0.9384\n",
            "Epoch 114/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4886 - accuracy: 0.9359 - val_loss: 0.1682 - val_accuracy: 0.9512\n",
            "Epoch 115/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4800 - accuracy: 0.9338 - val_loss: 0.1479 - val_accuracy: 0.9538\n",
            "Epoch 116/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5079 - accuracy: 0.9338 - val_loss: 0.2266 - val_accuracy: 0.9384\n",
            "Epoch 117/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4637 - accuracy: 0.9351 - val_loss: 0.1276 - val_accuracy: 0.9546\n",
            "Epoch 118/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4750 - accuracy: 0.9336 - val_loss: 0.1686 - val_accuracy: 0.9492\n",
            "Epoch 119/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5004 - accuracy: 0.9354 - val_loss: 0.2127 - val_accuracy: 0.9312\n",
            "Epoch 120/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4817 - accuracy: 0.9337 - val_loss: 0.1697 - val_accuracy: 0.9395\n",
            "Epoch 121/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4500 - accuracy: 0.9382 - val_loss: 0.1431 - val_accuracy: 0.9601\n",
            "Epoch 122/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4800 - accuracy: 0.9367 - val_loss: 0.1285 - val_accuracy: 0.9599\n",
            "Epoch 123/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4595 - accuracy: 0.9380 - val_loss: 0.1617 - val_accuracy: 0.9536\n",
            "Epoch 124/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5269 - accuracy: 0.9341 - val_loss: 0.1400 - val_accuracy: 0.9551\n",
            "Epoch 125/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4380 - accuracy: 0.9422 - val_loss: 0.1113 - val_accuracy: 0.9661\n",
            "Epoch 126/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4706 - accuracy: 0.9378 - val_loss: 0.1337 - val_accuracy: 0.9551\n",
            "Epoch 127/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4702 - accuracy: 0.9398 - val_loss: 0.1410 - val_accuracy: 0.9538\n",
            "Epoch 128/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4511 - accuracy: 0.9397 - val_loss: 0.1205 - val_accuracy: 0.9661\n",
            "Epoch 129/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5326 - accuracy: 0.9322 - val_loss: 0.1515 - val_accuracy: 0.9501\n",
            "Epoch 130/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4559 - accuracy: 0.9400 - val_loss: 0.1061 - val_accuracy: 0.9683\n",
            "Epoch 131/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4474 - accuracy: 0.9399 - val_loss: 0.1271 - val_accuracy: 0.9562\n",
            "Epoch 132/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4422 - accuracy: 0.9411 - val_loss: 0.1266 - val_accuracy: 0.9590\n",
            "Epoch 133/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4199 - accuracy: 0.9452 - val_loss: 0.1264 - val_accuracy: 0.9620\n",
            "Epoch 134/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4365 - accuracy: 0.9451 - val_loss: 0.1162 - val_accuracy: 0.9644\n",
            "Epoch 135/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4313 - accuracy: 0.9433 - val_loss: 0.1034 - val_accuracy: 0.9677\n",
            "Epoch 136/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4297 - accuracy: 0.9405 - val_loss: 0.1485 - val_accuracy: 0.9503\n",
            "Epoch 137/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4849 - accuracy: 0.9382 - val_loss: 0.1230 - val_accuracy: 0.9603\n",
            "Epoch 138/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.5077 - accuracy: 0.9324 - val_loss: 0.1244 - val_accuracy: 0.9620\n",
            "Epoch 139/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4511 - accuracy: 0.9419 - val_loss: 0.1162 - val_accuracy: 0.9638\n",
            "Epoch 140/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4420 - accuracy: 0.9387 - val_loss: 0.1171 - val_accuracy: 0.9664\n",
            "Epoch 141/600\n",
            "336/336 [==============================] - 8s 22ms/step - loss: 0.4322 - accuracy: 0.9408 - val_loss: 4.2909 - val_accuracy: 0.6402\n",
            "Epoch 142/600\n",
            "336/336 [==============================] - 8s 22ms/step - loss: 0.4088 - accuracy: 0.9442 - val_loss: 0.1400 - val_accuracy: 0.9544\n",
            "Epoch 143/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4351 - accuracy: 0.9437 - val_loss: 0.1116 - val_accuracy: 0.9683\n",
            "Epoch 144/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.4320 - accuracy: 0.9411 - val_loss: 0.1004 - val_accuracy: 0.9703\n",
            "Epoch 145/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4514 - accuracy: 0.9408 - val_loss: 0.1690 - val_accuracy: 0.9464\n",
            "Epoch 146/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4439 - accuracy: 0.9421 - val_loss: 0.1334 - val_accuracy: 0.9568\n",
            "Epoch 147/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4363 - accuracy: 0.9445 - val_loss: 0.3943 - val_accuracy: 0.8939\n",
            "Epoch 148/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4024 - accuracy: 0.9468 - val_loss: 0.1849 - val_accuracy: 0.9427\n",
            "Epoch 149/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4145 - accuracy: 0.9453 - val_loss: 0.1198 - val_accuracy: 0.9642\n",
            "Epoch 150/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4552 - accuracy: 0.9418 - val_loss: 0.1555 - val_accuracy: 0.9531\n",
            "Epoch 151/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4143 - accuracy: 0.9459 - val_loss: 0.1168 - val_accuracy: 0.9648\n",
            "Epoch 152/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.3934 - accuracy: 0.9449 - val_loss: 0.1728 - val_accuracy: 0.9410\n",
            "Epoch 153/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4222 - accuracy: 0.9448 - val_loss: 0.1320 - val_accuracy: 0.9564\n",
            "Epoch 154/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4330 - accuracy: 0.9445 - val_loss: 0.1100 - val_accuracy: 0.9703\n",
            "Epoch 155/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4034 - accuracy: 0.9471 - val_loss: 0.1105 - val_accuracy: 0.9683\n",
            "Epoch 156/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3797 - accuracy: 0.9491 - val_loss: 0.2631 - val_accuracy: 0.9345\n",
            "Epoch 157/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3967 - accuracy: 0.9493 - val_loss: 0.2392 - val_accuracy: 0.9243\n",
            "Epoch 158/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.4377 - accuracy: 0.9414 - val_loss: 0.1377 - val_accuracy: 0.9572\n",
            "Epoch 159/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3932 - accuracy: 0.9461 - val_loss: 0.1203 - val_accuracy: 0.9629\n",
            "Epoch 160/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3855 - accuracy: 0.9494 - val_loss: 0.1250 - val_accuracy: 0.9668\n",
            "Epoch 161/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3920 - accuracy: 0.9476 - val_loss: 0.1109 - val_accuracy: 0.9683\n",
            "Epoch 162/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4005 - accuracy: 0.9473 - val_loss: 0.2744 - val_accuracy: 0.9334\n",
            "Epoch 163/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4069 - accuracy: 0.9470 - val_loss: 0.1048 - val_accuracy: 0.9670\n",
            "Epoch 164/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3752 - accuracy: 0.9515 - val_loss: 0.1030 - val_accuracy: 0.9698\n",
            "Epoch 165/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3850 - accuracy: 0.9488 - val_loss: 0.1635 - val_accuracy: 0.9601\n",
            "Epoch 166/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3781 - accuracy: 0.9491 - val_loss: 0.1477 - val_accuracy: 0.9583\n",
            "Epoch 167/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3830 - accuracy: 0.9507 - val_loss: 0.1602 - val_accuracy: 0.9540\n",
            "Epoch 168/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3656 - accuracy: 0.9501 - val_loss: 0.4179 - val_accuracy: 0.8854\n",
            "Epoch 169/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3723 - accuracy: 0.9498 - val_loss: 0.0917 - val_accuracy: 0.9742\n",
            "Epoch 170/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3891 - accuracy: 0.9484 - val_loss: 0.2153 - val_accuracy: 0.9540\n",
            "Epoch 171/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4052 - accuracy: 0.9476 - val_loss: 0.1128 - val_accuracy: 0.9607\n",
            "Epoch 172/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3867 - accuracy: 0.9494 - val_loss: 0.1177 - val_accuracy: 0.9651\n",
            "Epoch 173/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3640 - accuracy: 0.9527 - val_loss: 0.1104 - val_accuracy: 0.9720\n",
            "Epoch 174/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4172 - accuracy: 0.9459 - val_loss: 0.3843 - val_accuracy: 0.9049\n",
            "Epoch 175/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3913 - accuracy: 0.9496 - val_loss: 0.1195 - val_accuracy: 0.9599\n",
            "Epoch 176/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3590 - accuracy: 0.9498 - val_loss: 0.0942 - val_accuracy: 0.9761\n",
            "Epoch 177/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3535 - accuracy: 0.9540 - val_loss: 0.2188 - val_accuracy: 0.9371\n",
            "Epoch 178/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3573 - accuracy: 0.9517 - val_loss: 0.2751 - val_accuracy: 0.9442\n",
            "Epoch 179/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3705 - accuracy: 0.9496 - val_loss: 0.1149 - val_accuracy: 0.9670\n",
            "Epoch 180/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3842 - accuracy: 0.9479 - val_loss: 0.2368 - val_accuracy: 0.9362\n",
            "Epoch 181/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3608 - accuracy: 0.9546 - val_loss: 0.1977 - val_accuracy: 0.9440\n",
            "Epoch 182/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3379 - accuracy: 0.9568 - val_loss: 0.1313 - val_accuracy: 0.9655\n",
            "Epoch 183/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3461 - accuracy: 0.9554 - val_loss: 0.1066 - val_accuracy: 0.9690\n",
            "Epoch 184/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.4210 - accuracy: 0.9462 - val_loss: 0.1352 - val_accuracy: 0.9586\n",
            "Epoch 185/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.3702 - accuracy: 0.9502 - val_loss: 0.1008 - val_accuracy: 0.9716\n",
            "Epoch 186/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3551 - accuracy: 0.9528 - val_loss: 0.0982 - val_accuracy: 0.9707\n",
            "Epoch 187/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3561 - accuracy: 0.9513 - val_loss: 0.1177 - val_accuracy: 0.9659\n",
            "Epoch 188/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3688 - accuracy: 0.9500 - val_loss: 0.1617 - val_accuracy: 0.9596\n",
            "Epoch 189/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.3893 - accuracy: 0.9488 - val_loss: 0.1087 - val_accuracy: 0.9685\n",
            "Epoch 190/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.3555 - accuracy: 0.9527 - val_loss: 0.1193 - val_accuracy: 0.9646\n",
            "Epoch 191/600\n",
            "336/336 [==============================] - 9s 27ms/step - loss: 0.3144 - accuracy: 0.9585 - val_loss: 0.1460 - val_accuracy: 0.9531\n",
            "Epoch 192/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.3524 - accuracy: 0.9541 - val_loss: 0.1025 - val_accuracy: 0.9677\n",
            "Epoch 193/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.3663 - accuracy: 0.9509 - val_loss: 0.1149 - val_accuracy: 0.9664\n",
            "Epoch 194/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3411 - accuracy: 0.9553 - val_loss: 0.1098 - val_accuracy: 0.9701\n",
            "Epoch 195/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3346 - accuracy: 0.9558 - val_loss: 0.0909 - val_accuracy: 0.9746\n",
            "Epoch 196/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.3397 - accuracy: 0.9530 - val_loss: 0.1375 - val_accuracy: 0.9577\n",
            "Epoch 197/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3514 - accuracy: 0.9533 - val_loss: 0.0915 - val_accuracy: 0.9740\n",
            "Epoch 198/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3574 - accuracy: 0.9529 - val_loss: 0.1083 - val_accuracy: 0.9666\n",
            "Epoch 199/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3283 - accuracy: 0.9543 - val_loss: 0.0872 - val_accuracy: 0.9755\n",
            "Epoch 200/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3285 - accuracy: 0.9558 - val_loss: 0.0915 - val_accuracy: 0.9727\n",
            "Epoch 201/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.3361 - accuracy: 0.9551 - val_loss: 0.3684 - val_accuracy: 0.8934\n",
            "Epoch 202/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3767 - accuracy: 0.9488 - val_loss: 0.1101 - val_accuracy: 0.9694\n",
            "Epoch 203/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3421 - accuracy: 0.9539 - val_loss: 0.1043 - val_accuracy: 0.9718\n",
            "Epoch 204/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3299 - accuracy: 0.9537 - val_loss: 0.0935 - val_accuracy: 0.9737\n",
            "Epoch 205/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3282 - accuracy: 0.9547 - val_loss: 0.1135 - val_accuracy: 0.9627\n",
            "Epoch 206/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3669 - accuracy: 0.9519 - val_loss: 0.1288 - val_accuracy: 0.9607\n",
            "Epoch 207/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3272 - accuracy: 0.9547 - val_loss: 0.1090 - val_accuracy: 0.9666\n",
            "Epoch 208/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3493 - accuracy: 0.9542 - val_loss: 0.1220 - val_accuracy: 0.9642\n",
            "Epoch 209/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3159 - accuracy: 0.9562 - val_loss: 0.1139 - val_accuracy: 0.9670\n",
            "Epoch 210/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3527 - accuracy: 0.9543 - val_loss: 0.1213 - val_accuracy: 0.9612\n",
            "Epoch 211/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3171 - accuracy: 0.9580 - val_loss: 0.0937 - val_accuracy: 0.9709\n",
            "Epoch 212/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3234 - accuracy: 0.9565 - val_loss: 0.0894 - val_accuracy: 0.9740\n",
            "Epoch 213/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3429 - accuracy: 0.9556 - val_loss: 0.1065 - val_accuracy: 0.9716\n",
            "Epoch 214/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3301 - accuracy: 0.9568 - val_loss: 0.1038 - val_accuracy: 0.9670\n",
            "Epoch 215/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3487 - accuracy: 0.9548 - val_loss: 0.1109 - val_accuracy: 0.9690\n",
            "Epoch 216/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3053 - accuracy: 0.9602 - val_loss: 0.1092 - val_accuracy: 0.9711\n",
            "Epoch 217/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3437 - accuracy: 0.9552 - val_loss: 0.1323 - val_accuracy: 0.9612\n",
            "Epoch 218/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3326 - accuracy: 0.9595 - val_loss: 0.1318 - val_accuracy: 0.9644\n",
            "Epoch 219/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3429 - accuracy: 0.9544 - val_loss: 0.1064 - val_accuracy: 0.9701\n",
            "Epoch 220/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3491 - accuracy: 0.9557 - val_loss: 0.1734 - val_accuracy: 0.9568\n",
            "Epoch 221/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2956 - accuracy: 0.9614 - val_loss: 0.1344 - val_accuracy: 0.9644\n",
            "Epoch 222/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3209 - accuracy: 0.9556 - val_loss: 0.0898 - val_accuracy: 0.9779\n",
            "Epoch 223/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3265 - accuracy: 0.9573 - val_loss: 0.0969 - val_accuracy: 0.9720\n",
            "Epoch 224/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3339 - accuracy: 0.9569 - val_loss: 0.2242 - val_accuracy: 0.9579\n",
            "Epoch 225/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2911 - accuracy: 0.9598 - val_loss: 0.1637 - val_accuracy: 0.9581\n",
            "Epoch 226/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.3069 - accuracy: 0.9606 - val_loss: 0.1238 - val_accuracy: 0.9644\n",
            "Epoch 227/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3512 - accuracy: 0.9553 - val_loss: 0.2228 - val_accuracy: 0.9540\n",
            "Epoch 228/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.3121 - accuracy: 0.9593 - val_loss: 0.1569 - val_accuracy: 0.9570\n",
            "Epoch 229/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.3079 - accuracy: 0.9581 - val_loss: 0.0932 - val_accuracy: 0.9744\n",
            "Epoch 230/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2831 - accuracy: 0.9604 - val_loss: 0.1058 - val_accuracy: 0.9707\n",
            "Epoch 231/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3288 - accuracy: 0.9562 - val_loss: 0.0826 - val_accuracy: 0.9763\n",
            "Epoch 232/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3102 - accuracy: 0.9568 - val_loss: 0.0899 - val_accuracy: 0.9757\n",
            "Epoch 233/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3123 - accuracy: 0.9563 - val_loss: 0.2448 - val_accuracy: 0.9479\n",
            "Epoch 234/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2920 - accuracy: 0.9611 - val_loss: 0.1460 - val_accuracy: 0.9594\n",
            "Epoch 235/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3103 - accuracy: 0.9578 - val_loss: 0.1810 - val_accuracy: 0.9544\n",
            "Epoch 236/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2976 - accuracy: 0.9600 - val_loss: 0.1091 - val_accuracy: 0.9720\n",
            "Epoch 237/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3025 - accuracy: 0.9583 - val_loss: 0.1139 - val_accuracy: 0.9668\n",
            "Epoch 238/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2924 - accuracy: 0.9604 - val_loss: 0.1274 - val_accuracy: 0.9640\n",
            "Epoch 239/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3218 - accuracy: 0.9582 - val_loss: 0.0926 - val_accuracy: 0.9737\n",
            "Epoch 240/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2922 - accuracy: 0.9620 - val_loss: 0.0993 - val_accuracy: 0.9724\n",
            "Epoch 241/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3166 - accuracy: 0.9605 - val_loss: 0.0914 - val_accuracy: 0.9742\n",
            "Epoch 242/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2774 - accuracy: 0.9620 - val_loss: 0.1215 - val_accuracy: 0.9666\n",
            "Epoch 243/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2783 - accuracy: 0.9634 - val_loss: 0.0960 - val_accuracy: 0.9753\n",
            "Epoch 244/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3400 - accuracy: 0.9557 - val_loss: 0.3165 - val_accuracy: 0.9431\n",
            "Epoch 245/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3242 - accuracy: 0.9578 - val_loss: 0.1280 - val_accuracy: 0.9648\n",
            "Epoch 246/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2871 - accuracy: 0.9600 - val_loss: 0.0971 - val_accuracy: 0.9724\n",
            "Epoch 247/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2937 - accuracy: 0.9605 - val_loss: 0.2069 - val_accuracy: 0.9579\n",
            "Epoch 248/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3092 - accuracy: 0.9594 - val_loss: 0.1197 - val_accuracy: 0.9694\n",
            "Epoch 249/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2973 - accuracy: 0.9627 - val_loss: 0.1315 - val_accuracy: 0.9616\n",
            "Epoch 250/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3046 - accuracy: 0.9587 - val_loss: 0.0979 - val_accuracy: 0.9731\n",
            "Epoch 251/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2708 - accuracy: 0.9616 - val_loss: 0.0887 - val_accuracy: 0.9770\n",
            "Epoch 252/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2829 - accuracy: 0.9609 - val_loss: 0.0851 - val_accuracy: 0.9759\n",
            "Epoch 253/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2975 - accuracy: 0.9603 - val_loss: 0.1050 - val_accuracy: 0.9688\n",
            "Epoch 254/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2770 - accuracy: 0.9644 - val_loss: 0.1316 - val_accuracy: 0.9685\n",
            "Epoch 255/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3019 - accuracy: 0.9593 - val_loss: 0.0960 - val_accuracy: 0.9757\n",
            "Epoch 256/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3204 - accuracy: 0.9576 - val_loss: 0.1450 - val_accuracy: 0.9529\n",
            "Epoch 257/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3083 - accuracy: 0.9594 - val_loss: 0.0837 - val_accuracy: 0.9770\n",
            "Epoch 258/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2724 - accuracy: 0.9614 - val_loss: 0.0839 - val_accuracy: 0.9746\n",
            "Epoch 259/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2932 - accuracy: 0.9599 - val_loss: 0.0971 - val_accuracy: 0.9718\n",
            "Epoch 260/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2723 - accuracy: 0.9623 - val_loss: 0.1224 - val_accuracy: 0.9655\n",
            "Epoch 261/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2940 - accuracy: 0.9612 - val_loss: 0.2593 - val_accuracy: 0.9542\n",
            "Epoch 262/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2694 - accuracy: 0.9638 - val_loss: 0.0800 - val_accuracy: 0.9796\n",
            "Epoch 263/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2846 - accuracy: 0.9639 - val_loss: 0.0900 - val_accuracy: 0.9748\n",
            "Epoch 264/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2943 - accuracy: 0.9597 - val_loss: 0.0833 - val_accuracy: 0.9770\n",
            "Epoch 265/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2854 - accuracy: 0.9609 - val_loss: 0.0872 - val_accuracy: 0.9768\n",
            "Epoch 266/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2848 - accuracy: 0.9602 - val_loss: 0.0854 - val_accuracy: 0.9753\n",
            "Epoch 267/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2821 - accuracy: 0.9638 - val_loss: 0.0971 - val_accuracy: 0.9709\n",
            "Epoch 268/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.3129 - accuracy: 0.9571 - val_loss: 1.3270 - val_accuracy: 0.7830\n",
            "Epoch 269/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2693 - accuracy: 0.9641 - val_loss: 0.0917 - val_accuracy: 0.9724\n",
            "Epoch 270/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2697 - accuracy: 0.9631 - val_loss: 0.0959 - val_accuracy: 0.9744\n",
            "Epoch 271/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2676 - accuracy: 0.9637 - val_loss: 0.0930 - val_accuracy: 0.9755\n",
            "Epoch 272/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2594 - accuracy: 0.9658 - val_loss: 0.1386 - val_accuracy: 0.9644\n",
            "Epoch 273/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2555 - accuracy: 0.9654 - val_loss: 0.1148 - val_accuracy: 0.9679\n",
            "Epoch 274/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2783 - accuracy: 0.9647 - val_loss: 0.1500 - val_accuracy: 0.9627\n",
            "Epoch 275/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2644 - accuracy: 0.9647 - val_loss: 0.1076 - val_accuracy: 0.9705\n",
            "Epoch 276/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2660 - accuracy: 0.9634 - val_loss: 0.0922 - val_accuracy: 0.9755\n",
            "Epoch 277/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2808 - accuracy: 0.9618 - val_loss: 0.0880 - val_accuracy: 0.9750\n",
            "Epoch 278/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2790 - accuracy: 0.9628 - val_loss: 0.1562 - val_accuracy: 0.9579\n",
            "Epoch 279/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2429 - accuracy: 0.9670 - val_loss: 0.1070 - val_accuracy: 0.9757\n",
            "Epoch 280/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2722 - accuracy: 0.9613 - val_loss: 0.0965 - val_accuracy: 0.9729\n",
            "Epoch 281/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2800 - accuracy: 0.9624 - val_loss: 0.2030 - val_accuracy: 0.9392\n",
            "Epoch 282/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2759 - accuracy: 0.9623 - val_loss: 0.1053 - val_accuracy: 0.9727\n",
            "Epoch 283/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2675 - accuracy: 0.9641 - val_loss: 0.1059 - val_accuracy: 0.9763\n",
            "Epoch 284/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2606 - accuracy: 0.9646 - val_loss: 0.1386 - val_accuracy: 0.9620\n",
            "Epoch 285/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2598 - accuracy: 0.9671 - val_loss: 0.0938 - val_accuracy: 0.9779\n",
            "Epoch 286/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2370 - accuracy: 0.9671 - val_loss: 0.1104 - val_accuracy: 0.9750\n",
            "Epoch 287/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2731 - accuracy: 0.9627 - val_loss: 0.1070 - val_accuracy: 0.9731\n",
            "Epoch 288/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2737 - accuracy: 0.9651 - val_loss: 0.0815 - val_accuracy: 0.9748\n",
            "Epoch 289/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2451 - accuracy: 0.9661 - val_loss: 0.1070 - val_accuracy: 0.9707\n",
            "Epoch 290/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2498 - accuracy: 0.9684 - val_loss: 0.0878 - val_accuracy: 0.9761\n",
            "Epoch 291/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2687 - accuracy: 0.9636 - val_loss: 0.0884 - val_accuracy: 0.9770\n",
            "Epoch 292/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2418 - accuracy: 0.9688 - val_loss: 0.1047 - val_accuracy: 0.9705\n",
            "Epoch 293/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2563 - accuracy: 0.9640 - val_loss: 0.1213 - val_accuracy: 0.9679\n",
            "Epoch 294/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2338 - accuracy: 0.9665 - val_loss: 0.1027 - val_accuracy: 0.9735\n",
            "Epoch 295/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2857 - accuracy: 0.9622 - val_loss: 0.0988 - val_accuracy: 0.9735\n",
            "Epoch 296/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2427 - accuracy: 0.9678 - val_loss: 0.1064 - val_accuracy: 0.9727\n",
            "Epoch 297/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2595 - accuracy: 0.9672 - val_loss: 0.0894 - val_accuracy: 0.9759\n",
            "Epoch 298/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2543 - accuracy: 0.9652 - val_loss: 0.0842 - val_accuracy: 0.9789\n",
            "Epoch 299/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2315 - accuracy: 0.9675 - val_loss: 0.0889 - val_accuracy: 0.9772\n",
            "Epoch 300/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2432 - accuracy: 0.9671 - val_loss: 0.1096 - val_accuracy: 0.9716\n",
            "Epoch 301/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2443 - accuracy: 0.9691 - val_loss: 0.1480 - val_accuracy: 0.9657\n",
            "Epoch 302/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2594 - accuracy: 0.9678 - val_loss: 0.0929 - val_accuracy: 0.9772\n",
            "Epoch 303/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2613 - accuracy: 0.9642 - val_loss: 0.0928 - val_accuracy: 0.9757\n",
            "Epoch 304/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2384 - accuracy: 0.9686 - val_loss: 0.0912 - val_accuracy: 0.9770\n",
            "Epoch 305/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2704 - accuracy: 0.9664 - val_loss: 0.1523 - val_accuracy: 0.9625\n",
            "Epoch 306/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2582 - accuracy: 0.9637 - val_loss: 0.0963 - val_accuracy: 0.9753\n",
            "Epoch 307/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2494 - accuracy: 0.9696 - val_loss: 0.0931 - val_accuracy: 0.9748\n",
            "Epoch 308/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2374 - accuracy: 0.9689 - val_loss: 0.7036 - val_accuracy: 0.8607\n",
            "Epoch 309/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2557 - accuracy: 0.9665 - val_loss: 0.1443 - val_accuracy: 0.9614\n",
            "Epoch 310/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2532 - accuracy: 0.9684 - val_loss: 0.0953 - val_accuracy: 0.9759\n",
            "Epoch 311/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2496 - accuracy: 0.9673 - val_loss: 0.0850 - val_accuracy: 0.9783\n",
            "Epoch 312/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2451 - accuracy: 0.9665 - val_loss: 0.0873 - val_accuracy: 0.9748\n",
            "Epoch 313/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2294 - accuracy: 0.9672 - val_loss: 0.2757 - val_accuracy: 0.9375\n",
            "Epoch 314/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2491 - accuracy: 0.9695 - val_loss: 0.0763 - val_accuracy: 0.9822\n",
            "Epoch 315/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2327 - accuracy: 0.9692 - val_loss: 0.0721 - val_accuracy: 0.9822\n",
            "Epoch 316/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2176 - accuracy: 0.9707 - val_loss: 0.0698 - val_accuracy: 0.9816\n",
            "Epoch 317/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2414 - accuracy: 0.9685 - val_loss: 0.1847 - val_accuracy: 0.9599\n",
            "Epoch 318/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2395 - accuracy: 0.9685 - val_loss: 0.1732 - val_accuracy: 0.9644\n",
            "Epoch 319/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2283 - accuracy: 0.9713 - val_loss: 0.0800 - val_accuracy: 0.9792\n",
            "Epoch 320/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.2494 - accuracy: 0.9685 - val_loss: 0.0924 - val_accuracy: 0.9766\n",
            "Epoch 321/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2322 - accuracy: 0.9677 - val_loss: 0.0932 - val_accuracy: 0.9781\n",
            "Epoch 322/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2776 - accuracy: 0.9624 - val_loss: 0.0977 - val_accuracy: 0.9755\n",
            "Epoch 323/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2482 - accuracy: 0.9679 - val_loss: 0.0947 - val_accuracy: 0.9759\n",
            "Epoch 324/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2202 - accuracy: 0.9719 - val_loss: 0.0759 - val_accuracy: 0.9816\n",
            "Epoch 325/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2141 - accuracy: 0.9701 - val_loss: 0.1019 - val_accuracy: 0.9718\n",
            "Epoch 326/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2337 - accuracy: 0.9691 - val_loss: 0.0840 - val_accuracy: 0.9789\n",
            "Epoch 327/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2292 - accuracy: 0.9700 - val_loss: 0.0855 - val_accuracy: 0.9811\n",
            "Epoch 328/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2486 - accuracy: 0.9678 - val_loss: 0.0974 - val_accuracy: 0.9755\n",
            "Epoch 329/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2142 - accuracy: 0.9707 - val_loss: 0.0886 - val_accuracy: 0.9759\n",
            "Epoch 330/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2213 - accuracy: 0.9701 - val_loss: 0.0964 - val_accuracy: 0.9755\n",
            "Epoch 331/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2348 - accuracy: 0.9693 - val_loss: 0.1055 - val_accuracy: 0.9735\n",
            "Epoch 332/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2065 - accuracy: 0.9716 - val_loss: 0.2168 - val_accuracy: 0.9559\n",
            "Epoch 333/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2657 - accuracy: 0.9637 - val_loss: 0.0841 - val_accuracy: 0.9779\n",
            "Epoch 334/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2254 - accuracy: 0.9695 - val_loss: 0.1143 - val_accuracy: 0.9698\n",
            "Epoch 335/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2286 - accuracy: 0.9702 - val_loss: 0.0986 - val_accuracy: 0.9727\n",
            "Epoch 336/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2388 - accuracy: 0.9687 - val_loss: 0.0885 - val_accuracy: 0.9779\n",
            "Epoch 337/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2448 - accuracy: 0.9666 - val_loss: 0.1734 - val_accuracy: 0.9605\n",
            "Epoch 338/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2465 - accuracy: 0.9682 - val_loss: 0.0829 - val_accuracy: 0.9792\n",
            "Epoch 339/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2299 - accuracy: 0.9690 - val_loss: 0.0756 - val_accuracy: 0.9805\n",
            "Epoch 340/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2423 - accuracy: 0.9687 - val_loss: 0.0904 - val_accuracy: 0.9766\n",
            "Epoch 341/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1891 - accuracy: 0.9760 - val_loss: 0.2265 - val_accuracy: 0.9473\n",
            "Epoch 342/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2237 - accuracy: 0.9720 - val_loss: 0.0733 - val_accuracy: 0.9789\n",
            "Epoch 343/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1952 - accuracy: 0.9756 - val_loss: 0.0868 - val_accuracy: 0.9779\n",
            "Epoch 344/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2256 - accuracy: 0.9708 - val_loss: 0.1077 - val_accuracy: 0.9666\n",
            "Epoch 345/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2259 - accuracy: 0.9675 - val_loss: 0.0886 - val_accuracy: 0.9740\n",
            "Epoch 346/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2208 - accuracy: 0.9716 - val_loss: 0.0951 - val_accuracy: 0.9737\n",
            "Epoch 347/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2027 - accuracy: 0.9712 - val_loss: 0.1634 - val_accuracy: 0.9596\n",
            "Epoch 348/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.2211 - accuracy: 0.9716 - val_loss: 0.0919 - val_accuracy: 0.9772\n",
            "Epoch 349/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2066 - accuracy: 0.9733 - val_loss: 0.1041 - val_accuracy: 0.9727\n",
            "Epoch 350/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2140 - accuracy: 0.9731 - val_loss: 0.0933 - val_accuracy: 0.9763\n",
            "Epoch 351/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2375 - accuracy: 0.9714 - val_loss: 0.0834 - val_accuracy: 0.9809\n",
            "Epoch 352/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2322 - accuracy: 0.9702 - val_loss: 0.0892 - val_accuracy: 0.9770\n",
            "Epoch 353/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2228 - accuracy: 0.9710 - val_loss: 0.0943 - val_accuracy: 0.9729\n",
            "Epoch 354/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2189 - accuracy: 0.9701 - val_loss: 0.0816 - val_accuracy: 0.9798\n",
            "Epoch 355/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2179 - accuracy: 0.9698 - val_loss: 0.0798 - val_accuracy: 0.9811\n",
            "Epoch 356/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2129 - accuracy: 0.9719 - val_loss: 0.0815 - val_accuracy: 0.9776\n",
            "Epoch 357/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2281 - accuracy: 0.9698 - val_loss: 0.0899 - val_accuracy: 0.9796\n",
            "Epoch 358/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2158 - accuracy: 0.9714 - val_loss: 0.0788 - val_accuracy: 0.9774\n",
            "Epoch 359/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2117 - accuracy: 0.9719 - val_loss: 0.0800 - val_accuracy: 0.9776\n",
            "Epoch 360/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2168 - accuracy: 0.9725 - val_loss: 0.0793 - val_accuracy: 0.9811\n",
            "Epoch 361/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2201 - accuracy: 0.9721 - val_loss: 0.0825 - val_accuracy: 0.9776\n",
            "Epoch 362/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2225 - accuracy: 0.9707 - val_loss: 0.0879 - val_accuracy: 0.9794\n",
            "Epoch 363/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2051 - accuracy: 0.9707 - val_loss: 0.0863 - val_accuracy: 0.9785\n",
            "Epoch 364/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2294 - accuracy: 0.9702 - val_loss: 0.0827 - val_accuracy: 0.9772\n",
            "Epoch 365/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2148 - accuracy: 0.9712 - val_loss: 0.0940 - val_accuracy: 0.9770\n",
            "Epoch 366/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2079 - accuracy: 0.9715 - val_loss: 0.0732 - val_accuracy: 0.9807\n",
            "Epoch 367/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1933 - accuracy: 0.9719 - val_loss: 0.0898 - val_accuracy: 0.9768\n",
            "Epoch 368/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.2088 - accuracy: 0.9743 - val_loss: 0.0961 - val_accuracy: 0.9742\n",
            "Epoch 369/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1991 - accuracy: 0.9733 - val_loss: 0.0727 - val_accuracy: 0.9822\n",
            "Epoch 370/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1855 - accuracy: 0.9733 - val_loss: 0.0951 - val_accuracy: 0.9766\n",
            "Epoch 371/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1953 - accuracy: 0.9739 - val_loss: 0.0762 - val_accuracy: 0.9800\n",
            "Epoch 372/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2115 - accuracy: 0.9712 - val_loss: 0.0833 - val_accuracy: 0.9785\n",
            "Epoch 373/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1856 - accuracy: 0.9741 - val_loss: 0.1107 - val_accuracy: 0.9724\n",
            "Epoch 374/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1912 - accuracy: 0.9725 - val_loss: 0.0810 - val_accuracy: 0.9794\n",
            "Epoch 375/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2216 - accuracy: 0.9699 - val_loss: 0.0822 - val_accuracy: 0.9794\n",
            "Epoch 376/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2304 - accuracy: 0.9718 - val_loss: 0.0727 - val_accuracy: 0.9826\n",
            "Epoch 377/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1934 - accuracy: 0.9726 - val_loss: 0.0772 - val_accuracy: 0.9803\n",
            "Epoch 378/600\n",
            "336/336 [==============================] - 9s 27ms/step - loss: 0.1894 - accuracy: 0.9743 - val_loss: 0.0817 - val_accuracy: 0.9796\n",
            "Epoch 379/600\n",
            "336/336 [==============================] - 9s 27ms/step - loss: 0.2087 - accuracy: 0.9738 - val_loss: 0.0859 - val_accuracy: 0.9794\n",
            "Epoch 380/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1870 - accuracy: 0.9736 - val_loss: 0.0728 - val_accuracy: 0.9824\n",
            "Epoch 381/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1979 - accuracy: 0.9724 - val_loss: 0.0742 - val_accuracy: 0.9829\n",
            "Epoch 382/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1894 - accuracy: 0.9760 - val_loss: 0.0989 - val_accuracy: 0.9755\n",
            "Epoch 383/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.2194 - accuracy: 0.9712 - val_loss: 0.0813 - val_accuracy: 0.9796\n",
            "Epoch 384/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1877 - accuracy: 0.9733 - val_loss: 0.0794 - val_accuracy: 0.9787\n",
            "Epoch 385/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2073 - accuracy: 0.9707 - val_loss: 0.0783 - val_accuracy: 0.9826\n",
            "Epoch 386/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.2011 - accuracy: 0.9739 - val_loss: 0.1126 - val_accuracy: 0.9698\n",
            "Epoch 387/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1921 - accuracy: 0.9738 - val_loss: 0.0931 - val_accuracy: 0.9755\n",
            "Epoch 388/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1874 - accuracy: 0.9740 - val_loss: 0.0847 - val_accuracy: 0.9796\n",
            "Epoch 389/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1738 - accuracy: 0.9762 - val_loss: 0.0791 - val_accuracy: 0.9796\n",
            "Epoch 390/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1835 - accuracy: 0.9747 - val_loss: 0.0799 - val_accuracy: 0.9796\n",
            "Epoch 391/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1855 - accuracy: 0.9760 - val_loss: 0.0740 - val_accuracy: 0.9826\n",
            "Epoch 392/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.2127 - accuracy: 0.9734 - val_loss: 0.0783 - val_accuracy: 0.9800\n",
            "Epoch 393/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1897 - accuracy: 0.9751 - val_loss: 0.0953 - val_accuracy: 0.9753\n",
            "Epoch 394/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1897 - accuracy: 0.9751 - val_loss: 0.0703 - val_accuracy: 0.9829\n",
            "Epoch 395/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1812 - accuracy: 0.9745 - val_loss: 0.0949 - val_accuracy: 0.9783\n",
            "Epoch 396/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1819 - accuracy: 0.9752 - val_loss: 0.0827 - val_accuracy: 0.9770\n",
            "Epoch 397/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.2068 - accuracy: 0.9705 - val_loss: 0.0674 - val_accuracy: 0.9837\n",
            "Epoch 398/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1805 - accuracy: 0.9760 - val_loss: 0.0689 - val_accuracy: 0.9835\n",
            "Epoch 399/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1807 - accuracy: 0.9738 - val_loss: 0.0684 - val_accuracy: 0.9831\n",
            "Epoch 400/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1719 - accuracy: 0.9740 - val_loss: 0.0818 - val_accuracy: 0.9787\n",
            "Epoch 401/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1881 - accuracy: 0.9750 - val_loss: 0.1619 - val_accuracy: 0.9531\n",
            "Epoch 402/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1828 - accuracy: 0.9760 - val_loss: 0.0676 - val_accuracy: 0.9831\n",
            "Epoch 403/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1677 - accuracy: 0.9774 - val_loss: 0.0715 - val_accuracy: 0.9816\n",
            "Epoch 404/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1947 - accuracy: 0.9762 - val_loss: 0.0741 - val_accuracy: 0.9807\n",
            "Epoch 405/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1630 - accuracy: 0.9780 - val_loss: 0.0652 - val_accuracy: 0.9850\n",
            "Epoch 406/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1613 - accuracy: 0.9768 - val_loss: 0.0691 - val_accuracy: 0.9837\n",
            "Epoch 407/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1807 - accuracy: 0.9740 - val_loss: 0.1264 - val_accuracy: 0.9709\n",
            "Epoch 408/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.2057 - accuracy: 0.9734 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 409/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1903 - accuracy: 0.9745 - val_loss: 0.0753 - val_accuracy: 0.9818\n",
            "Epoch 410/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1704 - accuracy: 0.9775 - val_loss: 0.0774 - val_accuracy: 0.9794\n",
            "Epoch 411/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1794 - accuracy: 0.9756 - val_loss: 0.0772 - val_accuracy: 0.9820\n",
            "Epoch 412/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1650 - accuracy: 0.9791 - val_loss: 0.0869 - val_accuracy: 0.9792\n",
            "Epoch 413/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1950 - accuracy: 0.9745 - val_loss: 0.4018 - val_accuracy: 0.9286\n",
            "Epoch 414/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1883 - accuracy: 0.9750 - val_loss: 0.0787 - val_accuracy: 0.9800\n",
            "Epoch 415/600\n",
            "336/336 [==============================] - 9s 27ms/step - loss: 0.1791 - accuracy: 0.9753 - val_loss: 0.0766 - val_accuracy: 0.9816\n",
            "Epoch 416/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1903 - accuracy: 0.9768 - val_loss: 0.0732 - val_accuracy: 0.9822\n",
            "Epoch 417/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1734 - accuracy: 0.9779 - val_loss: 0.0798 - val_accuracy: 0.9800\n",
            "Epoch 418/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1602 - accuracy: 0.9788 - val_loss: 0.0705 - val_accuracy: 0.9833\n",
            "Epoch 419/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1792 - accuracy: 0.9758 - val_loss: 0.0764 - val_accuracy: 0.9813\n",
            "Epoch 420/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1831 - accuracy: 0.9769 - val_loss: 0.0815 - val_accuracy: 0.9803\n",
            "Epoch 421/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1751 - accuracy: 0.9757 - val_loss: 0.0791 - val_accuracy: 0.9807\n",
            "Epoch 422/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1700 - accuracy: 0.9780 - val_loss: 0.0785 - val_accuracy: 0.9807\n",
            "Epoch 423/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1699 - accuracy: 0.9774 - val_loss: 0.0777 - val_accuracy: 0.9829\n",
            "Epoch 424/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1783 - accuracy: 0.9788 - val_loss: 0.1251 - val_accuracy: 0.9701\n",
            "Epoch 425/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1663 - accuracy: 0.9751 - val_loss: 0.0686 - val_accuracy: 0.9820\n",
            "Epoch 426/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1919 - accuracy: 0.9747 - val_loss: 0.0760 - val_accuracy: 0.9796\n",
            "Epoch 427/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1753 - accuracy: 0.9772 - val_loss: 0.0753 - val_accuracy: 0.9813\n",
            "Epoch 428/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1590 - accuracy: 0.9774 - val_loss: 0.1057 - val_accuracy: 0.9733\n",
            "Epoch 429/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1898 - accuracy: 0.9736 - val_loss: 0.0684 - val_accuracy: 0.9831\n",
            "Epoch 430/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1851 - accuracy: 0.9768 - val_loss: 0.0823 - val_accuracy: 0.9796\n",
            "Epoch 431/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1904 - accuracy: 0.9756 - val_loss: 0.0679 - val_accuracy: 0.9829\n",
            "Epoch 432/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1909 - accuracy: 0.9750 - val_loss: 0.0648 - val_accuracy: 0.9844\n",
            "Epoch 433/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1665 - accuracy: 0.9778 - val_loss: 0.0699 - val_accuracy: 0.9829\n",
            "Epoch 434/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1815 - accuracy: 0.9761 - val_loss: 0.0763 - val_accuracy: 0.9811\n",
            "Epoch 435/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1914 - accuracy: 0.9755 - val_loss: 0.0685 - val_accuracy: 0.9850\n",
            "Epoch 436/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1626 - accuracy: 0.9788 - val_loss: 0.0828 - val_accuracy: 0.9803\n",
            "Epoch 437/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1656 - accuracy: 0.9786 - val_loss: 0.0702 - val_accuracy: 0.9835\n",
            "Epoch 438/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1627 - accuracy: 0.9779 - val_loss: 0.0736 - val_accuracy: 0.9820\n",
            "Epoch 439/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1602 - accuracy: 0.9779 - val_loss: 0.0898 - val_accuracy: 0.9783\n",
            "Epoch 440/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1547 - accuracy: 0.9783 - val_loss: 0.0688 - val_accuracy: 0.9833\n",
            "Epoch 441/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1785 - accuracy: 0.9738 - val_loss: 0.0832 - val_accuracy: 0.9781\n",
            "Epoch 442/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1759 - accuracy: 0.9779 - val_loss: 0.0681 - val_accuracy: 0.9835\n",
            "Epoch 443/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1587 - accuracy: 0.9773 - val_loss: 0.0741 - val_accuracy: 0.9818\n",
            "Epoch 444/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1471 - accuracy: 0.9803 - val_loss: 0.0730 - val_accuracy: 0.9820\n",
            "Epoch 445/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1798 - accuracy: 0.9777 - val_loss: 0.0722 - val_accuracy: 0.9822\n",
            "Epoch 446/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1500 - accuracy: 0.9797 - val_loss: 0.0918 - val_accuracy: 0.9753\n",
            "Epoch 447/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1649 - accuracy: 0.9784 - val_loss: 0.0740 - val_accuracy: 0.9829\n",
            "Epoch 448/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1524 - accuracy: 0.9782 - val_loss: 0.0687 - val_accuracy: 0.9848\n",
            "Epoch 449/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1611 - accuracy: 0.9779 - val_loss: 0.1331 - val_accuracy: 0.9696\n",
            "Epoch 450/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1585 - accuracy: 0.9790 - val_loss: 0.0937 - val_accuracy: 0.9763\n",
            "Epoch 451/600\n",
            "336/336 [==============================] - 9s 27ms/step - loss: 0.1639 - accuracy: 0.9763 - val_loss: 0.0805 - val_accuracy: 0.9835\n",
            "Epoch 452/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1421 - accuracy: 0.9805 - val_loss: 0.0806 - val_accuracy: 0.9809\n",
            "Epoch 453/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1645 - accuracy: 0.9787 - val_loss: 0.0750 - val_accuracy: 0.9820\n",
            "Epoch 454/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1614 - accuracy: 0.9780 - val_loss: 0.0750 - val_accuracy: 0.9835\n",
            "Epoch 455/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1561 - accuracy: 0.9794 - val_loss: 0.0726 - val_accuracy: 0.9844\n",
            "Epoch 456/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1652 - accuracy: 0.9787 - val_loss: 0.0807 - val_accuracy: 0.9813\n",
            "Epoch 457/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1586 - accuracy: 0.9767 - val_loss: 0.0807 - val_accuracy: 0.9833\n",
            "Epoch 458/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1533 - accuracy: 0.9787 - val_loss: 0.1099 - val_accuracy: 0.9735\n",
            "Epoch 459/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1569 - accuracy: 0.9774 - val_loss: 0.0741 - val_accuracy: 0.9824\n",
            "Epoch 460/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1617 - accuracy: 0.9782 - val_loss: 0.0704 - val_accuracy: 0.9833\n",
            "Epoch 461/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1400 - accuracy: 0.9807 - val_loss: 0.0705 - val_accuracy: 0.9833\n",
            "Epoch 462/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1481 - accuracy: 0.9807 - val_loss: 0.0785 - val_accuracy: 0.9822\n",
            "Epoch 463/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1530 - accuracy: 0.9788 - val_loss: 0.0745 - val_accuracy: 0.9822\n",
            "Epoch 464/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1467 - accuracy: 0.9792 - val_loss: 0.0740 - val_accuracy: 0.9822\n",
            "Epoch 465/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1618 - accuracy: 0.9793 - val_loss: 0.0815 - val_accuracy: 0.9805\n",
            "Epoch 466/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1688 - accuracy: 0.9793 - val_loss: 0.0734 - val_accuracy: 0.9826\n",
            "Epoch 467/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1310 - accuracy: 0.9815 - val_loss: 0.0945 - val_accuracy: 0.9740\n",
            "Epoch 468/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1547 - accuracy: 0.9791 - val_loss: 0.0688 - val_accuracy: 0.9822\n",
            "Epoch 469/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1416 - accuracy: 0.9805 - val_loss: 0.0696 - val_accuracy: 0.9844\n",
            "Epoch 470/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1707 - accuracy: 0.9790 - val_loss: 0.0731 - val_accuracy: 0.9809\n",
            "Epoch 471/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1733 - accuracy: 0.9766 - val_loss: 0.0688 - val_accuracy: 0.9848\n",
            "Epoch 472/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1575 - accuracy: 0.9803 - val_loss: 0.0726 - val_accuracy: 0.9813\n",
            "Epoch 473/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1519 - accuracy: 0.9786 - val_loss: 0.0633 - val_accuracy: 0.9850\n",
            "Epoch 474/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1559 - accuracy: 0.9793 - val_loss: 0.0663 - val_accuracy: 0.9850\n",
            "Epoch 475/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1688 - accuracy: 0.9792 - val_loss: 0.0694 - val_accuracy: 0.9835\n",
            "Epoch 476/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1458 - accuracy: 0.9781 - val_loss: 0.0657 - val_accuracy: 0.9852\n",
            "Epoch 477/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1523 - accuracy: 0.9798 - val_loss: 0.0616 - val_accuracy: 0.9861\n",
            "Epoch 478/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1653 - accuracy: 0.9789 - val_loss: 0.0712 - val_accuracy: 0.9850\n",
            "Epoch 479/600\n",
            "336/336 [==============================] - 9s 27ms/step - loss: 0.1418 - accuracy: 0.9807 - val_loss: 0.0673 - val_accuracy: 0.9837\n",
            "Epoch 480/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1305 - accuracy: 0.9827 - val_loss: 0.0713 - val_accuracy: 0.9835\n",
            "Epoch 481/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1374 - accuracy: 0.9809 - val_loss: 0.0753 - val_accuracy: 0.9829\n",
            "Epoch 482/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1464 - accuracy: 0.9781 - val_loss: 0.0726 - val_accuracy: 0.9846\n",
            "Epoch 483/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1588 - accuracy: 0.9799 - val_loss: 0.0687 - val_accuracy: 0.9861\n",
            "Epoch 484/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1717 - accuracy: 0.9782 - val_loss: 0.0630 - val_accuracy: 0.9852\n",
            "Epoch 485/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1568 - accuracy: 0.9795 - val_loss: 0.0661 - val_accuracy: 0.9842\n",
            "Epoch 486/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1487 - accuracy: 0.9810 - val_loss: 0.0633 - val_accuracy: 0.9852\n",
            "Epoch 487/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1327 - accuracy: 0.9796 - val_loss: 0.0698 - val_accuracy: 0.9831\n",
            "Epoch 488/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1399 - accuracy: 0.9819 - val_loss: 0.0668 - val_accuracy: 0.9852\n",
            "Epoch 489/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1423 - accuracy: 0.9805 - val_loss: 0.0886 - val_accuracy: 0.9750\n",
            "Epoch 490/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1413 - accuracy: 0.9801 - val_loss: 0.0620 - val_accuracy: 0.9850\n",
            "Epoch 491/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1366 - accuracy: 0.9803 - val_loss: 0.0678 - val_accuracy: 0.9842\n",
            "Epoch 492/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1457 - accuracy: 0.9786 - val_loss: 0.0657 - val_accuracy: 0.9833\n",
            "Epoch 493/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1695 - accuracy: 0.9782 - val_loss: 0.0606 - val_accuracy: 0.9855\n",
            "Epoch 494/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1262 - accuracy: 0.9830 - val_loss: 0.0680 - val_accuracy: 0.9837\n",
            "Epoch 495/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1304 - accuracy: 0.9815 - val_loss: 0.0676 - val_accuracy: 0.9835\n",
            "Epoch 496/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1437 - accuracy: 0.9804 - val_loss: 0.0748 - val_accuracy: 0.9829\n",
            "Epoch 497/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1433 - accuracy: 0.9813 - val_loss: 0.0641 - val_accuracy: 0.9835\n",
            "Epoch 498/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1598 - accuracy: 0.9802 - val_loss: 0.0666 - val_accuracy: 0.9833\n",
            "Epoch 499/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1427 - accuracy: 0.9809 - val_loss: 0.0701 - val_accuracy: 0.9837\n",
            "Epoch 500/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1424 - accuracy: 0.9828 - val_loss: 0.0619 - val_accuracy: 0.9863\n",
            "Epoch 501/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1519 - accuracy: 0.9802 - val_loss: 0.0679 - val_accuracy: 0.9846\n",
            "Epoch 502/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1418 - accuracy: 0.9804 - val_loss: 0.0661 - val_accuracy: 0.9842\n",
            "Epoch 503/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1237 - accuracy: 0.9817 - val_loss: 0.0663 - val_accuracy: 0.9842\n",
            "Epoch 504/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1398 - accuracy: 0.9808 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
            "Epoch 505/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1425 - accuracy: 0.9821 - val_loss: 0.0719 - val_accuracy: 0.9824\n",
            "Epoch 506/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1536 - accuracy: 0.9797 - val_loss: 0.0701 - val_accuracy: 0.9816\n",
            "Epoch 507/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1343 - accuracy: 0.9797 - val_loss: 0.0749 - val_accuracy: 0.9818\n",
            "Epoch 508/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1419 - accuracy: 0.9814 - val_loss: 0.0722 - val_accuracy: 0.9829\n",
            "Epoch 509/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1484 - accuracy: 0.9798 - val_loss: 0.0729 - val_accuracy: 0.9829\n",
            "Epoch 510/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1355 - accuracy: 0.9813 - val_loss: 0.0755 - val_accuracy: 0.9833\n",
            "Epoch 511/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1339 - accuracy: 0.9847 - val_loss: 0.0703 - val_accuracy: 0.9848\n",
            "Epoch 512/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1157 - accuracy: 0.9844 - val_loss: 0.0649 - val_accuracy: 0.9842\n",
            "Epoch 513/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1285 - accuracy: 0.9813 - val_loss: 0.0717 - val_accuracy: 0.9824\n",
            "Epoch 514/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1513 - accuracy: 0.9805 - val_loss: 0.0716 - val_accuracy: 0.9831\n",
            "Epoch 515/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1427 - accuracy: 0.9807 - val_loss: 0.0727 - val_accuracy: 0.9826\n",
            "Epoch 516/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1435 - accuracy: 0.9793 - val_loss: 0.0705 - val_accuracy: 0.9833\n",
            "Epoch 517/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1290 - accuracy: 0.9829 - val_loss: 0.0637 - val_accuracy: 0.9844\n",
            "Epoch 518/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1197 - accuracy: 0.9829 - val_loss: 0.0662 - val_accuracy: 0.9839\n",
            "Epoch 519/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1481 - accuracy: 0.9806 - val_loss: 0.0687 - val_accuracy: 0.9837\n",
            "Epoch 520/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1339 - accuracy: 0.9810 - val_loss: 0.1212 - val_accuracy: 0.9707\n",
            "Epoch 521/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1294 - accuracy: 0.9824 - val_loss: 0.0669 - val_accuracy: 0.9842\n",
            "Epoch 522/600\n",
            "336/336 [==============================] - 9s 25ms/step - loss: 0.1267 - accuracy: 0.9831 - val_loss: 0.0653 - val_accuracy: 0.9848\n",
            "Epoch 523/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1253 - accuracy: 0.9831 - val_loss: 0.0705 - val_accuracy: 0.9831\n",
            "Epoch 524/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1267 - accuracy: 0.9831 - val_loss: 0.0741 - val_accuracy: 0.9816\n",
            "Epoch 525/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1419 - accuracy: 0.9804 - val_loss: 0.0642 - val_accuracy: 0.9837\n",
            "Epoch 526/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1324 - accuracy: 0.9822 - val_loss: 0.0672 - val_accuracy: 0.9848\n",
            "Epoch 527/600\n",
            "336/336 [==============================] - 9s 26ms/step - loss: 0.1495 - accuracy: 0.9822 - val_loss: 0.0714 - val_accuracy: 0.9829\n",
            "Epoch 528/600\n",
            "336/336 [==============================] - 8s 25ms/step - loss: 0.1392 - accuracy: 0.9830 - val_loss: 0.0670 - val_accuracy: 0.9842\n",
            "Epoch 529/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1497 - accuracy: 0.9812 - val_loss: 0.0700 - val_accuracy: 0.9831\n",
            "Epoch 530/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1384 - accuracy: 0.9821 - val_loss: 0.0676 - val_accuracy: 0.9829\n",
            "Epoch 531/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1391 - accuracy: 0.9822 - val_loss: 0.0668 - val_accuracy: 0.9829\n",
            "Epoch 532/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1213 - accuracy: 0.9829 - val_loss: 0.0635 - val_accuracy: 0.9837\n",
            "Epoch 533/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1191 - accuracy: 0.9831 - val_loss: 0.0636 - val_accuracy: 0.9837\n",
            "Epoch 534/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1212 - accuracy: 0.9840 - val_loss: 0.0658 - val_accuracy: 0.9831\n",
            "Epoch 535/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1333 - accuracy: 0.9821 - val_loss: 0.0631 - val_accuracy: 0.9842\n",
            "Epoch 536/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1163 - accuracy: 0.9837 - val_loss: 0.0606 - val_accuracy: 0.9844\n",
            "Epoch 537/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1103 - accuracy: 0.9835 - val_loss: 0.0606 - val_accuracy: 0.9844\n",
            "Epoch 538/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1306 - accuracy: 0.9831 - val_loss: 0.0697 - val_accuracy: 0.9833\n",
            "Epoch 539/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1452 - accuracy: 0.9806 - val_loss: 0.0711 - val_accuracy: 0.9822\n",
            "Epoch 540/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1246 - accuracy: 0.9832 - val_loss: 0.0621 - val_accuracy: 0.9848\n",
            "Epoch 541/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1199 - accuracy: 0.9844 - val_loss: 0.0666 - val_accuracy: 0.9833\n",
            "Epoch 542/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1183 - accuracy: 0.9827 - val_loss: 0.0714 - val_accuracy: 0.9837\n",
            "Epoch 543/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1150 - accuracy: 0.9845 - val_loss: 0.0667 - val_accuracy: 0.9835\n",
            "Epoch 544/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1107 - accuracy: 0.9851 - val_loss: 0.0706 - val_accuracy: 0.9831\n",
            "Epoch 545/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1399 - accuracy: 0.9846 - val_loss: 0.0733 - val_accuracy: 0.9820\n",
            "Epoch 546/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1238 - accuracy: 0.9828 - val_loss: 0.0710 - val_accuracy: 0.9829\n",
            "Epoch 547/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1075 - accuracy: 0.9842 - val_loss: 0.0659 - val_accuracy: 0.9844\n",
            "Epoch 548/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1325 - accuracy: 0.9828 - val_loss: 0.0743 - val_accuracy: 0.9829\n",
            "Epoch 549/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1259 - accuracy: 0.9825 - val_loss: 0.0721 - val_accuracy: 0.9822\n",
            "Epoch 550/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1099 - accuracy: 0.9837 - val_loss: 0.0667 - val_accuracy: 0.9837\n",
            "Epoch 551/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1173 - accuracy: 0.9830 - val_loss: 0.0715 - val_accuracy: 0.9833\n",
            "Epoch 552/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1315 - accuracy: 0.9830 - val_loss: 0.0676 - val_accuracy: 0.9837\n",
            "Epoch 553/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1214 - accuracy: 0.9826 - val_loss: 0.0711 - val_accuracy: 0.9826\n",
            "Epoch 554/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1112 - accuracy: 0.9852 - val_loss: 0.0715 - val_accuracy: 0.9824\n",
            "Epoch 555/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1226 - accuracy: 0.9839 - val_loss: 0.0650 - val_accuracy: 0.9842\n",
            "Epoch 556/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1123 - accuracy: 0.9841 - val_loss: 0.0713 - val_accuracy: 0.9835\n",
            "Epoch 557/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1227 - accuracy: 0.9824 - val_loss: 0.0687 - val_accuracy: 0.9837\n",
            "Epoch 558/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1048 - accuracy: 0.9863 - val_loss: 0.0691 - val_accuracy: 0.9826\n",
            "Epoch 559/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1098 - accuracy: 0.9860 - val_loss: 0.0672 - val_accuracy: 0.9831\n",
            "Epoch 560/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1190 - accuracy: 0.9838 - val_loss: 0.0680 - val_accuracy: 0.9818\n",
            "Epoch 561/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1095 - accuracy: 0.9840 - val_loss: 0.0699 - val_accuracy: 0.9833\n",
            "Epoch 562/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1167 - accuracy: 0.9844 - val_loss: 0.0697 - val_accuracy: 0.9833\n",
            "Epoch 563/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1135 - accuracy: 0.9849 - val_loss: 0.0671 - val_accuracy: 0.9831\n",
            "Epoch 564/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1099 - accuracy: 0.9841 - val_loss: 0.0685 - val_accuracy: 0.9837\n",
            "Epoch 565/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1000 - accuracy: 0.9855 - val_loss: 0.0705 - val_accuracy: 0.9826\n",
            "Epoch 566/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1114 - accuracy: 0.9858 - val_loss: 0.0677 - val_accuracy: 0.9831\n",
            "Epoch 567/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1167 - accuracy: 0.9838 - val_loss: 0.0658 - val_accuracy: 0.9837\n",
            "Epoch 568/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1305 - accuracy: 0.9836 - val_loss: 0.0662 - val_accuracy: 0.9844\n",
            "Epoch 569/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1179 - accuracy: 0.9846 - val_loss: 0.0642 - val_accuracy: 0.9848\n",
            "Epoch 570/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1041 - accuracy: 0.9852 - val_loss: 0.0659 - val_accuracy: 0.9835\n",
            "Epoch 571/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1010 - accuracy: 0.9871 - val_loss: 0.0663 - val_accuracy: 0.9835\n",
            "Epoch 572/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1075 - accuracy: 0.9855 - val_loss: 0.0663 - val_accuracy: 0.9844\n",
            "Epoch 573/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.0988 - accuracy: 0.9854 - val_loss: 0.0661 - val_accuracy: 0.9842\n",
            "Epoch 574/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1232 - accuracy: 0.9832 - val_loss: 0.0657 - val_accuracy: 0.9848\n",
            "Epoch 575/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1126 - accuracy: 0.9849 - val_loss: 0.0658 - val_accuracy: 0.9850\n",
            "Epoch 576/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1044 - accuracy: 0.9847 - val_loss: 0.0666 - val_accuracy: 0.9850\n",
            "Epoch 577/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1042 - accuracy: 0.9862 - val_loss: 0.0660 - val_accuracy: 0.9848\n",
            "Epoch 578/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1084 - accuracy: 0.9859 - val_loss: 0.0650 - val_accuracy: 0.9844\n",
            "Epoch 579/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1097 - accuracy: 0.9851 - val_loss: 0.0669 - val_accuracy: 0.9850\n",
            "Epoch 580/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1095 - accuracy: 0.9833 - val_loss: 0.0659 - val_accuracy: 0.9848\n",
            "Epoch 581/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1152 - accuracy: 0.9852 - val_loss: 0.0654 - val_accuracy: 0.9850\n",
            "Epoch 582/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1030 - accuracy: 0.9869 - val_loss: 0.0653 - val_accuracy: 0.9846\n",
            "Epoch 583/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1182 - accuracy: 0.9837 - val_loss: 0.0682 - val_accuracy: 0.9846\n",
            "Epoch 584/600\n",
            "336/336 [==============================] - 8s 24ms/step - loss: 0.1036 - accuracy: 0.9841 - val_loss: 0.0684 - val_accuracy: 0.9848\n",
            "Epoch 585/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1215 - accuracy: 0.9838 - val_loss: 0.0661 - val_accuracy: 0.9846\n",
            "Epoch 586/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.0989 - accuracy: 0.9872 - val_loss: 0.0657 - val_accuracy: 0.9850\n",
            "Epoch 587/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1127 - accuracy: 0.9839 - val_loss: 0.0664 - val_accuracy: 0.9844\n",
            "Epoch 588/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1068 - accuracy: 0.9846 - val_loss: 0.0661 - val_accuracy: 0.9855\n",
            "Epoch 589/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1047 - accuracy: 0.9859 - val_loss: 0.0669 - val_accuracy: 0.9850\n",
            "Epoch 590/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1132 - accuracy: 0.9850 - val_loss: 0.0664 - val_accuracy: 0.9846\n",
            "Epoch 591/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1095 - accuracy: 0.9850 - val_loss: 0.0671 - val_accuracy: 0.9842\n",
            "Epoch 592/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1073 - accuracy: 0.9846 - val_loss: 0.0661 - val_accuracy: 0.9842\n",
            "Epoch 593/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1068 - accuracy: 0.9856 - val_loss: 0.0666 - val_accuracy: 0.9844\n",
            "Epoch 594/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1106 - accuracy: 0.9848 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
            "Epoch 595/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.0954 - accuracy: 0.9864 - val_loss: 0.0666 - val_accuracy: 0.9848\n",
            "Epoch 596/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1081 - accuracy: 0.9858 - val_loss: 0.0665 - val_accuracy: 0.9848\n",
            "Epoch 597/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1146 - accuracy: 0.9844 - val_loss: 0.0663 - val_accuracy: 0.9848\n",
            "Epoch 598/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1024 - accuracy: 0.9842 - val_loss: 0.0663 - val_accuracy: 0.9842\n",
            "Epoch 599/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1054 - accuracy: 0.9855 - val_loss: 0.0659 - val_accuracy: 0.9848\n",
            "Epoch 600/600\n",
            "336/336 [==============================] - 8s 23ms/step - loss: 0.1079 - accuracy: 0.9851 - val_loss: 0.0658 - val_accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW96qUuDVf9D"
      },
      "source": [
        "# save the model\n",
        "model.save(f\"{dbBase}//model_mvcnn_color_roi_10class_28px1px_threshinv_255_minvgg_crop32px.h5\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlJvk8zWwhz_",
        "outputId": "c8fc9f9a-4ea7-49ac-8141-09efcd602336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sp"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<loader_util.preprocessing.simplepreprocesor.SimplePreProcessor at 0x7f6040a424a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kofqlYIVf9b",
        "outputId": "b5fac978-7e58-42d6-f22c-a87e832e8921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# calculate the classification report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "validDB = h5py.File(dbValidPath, mode=\"r\")\n",
        "testx = validDB[\"images\"][:]\n",
        "testy = to_categorical(validDB[\"labels\"][:], class_num)\n",
        "\n",
        "testx_resized = np.array([sp.preprocess(img) for img in testx])\n",
        "testx_resized = np.expand_dims(testx_resized, -1)\n",
        "testx_resized.shape\n",
        "\n",
        "preds = model.predict(testx_resized, batch_size=batch_size)\n",
        "print(classification_report(testy.argmax(axis=1),\n",
        "                            preds.argmax(axis=1)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       194\n",
            "           1       0.95      0.94      0.94       464\n",
            "           2       0.94      0.93      0.94       288\n",
            "           3       1.00      1.00      1.00       263\n",
            "           4       0.99      1.00      0.99       554\n",
            "           5       1.00      1.00      1.00       317\n",
            "           6       1.00      1.00      1.00      1157\n",
            "           7       0.99      1.00      1.00       342\n",
            "           8       0.99      0.99      0.99       796\n",
            "           9       0.97      0.93      0.95       238\n",
            "\n",
            "    accuracy                           0.98      4613\n",
            "   macro avg       0.98      0.98      0.98      4613\n",
            "weighted avg       0.98      0.98      0.98      4613\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muzPuaCcVf9k",
        "outputId": "9b829672-a62b-458d-96af-d946b6d30cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "# print confusion matrix\n",
        "labels = list(trainFile[\"label_names\"])\n",
        "labels = [label.decode() for label in labels]\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(testy.argmax(axis=1),\n",
        "                    preds.argmax(axis=1),\n",
        "                    )\n",
        "\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "\n",
        "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names)\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='viridis')\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "print_confusion_matrix(cm, class_names=labels)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSEz_RnHfkIK",
        "outputId": "42e3aa82-955b-4c08-934c-9b6bda6f778e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "for layer in model.layers:\n",
        "  print(layer)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f604099cbe0>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f60409b4550>\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f60409b45f8>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f60409b4b70>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f603011cb00>\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f60301302b0>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f60301308d0>\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f60300bba20>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f60300d18d0>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f60300e1e48>\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f60300e1eb8>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f60300e8240>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f6030084b00>\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6030084b38>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f60300e7128>\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f60300932e8>\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f60300a4dd8>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f60300a4f98>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f6030033908>\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f60300339b0>\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f6030033b38>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f603003c940>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f6030066978>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guH6INHTsu_1",
        "outputId": "33c37952-d659-4231-b73b-88794494256c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "flattened_layer = model.layers[16]\n",
        "retrieval_model = Model(inputs=model.input, outputs=flattened_layer.output)\n",
        "retrieval_model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_input (InputLayer)    [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "=================================================================\n",
            "Total params: 65,760\n",
            "Trainable params: 65,376\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBYBSpCAwJFf",
        "outputId": "0a20f322-681e-4aef-b71c-8c5bc670b6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_image = trainFile[\"images\"][0]\n",
        "sample_image = sp.preprocess(sample_image)\n",
        "sample_image = np.expand_dims(sample_image, 0)\n",
        "sample_image = np.expand_dims(sample_image, -1)\n",
        "sample_image.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w7JICOqxIbW",
        "outputId": "fa731439-cb34-4d4b-89db-55ea35b31004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out_vect = retrieval_model.predict(sample_image)\n",
        "out_vect.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3136)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSpG8flmxRXp",
        "outputId": "5871c5c2-7de6-46ce-b69d-72c53c8d7a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "out_vect"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.0033077 , -0.79984945, -0.1830943 , ..., -0.44663826,\n",
              "        -0.38639158, -1.3448461 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OOt9d8ZyIol",
        "outputId": "1700e937-1e11-4e8e-c215-2c66fe9c2733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res = model.predict(sample_image)\n",
        "np.argmax(res, axis=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eFXm3v2yaJM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}