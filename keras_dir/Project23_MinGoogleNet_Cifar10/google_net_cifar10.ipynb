{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.axes._axes as axes\n",
    "from cv2 import cv2\n",
    "import os\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from loader_util.preprocessing import ImageToArrayPreprocessor, \\\n",
    "    AspectAwarePreprocessor, MeanPreprocessor, MeanSubtractionPreProcessor\n",
    "from loader_util.datasets import SimpleDatasetLoader\n",
    "from loader_util.nn.conv import FCHeadNet, MiniGoogleNet\n",
    "##\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from loader_util.callbacks import TrainingMonitor\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the total no of epochs\n",
    "NUM_EPOCHS = 70\n",
    "INIT_LR = 5e-3\n",
    "batch_size = 64\n",
    "\n",
    "# define the polynomial learnign rate scheduler\n",
    "def poly_decay(epoch):\n",
    "    # initialise the max no of epochs\n",
    "    max_epochs = NUM_EPOCHS\n",
    "    base_lr = INIT_LR\n",
    "    power = 1.0\n",
    "    \n",
    "    # compute new learnign enumerate\n",
    "    alpha = base_lr * (1 - (epoch / float(max_epochs)))**power\n",
    "    \n",
    "    # return the new lr\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the train test set\n",
    "(trainx, trainy), (testx, testy) = cifar10.load_data()\n",
    "trainx = trainx.astype('float')\n",
    "testx = testx.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mp = MeanSubtractionPreProcessor()\n",
    "\n",
    "def preprocess_image(dataset: List[np.ndarray]):\n",
    "    return_data = []\n",
    "    \n",
    "    for image in dataset:\n",
    "        processed_image = mp.preprocess(image)\n",
    "        return_data.append(processed_image)\n",
    "        \n",
    "    return np.array(return_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# apply normalisation to images\n",
    "trainx = preprocess_image(trainx)\n",
    "testx = preprocess_image(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainy = lb.fit_transform(trainy)\n",
    "testy = lb.transform(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         horizontal_flip=True,\n",
    "                         fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct the set of callbacks\n",
    "fig_path = os.path.sep.join(['./', f\"{os.getpid()}.png\"])\n",
    "json_path = os.path.sep.join(['./', f\"{os.getpid()}.json\"])\n",
    "callbacks = [TrainingMonitor(fig_path, json_path),\n",
    "             LearningRateScheduler(poly_decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling Model....\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# initialise the optimizer model\n",
    "print(f'[INFO] Compiling Model....')\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model = MiniGoogleNet.build(width=32,\n",
    "                            height=32,\n",
    "                            depth=3,\n",
    "                            classes=10)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network....\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/70\n",
      "10000/10000 [==============================] - 5s 527us/sample - loss: 1.5402 - acc: 0.4918\n",
      "782/782 [==============================] - 89s 114ms/step - loss: 1.4955 - acc: 0.4630 - val_loss: 1.5403 - val_acc: 0.4918\n",
      "Epoch 2/70\n",
      "10000/10000 [==============================] - 5s 459us/sample - loss: 1.2299 - acc: 0.5717\n",
      "782/782 [==============================] - 85s 109ms/step - loss: 1.0759 - acc: 0.6215 - val_loss: 1.2283 - val_acc: 0.5717\n",
      "Epoch 3/70\n",
      "10000/10000 [==============================] - 5s 459us/sample - loss: 0.8974 - acc: 0.6846\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.8990 - acc: 0.6845 - val_loss: 0.8966 - val_acc: 0.6846\n",
      "Epoch 4/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 1.0090 - acc: 0.6689\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.7944 - acc: 0.7230 - val_loss: 1.0079 - val_acc: 0.6689\n",
      "Epoch 5/70\n",
      "10000/10000 [==============================] - 5s 464us/sample - loss: 0.8867 - acc: 0.6949\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.7108 - acc: 0.7535 - val_loss: 0.8851 - val_acc: 0.6949\n",
      "Epoch 6/70\n",
      "10000/10000 [==============================] - 5s 466us/sample - loss: 0.8328 - acc: 0.7301\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6545 - acc: 0.7725 - val_loss: 0.8312 - val_acc: 0.7301\n",
      "Epoch 7/70\n",
      "10000/10000 [==============================] - 5s 464us/sample - loss: 0.7877 - acc: 0.7354\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.6077 - acc: 0.7916 - val_loss: 0.7865 - val_acc: 0.7354\n",
      "Epoch 8/70\n",
      "10000/10000 [==============================] - 5s 470us/sample - loss: 0.7301 - acc: 0.7474\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5606 - acc: 0.8088 - val_loss: 0.7295 - val_acc: 0.7474\n",
      "Epoch 9/70\n",
      "10000/10000 [==============================] - 5s 474us/sample - loss: 0.5890 - acc: 0.8013\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5264 - acc: 0.8210 - val_loss: 0.5885 - val_acc: 0.8013\n",
      "Epoch 10/70\n",
      "10000/10000 [==============================] - 5s 464us/sample - loss: 0.7649 - acc: 0.7478\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.4972 - acc: 0.8298 - val_loss: 0.7640 - val_acc: 0.7478\n",
      "Epoch 11/70\n",
      "10000/10000 [==============================] - 5s 462us/sample - loss: 0.6736 - acc: 0.7802\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.4734 - acc: 0.8372 - val_loss: 0.6717 - val_acc: 0.7802\n",
      "Epoch 12/70\n",
      "10000/10000 [==============================] - 5s 460us/sample - loss: 0.6722 - acc: 0.7798\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.4439 - acc: 0.8495 - val_loss: 0.6716 - val_acc: 0.7798\n",
      "Epoch 13/70\n",
      "10000/10000 [==============================] - 5s 460us/sample - loss: 0.5653 - acc: 0.8145\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.4279 - acc: 0.8534 - val_loss: 0.5633 - val_acc: 0.8145\n",
      "Epoch 14/70\n",
      "10000/10000 [==============================] - 5s 462us/sample - loss: 0.9553 - acc: 0.7372\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.4071 - acc: 0.8602 - val_loss: 0.9541 - val_acc: 0.7372\n",
      "Epoch 15/70\n",
      "10000/10000 [==============================] - 5s 466us/sample - loss: 0.4615 - acc: 0.8470\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.3887 - acc: 0.8673 - val_loss: 0.4611 - val_acc: 0.8470\n",
      "Epoch 16/70\n",
      "10000/10000 [==============================] - 5s 467us/sample - loss: 0.4997 - acc: 0.8383\n",
      "782/782 [==============================] - 86s 111ms/step - loss: 0.3693 - acc: 0.8743 - val_loss: 0.4988 - val_acc: 0.8383\n",
      "Epoch 17/70\n",
      "10000/10000 [==============================] - 5s 470us/sample - loss: 0.5418 - acc: 0.8225\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.3556 - acc: 0.8791 - val_loss: 0.5426 - val_acc: 0.8225\n",
      "Epoch 18/70\n",
      "10000/10000 [==============================] - 5s 465us/sample - loss: 0.5458 - acc: 0.8295\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.3449 - acc: 0.8814 - val_loss: 0.5461 - val_acc: 0.8295\n",
      "Epoch 19/70\n",
      "10000/10000 [==============================] - 5s 466us/sample - loss: 0.8205 - acc: 0.7597\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.3305 - acc: 0.8868 - val_loss: 0.8186 - val_acc: 0.7597\n",
      "Epoch 20/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.6442 - acc: 0.8059\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.3170 - acc: 0.8918 - val_loss: 0.6457 - val_acc: 0.8059\n",
      "Epoch 21/70\n",
      "10000/10000 [==============================] - 5s 464us/sample - loss: 0.5154 - acc: 0.8359\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.3032 - acc: 0.8961 - val_loss: 0.5140 - val_acc: 0.8359\n",
      "Epoch 22/70\n",
      "10000/10000 [==============================] - 5s 465us/sample - loss: 0.5582 - acc: 0.8224\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2854 - acc: 0.9025 - val_loss: 0.5574 - val_acc: 0.8224\n",
      "Epoch 23/70\n",
      "10000/10000 [==============================] - 5s 461us/sample - loss: 0.6022 - acc: 0.8163\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2816 - acc: 0.9024 - val_loss: 0.6027 - val_acc: 0.8163\n",
      "Epoch 24/70\n",
      "10000/10000 [==============================] - 5s 464us/sample - loss: 0.4492 - acc: 0.8583\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2676 - acc: 0.9069 - val_loss: 0.4487 - val_acc: 0.8583\n",
      "Epoch 25/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.4603 - acc: 0.8583\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2594 - acc: 0.9123 - val_loss: 0.4591 - val_acc: 0.8583\n",
      "Epoch 26/70\n",
      "10000/10000 [==============================] - 5s 462us/sample - loss: 0.6229 - acc: 0.8224\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2519 - acc: 0.9122 - val_loss: 0.6225 - val_acc: 0.8224\n",
      "Epoch 27/70\n",
      "10000/10000 [==============================] - 5s 473us/sample - loss: 0.4609 - acc: 0.8518\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2398 - acc: 0.9182 - val_loss: 0.4607 - val_acc: 0.8518\n",
      "Epoch 28/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.4920 - acc: 0.8540\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.2298 - acc: 0.9202 - val_loss: 0.4929 - val_acc: 0.8540\n",
      "Epoch 29/70\n",
      "10000/10000 [==============================] - 5s 464us/sample - loss: 0.4382 - acc: 0.8612\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2238 - acc: 0.9234 - val_loss: 0.4366 - val_acc: 0.8612\n",
      "Epoch 30/70\n",
      "10000/10000 [==============================] - 5s 471us/sample - loss: 0.4103 - acc: 0.8691\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2134 - acc: 0.9256 - val_loss: 0.4090 - val_acc: 0.8691\n",
      "Epoch 31/70\n",
      "10000/10000 [==============================] - 5s 466us/sample - loss: 0.5558 - acc: 0.8405\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2094 - acc: 0.9277 - val_loss: 0.5555 - val_acc: 0.8405\n",
      "Epoch 32/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.4974 - acc: 0.8517\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2021 - acc: 0.9303 - val_loss: 0.4974 - val_acc: 0.8517\n",
      "Epoch 33/70\n",
      "10000/10000 [==============================] - 5s 457us/sample - loss: 0.6354 - acc: 0.8328\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1885 - acc: 0.9357 - val_loss: 0.6346 - val_acc: 0.8328\n",
      "Epoch 34/70\n",
      "10000/10000 [==============================] - 5s 464us/sample - loss: 0.7090 - acc: 0.8091\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1853 - acc: 0.9362 - val_loss: 0.7078 - val_acc: 0.8091\n",
      "Epoch 35/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.4888 - acc: 0.8599\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1798 - acc: 0.9371 - val_loss: 0.4888 - val_acc: 0.8599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/70\n",
      "10000/10000 [==============================] - 5s 466us/sample - loss: 0.5042 - acc: 0.8557\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.1735 - acc: 0.9405 - val_loss: 0.5038 - val_acc: 0.8557\n",
      "Epoch 37/70\n",
      "10000/10000 [==============================] - 5s 462us/sample - loss: 0.4865 - acc: 0.8657\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.1610 - acc: 0.9438 - val_loss: 0.4858 - val_acc: 0.8657\n",
      "Epoch 38/70\n",
      "10000/10000 [==============================] - 5s 462us/sample - loss: 0.5278 - acc: 0.8424\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1597 - acc: 0.9448 - val_loss: 0.5256 - val_acc: 0.8424\n",
      "Epoch 39/70\n",
      "10000/10000 [==============================] - 5s 468us/sample - loss: 0.4466 - acc: 0.8669\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.1537 - acc: 0.9479 - val_loss: 0.4459 - val_acc: 0.8669\n",
      "Epoch 40/70\n",
      "10000/10000 [==============================] - 5s 461us/sample - loss: 0.4998 - acc: 0.8556\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1435 - acc: 0.9502 - val_loss: 0.4997 - val_acc: 0.8556\n",
      "Epoch 41/70\n",
      "10000/10000 [==============================] - 5s 461us/sample - loss: 0.5037 - acc: 0.8600\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1458 - acc: 0.9499 - val_loss: 0.5029 - val_acc: 0.8600\n",
      "Epoch 42/70\n",
      "10000/10000 [==============================] - 5s 461us/sample - loss: 0.5367 - acc: 0.8647\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1385 - acc: 0.9521 - val_loss: 0.5368 - val_acc: 0.8647\n",
      "Epoch 43/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.5106 - acc: 0.8558\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1325 - acc: 0.9550 - val_loss: 0.5109 - val_acc: 0.8558\n",
      "Epoch 44/70\n",
      "10000/10000 [==============================] - 5s 461us/sample - loss: 0.4353 - acc: 0.8792\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1257 - acc: 0.9579 - val_loss: 0.4352 - val_acc: 0.8792\n",
      "Epoch 45/70\n",
      "10000/10000 [==============================] - 5s 466us/sample - loss: 0.4258 - acc: 0.8815\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1195 - acc: 0.9577 - val_loss: 0.4265 - val_acc: 0.8815\n",
      "Epoch 46/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.5007 - acc: 0.8682\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1130 - acc: 0.9611 - val_loss: 0.5023 - val_acc: 0.8682\n",
      "Epoch 47/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.4200 - acc: 0.8800\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.1102 - acc: 0.9619 - val_loss: 0.4215 - val_acc: 0.8800\n",
      "Epoch 48/70\n",
      "10000/10000 [==============================] - 5s 460us/sample - loss: 0.4606 - acc: 0.8740\n",
      "782/782 [==============================] - 85s 109ms/step - loss: 0.1081 - acc: 0.9628 - val_loss: 0.4621 - val_acc: 0.8740\n",
      "Epoch 49/70\n",
      "10000/10000 [==============================] - 5s 469us/sample - loss: 0.4674 - acc: 0.8710\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1034 - acc: 0.9646 - val_loss: 0.4666 - val_acc: 0.8710\n",
      "Epoch 50/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.4010 - acc: 0.8877\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0993 - acc: 0.9658 - val_loss: 0.4017 - val_acc: 0.8877\n",
      "Epoch 51/70\n",
      "10000/10000 [==============================] - 5s 464us/sample - loss: 0.4665 - acc: 0.8758\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0947 - acc: 0.9679 - val_loss: 0.4679 - val_acc: 0.8758\n",
      "Epoch 52/70\n",
      "10000/10000 [==============================] - 5s 472us/sample - loss: 0.4079 - acc: 0.8831\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.0894 - acc: 0.9696 - val_loss: 0.4082 - val_acc: 0.8831\n",
      "Epoch 53/70\n",
      "10000/10000 [==============================] - 5s 456us/sample - loss: 0.4507 - acc: 0.8848\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.0887 - acc: 0.9703 - val_loss: 0.4519 - val_acc: 0.8848\n",
      "Epoch 54/70\n",
      "10000/10000 [==============================] - 5s 465us/sample - loss: 0.4262 - acc: 0.8841\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.0838 - acc: 0.9715 - val_loss: 0.4276 - val_acc: 0.8841\n",
      "Epoch 55/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.5131 - acc: 0.8677\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.0801 - acc: 0.9732 - val_loss: 0.5134 - val_acc: 0.8677\n",
      "Epoch 56/70\n",
      "10000/10000 [==============================] - 5s 462us/sample - loss: 0.4236 - acc: 0.8868\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0743 - acc: 0.9753 - val_loss: 0.4242 - val_acc: 0.8868\n",
      "Epoch 57/70\n",
      "10000/10000 [==============================] - 5s 461us/sample - loss: 0.4075 - acc: 0.8898\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.0729 - acc: 0.9764 - val_loss: 0.4072 - val_acc: 0.8898\n",
      "Epoch 58/70\n",
      "10000/10000 [==============================] - 5s 461us/sample - loss: 0.4162 - acc: 0.8897\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.0731 - acc: 0.9760 - val_loss: 0.4161 - val_acc: 0.8897\n",
      "Epoch 59/70\n",
      "10000/10000 [==============================] - 5s 468us/sample - loss: 0.4454 - acc: 0.8853\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0714 - acc: 0.9764 - val_loss: 0.4461 - val_acc: 0.8853\n",
      "Epoch 60/70\n",
      "10000/10000 [==============================] - 5s 461us/sample - loss: 0.4510 - acc: 0.8839\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0680 - acc: 0.9771 - val_loss: 0.4525 - val_acc: 0.8839\n",
      "Epoch 61/70\n",
      "10000/10000 [==============================] - 5s 459us/sample - loss: 0.4390 - acc: 0.8842\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.0622 - acc: 0.9795 - val_loss: 0.4393 - val_acc: 0.8842\n",
      "Epoch 62/70\n",
      "10000/10000 [==============================] - 5s 461us/sample - loss: 0.4090 - acc: 0.8886\n",
      "782/782 [==============================] - 85s 109ms/step - loss: 0.0645 - acc: 0.9793 - val_loss: 0.4098 - val_acc: 0.8886\n",
      "Epoch 63/70\n",
      "10000/10000 [==============================] - 5s 460us/sample - loss: 0.4309 - acc: 0.8882\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0594 - acc: 0.9810 - val_loss: 0.4324 - val_acc: 0.8882\n",
      "Epoch 64/70\n",
      "10000/10000 [==============================] - 5s 465us/sample - loss: 0.4395 - acc: 0.8865\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0574 - acc: 0.9827 - val_loss: 0.4401 - val_acc: 0.8865\n",
      "Epoch 65/70\n",
      "10000/10000 [==============================] - 5s 466us/sample - loss: 0.4097 - acc: 0.8915\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.0558 - acc: 0.9831 - val_loss: 0.4102 - val_acc: 0.8915\n",
      "Epoch 66/70\n",
      "10000/10000 [==============================] - 5s 458us/sample - loss: 0.4173 - acc: 0.8929\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0516 - acc: 0.9839 - val_loss: 0.4185 - val_acc: 0.8929\n",
      "Epoch 67/70\n",
      "10000/10000 [==============================] - 5s 456us/sample - loss: 0.4091 - acc: 0.8912\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0519 - acc: 0.9837 - val_loss: 0.4096 - val_acc: 0.8912\n",
      "Epoch 68/70\n",
      "10000/10000 [==============================] - 5s 459us/sample - loss: 0.4076 - acc: 0.8934\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0509 - acc: 0.9845 - val_loss: 0.4082 - val_acc: 0.8934\n",
      "Epoch 69/70\n",
      "10000/10000 [==============================] - 5s 463us/sample - loss: 0.4013 - acc: 0.8929\n",
      "782/782 [==============================] - 85s 109ms/step - loss: 0.0502 - acc: 0.9839 - val_loss: 0.4017 - val_acc: 0.8929\n",
      "Epoch 70/70\n",
      "10000/10000 [==============================] - 5s 460us/sample - loss: 0.4020 - acc: 0.8935\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.0492 - acc: 0.9845 - val_loss: 0.4026 - val_acc: 0.8935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fecedcb75c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the network\n",
    "print('[INFO] training network....')\n",
    "model.fit_generator(aug.flow(trainx, trainy, batch_size=batch_size),\n",
    "                    validation_data=(testx, testy),\n",
    "                    steps_per_epoch=len(trainx) // batch_size,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}