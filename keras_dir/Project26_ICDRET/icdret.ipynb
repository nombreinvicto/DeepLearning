{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.axes._axes as axes\n",
    "from statistics import stdev, mean\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "total_iter = 100\n",
    "epoch_no = 300\n",
    "initial_rate = 1e-3\n",
    "\n",
    "def poly_decay(epoch):\n",
    "    max_epochs = epoch_no\n",
    "    baseLR = initial_rate\n",
    "    power = 1.0\n",
    "\n",
    "    alpha = baseLR * (1 - (epoch / float(max_epochs))) ** power\n",
    "    return alpha"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (307, 18)\n",
      "Head of data: .....\n",
      "    AREA  PERIMETER  CELL_ID     Lon     Lat  cdirjan  cdirfeb  cdirmar  \\\n",
      "0  0.127      1.427   287108  88.394  27.461     4954     3491     3231   \n",
      "1  0.126      1.426   288108  88.024  27.392     5138     3858     3814   \n",
      "2  0.126      1.423   285107  89.207  27.262     5676     4556     4011   \n",
      "3  0.126      1.421   286107  88.838  27.198     5518     4099     3790   \n",
      "4  0.125      1.420   287107  88.469  27.133     5128     4063     3735   \n",
      "\n",
      "   cdirapr  cdirmay  cdirjun  cdirjul  cdiraug  cdirsep  cdiroct  cdirnov  \\\n",
      "0     3306     2959     2053     1521     1750     1890     5114     4981   \n",
      "1     4181     3732     2263     1478     1702     2319     5631     5298   \n",
      "2     4070     3472     2124     1540     1786     2195     6022     5906   \n",
      "3     3727     2930     2110     1310     1858     1944     5508     5646   \n",
      "4     4206     3610     2553     1586     2197     2640     6258     5451   \n",
      "\n",
      "   cdirdec  cdirann  \n",
      "0     5233     3373  \n",
      "1     5473     3740  \n",
      "2     6048     3950  \n",
      "3     5725     3680  \n",
      "4     5740     3930  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(filepath_or_buffer='bangl40kmdir.csv')\n",
    "print(f\"Shape of data: {data.shape}\")\n",
    "print(f\"Head of data: .....\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after column dropped:.....\n",
      "    AREA  PERIMETER     Lon     Lat  cdirjan  cdirfeb  cdirmar  cdirapr  \\\n",
      "0  0.127      1.427  88.394  27.461     4954     3491     3231     3306   \n",
      "1  0.126      1.426  88.024  27.392     5138     3858     3814     4181   \n",
      "2  0.126      1.423  89.207  27.262     5676     4556     4011     4070   \n",
      "3  0.126      1.421  88.838  27.198     5518     4099     3790     3727   \n",
      "4  0.125      1.420  88.469  27.133     5128     4063     3735     4206   \n",
      "\n",
      "   cdirmay  cdirjun  cdirjul  cdiraug  cdirsep  cdiroct  cdirnov  cdirdec  \n",
      "0     2959     2053     1521     1750     1890     5114     4981     5233  \n",
      "1     3732     2263     1478     1702     2319     5631     5298     5473  \n",
      "2     3472     2124     1540     1786     2195     6022     5906     6048  \n",
      "3     2930     2110     1310     1858     1944     5508     5646     5725  \n",
      "4     3610     2553     1586     2197     2640     6258     5451     5740  \n"
     ]
    }
   ],
   "source": [
    "# drop the cell column\n",
    "data.drop(axis=1, columns=['CELL_ID', 'cdirann'], inplace=True)\n",
    "print(f\"Dataset after column dropped:.....\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "transformed_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Transformed Data: (307, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       AREA  PERIMETER       Lon       Lat   cdirjan   cdirfeb   cdirmar  \\\n0  2.220518   2.139975 -1.181275  2.092918 -0.440599 -1.090284 -1.469974   \n1  2.061056   2.113542 -1.397072  2.055000 -0.229423 -0.668575 -0.527803   \n2  2.061056   2.034242 -0.707106  1.983559  0.388037  0.133476 -0.209437   \n3  2.061056   1.981376 -0.922319  1.948389  0.206701 -0.391649 -0.566589   \n4  1.901595   1.954942 -1.137533  1.912669 -0.240900 -0.433016 -0.655473   \n\n    cdirapr   cdirmay   cdirjun   cdirjul   cdiraug   cdirsep   cdiroct  \\\n0 -0.706887 -0.724947  1.301844  2.439707  0.568503  0.081891  0.378378   \n1  0.950101  0.712523  1.903646  2.220726  0.400109  1.605891  1.696027   \n2  0.739901  0.229028  1.505310  2.536466  0.694799  1.165388  2.692546   \n3  0.090361 -0.778875  1.465190  1.365174  0.947391  0.273724  1.382544   \n4  0.997444  0.485652  2.734708  2.770724  2.136678  2.746227  3.294026   \n\n    cdirnov   cdirdec  \n0  0.131528 -0.595965  \n1  0.860217 -0.283600  \n2  2.257829  0.464774  \n3  1.660166  0.044383  \n4  1.211919  0.063906  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AREA</th>\n      <th>PERIMETER</th>\n      <th>Lon</th>\n      <th>Lat</th>\n      <th>cdirjan</th>\n      <th>cdirfeb</th>\n      <th>cdirmar</th>\n      <th>cdirapr</th>\n      <th>cdirmay</th>\n      <th>cdirjun</th>\n      <th>cdirjul</th>\n      <th>cdiraug</th>\n      <th>cdirsep</th>\n      <th>cdiroct</th>\n      <th>cdirnov</th>\n      <th>cdirdec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.220518</td>\n      <td>2.139975</td>\n      <td>-1.181275</td>\n      <td>2.092918</td>\n      <td>-0.440599</td>\n      <td>-1.090284</td>\n      <td>-1.469974</td>\n      <td>-0.706887</td>\n      <td>-0.724947</td>\n      <td>1.301844</td>\n      <td>2.439707</td>\n      <td>0.568503</td>\n      <td>0.081891</td>\n      <td>0.378378</td>\n      <td>0.131528</td>\n      <td>-0.595965</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.061056</td>\n      <td>2.113542</td>\n      <td>-1.397072</td>\n      <td>2.055000</td>\n      <td>-0.229423</td>\n      <td>-0.668575</td>\n      <td>-0.527803</td>\n      <td>0.950101</td>\n      <td>0.712523</td>\n      <td>1.903646</td>\n      <td>2.220726</td>\n      <td>0.400109</td>\n      <td>1.605891</td>\n      <td>1.696027</td>\n      <td>0.860217</td>\n      <td>-0.283600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.061056</td>\n      <td>2.034242</td>\n      <td>-0.707106</td>\n      <td>1.983559</td>\n      <td>0.388037</td>\n      <td>0.133476</td>\n      <td>-0.209437</td>\n      <td>0.739901</td>\n      <td>0.229028</td>\n      <td>1.505310</td>\n      <td>2.536466</td>\n      <td>0.694799</td>\n      <td>1.165388</td>\n      <td>2.692546</td>\n      <td>2.257829</td>\n      <td>0.464774</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.061056</td>\n      <td>1.981376</td>\n      <td>-0.922319</td>\n      <td>1.948389</td>\n      <td>0.206701</td>\n      <td>-0.391649</td>\n      <td>-0.566589</td>\n      <td>0.090361</td>\n      <td>-0.778875</td>\n      <td>1.465190</td>\n      <td>1.365174</td>\n      <td>0.947391</td>\n      <td>0.273724</td>\n      <td>1.382544</td>\n      <td>1.660166</td>\n      <td>0.044383</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.901595</td>\n      <td>1.954942</td>\n      <td>-1.137533</td>\n      <td>1.912669</td>\n      <td>-0.240900</td>\n      <td>-0.433016</td>\n      <td>-0.655473</td>\n      <td>0.997444</td>\n      <td>0.485652</td>\n      <td>2.734708</td>\n      <td>2.770724</td>\n      <td>2.136678</td>\n      <td>2.746227</td>\n      <td>3.294026</td>\n      <td>1.211919</td>\n      <td>0.063906</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = pd.DataFrame(data=transformed_data,\n",
    "                                columns=data.columns)\n",
    "print(f\"Shape of Transformed Data: {transformed_data.shape}\")\n",
    "transformed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_labels = ['AREA', 'PERIMETER', 'Lon', 'Lat']\n",
    "x = transformed_data[x_labels]\n",
    "y = transformed_data.drop(x_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# do the data split\n",
    "def get_data(testSize):\n",
    "    trainx, testx, trainy, testy = train_test_split(x, y, test_size=testSize)\n",
    "    trainx = np.array(trainx)\n",
    "    testx = np.array(testx)\n",
    "    trainy = np.array(trainy)\n",
    "    testy = np.array(testy)\n",
    "\n",
    "    return trainx, testx, trainy, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prediction_model(trainxShape, trainyShape):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(512, input_dim=trainxShape, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(trainyShape))\n",
    "\n",
    "    opt = Adam(lr=initial_rate)\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[RootMeanSquaredError(), coeff_determination])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Fitting Started for Iteration: 1\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 2\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 3\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 4\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 5\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 6\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 7\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 8\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 9\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 10\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 11\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 12\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 13\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 14\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 15\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 16\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 17\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 18\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 19\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 20\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 21\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 22\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 23\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 24\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 25\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 26\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 27\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 28\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 29\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 30\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 31\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 32\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 33\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 34\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 35\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 36\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 37\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 38\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 39\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 40\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 41\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 42\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 43\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 44\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 45\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 46\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 47\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 48\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 49\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 50\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 51\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 52\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 53\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 54\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 55\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 56\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 57\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 58\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 59\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 60\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 61\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 62\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 63\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 64\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 65\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 66\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 67\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 68\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 69\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 70\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 71\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 72\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 73\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 74\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 75\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 76\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 77\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 78\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 79\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 80\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 81\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 82\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 83\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 84\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 85\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 86\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 87\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 88\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 89\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 90\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 91\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 92\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 93\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 94\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 95\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 96\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 97\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 98\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 99\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Model Fitting Started for Iteration: 100\n",
      "Plotting and storing performance curves.....\n",
      "==================================================\n",
      "Serialising output as JSON.....\n"
     ]
    }
   ],
   "source": [
    "best_r2_history = []\n",
    "best_rmse_history = []\n",
    "\n",
    "\n",
    "for iteration in range(1,total_iter+1):\n",
    "\n",
    "    print(f\"Model Fitting Started for Iteration: {iteration}\")\n",
    "    trainx, testx, trainy, testy = get_data(testSize=0.3)\n",
    "    model = prediction_model(trainx.shape[1], trainy.shape[1])\n",
    "\n",
    "    H = model.fit(trainx, trainy,\n",
    "              validation_data=(testx, testy),\n",
    "              epochs=epoch_no,\n",
    "              verbose=0,\n",
    "              callbacks=[LearningRateScheduler(poly_decay)])\n",
    "\n",
    "    print(f\"Plotting and storing performance curves.....\")\n",
    "    epochs = range(1,epoch_no+1)\n",
    "    train_loss = H.history['loss']\n",
    "    train_rmse = H.history['root_mean_squared_error']\n",
    "\n",
    "    val_loss = H.history['val_loss']\n",
    "    val_rmse = H.history['val_root_mean_squared_error']\n",
    "    val_R2 = H.history['val_coeff_determination']\n",
    "\n",
    "    # store the best R2\n",
    "    best_r2_history.append(float(val_R2[-1]))\n",
    "    best_rmse_history.append(float(val_rmse[-1]))\n",
    "\n",
    "    plot_df = pd.DataFrame(data=np.c_[epochs,train_loss,train_rmse,val_loss,\n",
    "                                      val_rmse, val_R2],\n",
    "                           columns=['epochs','train_loss', 'train_rmse',\n",
    "                                    'val_loss', 'val_rmse', 'val_R2'])\n",
    "\n",
    "    sns.set(font_scale=1)\n",
    "    f, ax = plt.subplots(1, 1, figsize=(18,10))\n",
    "    sns.lineplot(data=plot_df, x='epochs', y='train_rmse',\n",
    "                 ax=ax, label='train_rmse', linewidth=3)\n",
    "    sns.lineplot(data=plot_df, x='epochs', y='val_rmse',\n",
    "                 ax=ax, label='val_rmse', linewidth=3)\n",
    "    sns.lineplot(data=plot_df, x='epochs', y='val_R2',\n",
    "                 ax=ax, label='R2_score', linewidth=3)\n",
    "\n",
    "    ax.set_ylabel('RMSE/R2')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_title(f\"Performance Curves of Iteration: {iteration}\")\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='18')# for legend text\n",
    "    plt.savefig(f\"output/curve_iter_{iteration}\");\n",
    "    plt.close(fig=f)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "print(f\"Serialising output as JSON.....\")\n",
    "out_dict = {\n",
    "    'r2': best_r2_history,\n",
    "    'rmse': best_rmse_history\n",
    "}\n",
    "\n",
    "f = open('output/out_dict.json', 'w')\n",
    "f.write(json.dumps(out_dict))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score statistics.....\n",
      "Mean R2 Score:  0.8219685661792755\n",
      "STD_Dev of R2 Score:  0.029001416553739348\n",
      "RMSE statistics.....\n",
      "Mean RMSE:  0.41508217453956603\n",
      "STD_Dev of RMSE 0.03207919231549063\n"
     ]
    }
   ],
   "source": [
    "# print the avg and the std dev of the r2 scores and validation rmse\n",
    "print(f\"R2 Score statistics.....\")\n",
    "print(\"Mean R2 Score: \", mean(best_r2_history))\n",
    "print(f\"STD_Dev of R2 Score: \", stdev(best_r2_history))\n",
    "\n",
    "print(f\"RMSE statistics.....\")\n",
    "print(\"Mean RMSE: \", mean(best_rmse_history))\n",
    "print(f\"STD_Dev of RMSE\", stdev(best_rmse_history))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.220518\t2.139975\t-1.181275\t2.092918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = np.array([[2.220518, 2.139975, -1.181275, 2.092918]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_op = model.predict(sample_input)\n",
    "sample_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_data = np.hstack((sample_input, sample_op))\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.26999998e-01, 1.42700000e+00, 8.83940006e+01, 2.74610000e+01,\n",
       "        4.98678980e+03, 3.92071968e+03, 3.59750531e+03, 4.02984843e+03,\n",
       "        3.32738933e+03, 2.30557796e+03, 1.44067773e+03, 1.81906735e+03,\n",
       "        2.31034458e+03, 5.77743285e+03, 5.17155548e+03, 5.44689920e+03]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=trainx.shape[1], activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(trainy.shape[1]))\n",
    "\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss='mse',\n",
    "              optimizer=opt,\n",
    "              metrics=['mae', 'mse', coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=trainx.shape[1], activation='relu'))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(trainy.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}