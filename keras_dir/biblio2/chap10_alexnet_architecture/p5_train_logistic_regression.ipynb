{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearch has been postponed in this notebook since it was taking up a lot of RAM space for the large dataset we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "loader_util_path = r\"/home/mhasan3/Desktop/WorkFolder/\"\n",
    "sys.path.append(loader_util_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.axes._axes as axes\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import the necessary keras packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from loader_util.preprocessing import ImageToArrayPreprocessor, AspectAwarePreprocessor\n",
    "from loader_util.datasets import SimpleDatasetLoader\n",
    "from loader_util.nn.conv import FCHeadNet\n",
    "##\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import scoring and utility functions from sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, ShuffleSplit\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "#\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct the argument parser\n",
    "data_dir = r\"/home/mhasan3/Desktop/WorkFolder/cats_vs_dogs/\"\n",
    "\n",
    "args = {\n",
    "    \"dataset\": f\"{data_dir}//hdf5//extracted_features.hdf5\",\n",
    "    \"model\": f\"{data_dir}//outputs//extracted_features_lr_model.pt\",\n",
    "    \"jobs\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# open the hdf5 dataset to get the extracted features\n",
    "db = h5py.File(args[\"dataset\"], \"r\")\n",
    "i = int(db[\"labels\"].shape[0] * 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] tuning hyperparameters.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# define the set of gridsearch parameters\n",
    "print(f'[INFO] tuning hyperparameters.....')\n",
    "# params = {\"C\": [0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "# model = GridSearchCV(LogisticRegression(solver=\"lbfgs\",\n",
    "#                                         multi_class=\"auto\"),\n",
    "#                      param_grid=params,\n",
    "#                      cv=3,\n",
    "#                      n_jobs=args[\"jobs\"])\n",
    "# model.fit(db[\"extracted_features\"][:i], db[\"labels\"][:i])\n",
    "# print(f'[INFO] best hyperparameters are: {model.best_params_}.....')\n",
    "\n",
    "lr = LogisticRegression()\n",
    "fit = lr.fit(db[\"extracted_features\"][:i], db[\"labels\"][:i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'dog']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = [cat.decode() for cat in db[\"label_names\"][:]]\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating.....\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.99      0.99      0.99      3118\n",
      "         dog       0.99      0.99      0.99      3132\n",
      "\n",
      "    accuracy                           0.99      6250\n",
      "   macro avg       0.99      0.99      0.99      6250\n",
      "weighted avg       0.99      0.99      0.99      6250\n",
      "\n",
      "[INFO] score: 0.98912.....\n"
     ]
    }
   ],
   "source": [
    "print(f'[INFO] evaluating.....')\n",
    "model = lr\n",
    "preds = model.predict(db[\"extracted_features\"][i:])\n",
    "print(classification_report(db[\"labels\"][i:], preds,\n",
    "                            target_names=target_names))\n",
    "\n",
    "# compute the raw accuracy with extra precision\n",
    "acc = accuracy_score(db[\"labels\"][i:], preds)\n",
    "print(f'[INFO] score: {acc}.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving model.....\n"
     ]
    }
   ],
   "source": [
    "# serialise the model to disk\n",
    "print(f'[INFO] saving model.....')\n",
    "f = open(args[\"model\"], \"wb\")\n",
    "f.write(pickle.dumps(model))\n",
    "f.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
