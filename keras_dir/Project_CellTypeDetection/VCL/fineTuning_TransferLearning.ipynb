{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Downloading https://files.pythonhosted.org/packages/18/32/c302e32d1cf59fd4132c3d82e4182ddd61ac4f0e22cebec44eb36d2e0fd3/opencv_contrib_python-4.2.0.32-cp36-cp36m-manylinux1_x86_64.whl (34.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 34.2MB 48kB/s  eta 0:00:011   20% |██████▋                         | 7.1MB 58.3MB/s eta 0:00:01    27% |████████▊                       | 9.4MB 32.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.11.3 (from opencv-contrib-python)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.2MB 80kB/s  eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-contrib-python\n",
      "Successfully installed numpy-1.18.1 opencv-contrib-python-4.2.0.32\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from loader_util.preprocessing import ImageToArrayPreprocessor, AspectAwarePreprocessor\n",
    "from loader_util.datasets import SimpleDatasetLoader\n",
    "from loader_util.nn.conv import FCHeadNet\n",
    "##\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'dataset': r'/home/mhasan3/Desktop/WorkFolder/flowers17/images/',\n",
    "    'model': 'flowers17.model'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct the image generator\n",
    "aug = ImageDataGenerator(rotation_range=30,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.2,\n",
    "                         zoom_range=0.2, horizontal_flip=True,\n",
    "                         fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# grab the list of images that we'll be describing then extract the class \n",
    "# label names from the imagePaths\n",
    "imagePaths = list(paths.list_images(args['dataset']))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "classNames = [str(x) for x in np.unique(classNames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/1360\n",
      "[INFO] processed 1000/1360\n"
     ]
    }
   ],
   "source": [
    "# initialise the image preprocessor\n",
    "aap = AspectAwarePreprocessor(224,224)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixels\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap, iap])\n",
    "data, labels = sdl.load(imagePaths, verbose=500)\n",
    "data = data.astype('float') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# partition the data into training and test splits\n",
    "trainx, testx, trainy, testy = train_test_split(data,\n",
    "                                                labels,\n",
    "                                                test_size=0.25,\n",
    "                                                random_state=42)\n",
    "\n",
    "# convert labels from integers into vectors\n",
    "le = LabelBinarizer()\n",
    "trainy = le.fit_transform(trainy)\n",
    "testy = le.transform(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the VGG16 network ensuring the head FC layer sets are left off\n",
    "baseModel = VGG16(weights='imagenet', include_top=False, \n",
    "                  input_tensor=Input(shape=(224, 224, 3))) # type: Model\n",
    "\n",
    "# initialise the new head of the network, a set of FC layers followed by \n",
    "# softmax\n",
    "headModel = FCHeadNet.builld(baseModel, len(classNames), D=256) # type: Model\n",
    "\n",
    "# place the head FC model on top of the base model - this will be the actual\n",
    "# model to train\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loop over all the layers in the base model and freeze them\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "340/340 [==============================] - 5s 15ms/sample - loss: 2.2524 - acc: 0.3118\n",
      "32/32 [==============================] - 33s 1s/step - loss: 6.5716 - acc: 0.1588 - val_loss: 2.2510 - val_acc: 0.3118\n",
      "Epoch 2/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 1.7091 - acc: 0.4412\n",
      "32/32 [==============================] - 12s 376ms/step - loss: 2.2449 - acc: 0.3029 - val_loss: 1.7157 - val_acc: 0.4412\n",
      "Epoch 3/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 1.3405 - acc: 0.6029\n",
      "32/32 [==============================] - 12s 382ms/step - loss: 1.9059 - acc: 0.4176 - val_loss: 1.3440 - val_acc: 0.6029\n",
      "Epoch 4/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.9797 - acc: 0.7559\n",
      "32/32 [==============================] - 12s 375ms/step - loss: 1.6611 - acc: 0.4618 - val_loss: 0.9840 - val_acc: 0.7559\n",
      "Epoch 5/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.8474 - acc: 0.7471\n",
      "32/32 [==============================] - 12s 376ms/step - loss: 1.4388 - acc: 0.5451 - val_loss: 0.8531 - val_acc: 0.7471\n",
      "Epoch 6/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.8150 - acc: 0.7265\n",
      "32/32 [==============================] - 12s 376ms/step - loss: 1.3181 - acc: 0.5686 - val_loss: 0.8230 - val_acc: 0.7265\n",
      "Epoch 7/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.7626 - acc: 0.7559\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 1.2272 - acc: 0.6020 - val_loss: 0.7702 - val_acc: 0.7559\n",
      "Epoch 8/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.6823 - acc: 0.8029\n",
      "32/32 [==============================] - 12s 377ms/step - loss: 1.1796 - acc: 0.6078 - val_loss: 0.6903 - val_acc: 0.8029\n",
      "Epoch 9/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.7098 - acc: 0.7588\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 1.0260 - acc: 0.6657 - val_loss: 0.7217 - val_acc: 0.7588\n",
      "Epoch 10/25\n",
      "340/340 [==============================] - 3s 10ms/sample - loss: 0.6534 - acc: 0.7971\n",
      "32/32 [==============================] - 12s 385ms/step - loss: 0.9882 - acc: 0.6745 - val_loss: 0.6560 - val_acc: 0.7971\n",
      "Epoch 11/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.6557 - acc: 0.7794\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.9546 - acc: 0.7000 - val_loss: 0.6700 - val_acc: 0.7794\n",
      "Epoch 12/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.4925 - acc: 0.8500\n",
      "32/32 [==============================] - 12s 380ms/step - loss: 0.9360 - acc: 0.7049 - val_loss: 0.4924 - val_acc: 0.8500\n",
      "Epoch 13/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.5942 - acc: 0.7971\n",
      "32/32 [==============================] - 12s 381ms/step - loss: 0.8382 - acc: 0.7353 - val_loss: 0.6028 - val_acc: 0.7971\n",
      "Epoch 14/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.5015 - acc: 0.8441\n",
      "32/32 [==============================] - 12s 378ms/step - loss: 0.8492 - acc: 0.7343 - val_loss: 0.5127 - val_acc: 0.8441\n",
      "Epoch 15/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.5381 - acc: 0.8265\n",
      "32/32 [==============================] - 12s 374ms/step - loss: 0.8077 - acc: 0.7304 - val_loss: 0.5487 - val_acc: 0.8265\n",
      "Epoch 16/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.5243 - acc: 0.8353\n",
      "32/32 [==============================] - 12s 376ms/step - loss: 0.8393 - acc: 0.7186 - val_loss: 0.5297 - val_acc: 0.8353\n",
      "Epoch 17/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.4553 - acc: 0.8353\n",
      "32/32 [==============================] - 12s 376ms/step - loss: 0.7295 - acc: 0.7843 - val_loss: 0.4623 - val_acc: 0.8353\n",
      "Epoch 18/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.5154 - acc: 0.8382\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 0.7149 - acc: 0.7775 - val_loss: 0.5294 - val_acc: 0.8382\n",
      "Epoch 19/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.4338 - acc: 0.8353\n",
      "32/32 [==============================] - 12s 375ms/step - loss: 0.7205 - acc: 0.7696 - val_loss: 0.4380 - val_acc: 0.8353\n",
      "Epoch 20/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.5076 - acc: 0.8382\n",
      "32/32 [==============================] - 12s 380ms/step - loss: 0.6803 - acc: 0.7725 - val_loss: 0.5115 - val_acc: 0.8382\n",
      "Epoch 21/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.6082 - acc: 0.8147\n",
      "32/32 [==============================] - 12s 382ms/step - loss: 0.6070 - acc: 0.8069 - val_loss: 0.6184 - val_acc: 0.8147\n",
      "Epoch 22/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.4614 - acc: 0.8529\n",
      "32/32 [==============================] - 12s 376ms/step - loss: 0.6265 - acc: 0.7990 - val_loss: 0.4700 - val_acc: 0.8529\n",
      "Epoch 23/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3782 - acc: 0.8676\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 0.6669 - acc: 0.7931 - val_loss: 0.3781 - val_acc: 0.8676\n",
      "Epoch 24/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.6366 - acc: 0.8353\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 0.5544 - acc: 0.8118 - val_loss: 0.6488 - val_acc: 0.8353\n",
      "Epoch 25/25\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.4763 - acc: 0.8471\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 0.5567 - acc: 0.8098 - val_loss: 0.4769 - val_acc: 0.8471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3478121b00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile and optimise model\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the head for few epochs\n",
    "model.fit_generator(aug.flow(trainx, trainy, batch_size=32),\n",
    "                    validation_data=(testx, testy),\n",
    "                    epochs=25,\n",
    "                    steps_per_epoch=len(trainx) // 32,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bluebell       0.63      0.95      0.76        20\n",
      "   buttercup       0.83      0.91      0.87        22\n",
      "   coltsfoot       0.92      0.73      0.81        15\n",
      "     cowslip       0.68      0.85      0.76        20\n",
      "      crocus       1.00      0.70      0.82        23\n",
      "    daffodil       0.70      0.89      0.78        18\n",
      "       daisy       1.00      0.89      0.94        19\n",
      "   dandelion       0.90      0.90      0.90        20\n",
      "  fritillary       1.00      0.75      0.86        20\n",
      "        iris       0.88      0.94      0.91        16\n",
      "  lilyvalley       0.94      0.74      0.83        23\n",
      "       pansy       1.00      0.88      0.93        16\n",
      "    snowdrop       0.72      0.91      0.81        23\n",
      "   sunflower       0.95      1.00      0.97        19\n",
      "   tigerlily       0.96      0.93      0.94        27\n",
      "       tulip       0.73      0.52      0.61        21\n",
      "  windflower       0.89      0.94      0.92        18\n",
      "\n",
      "    accuracy                           0.85       340\n",
      "   macro avg       0.87      0.85      0.85       340\n",
      "weighted avg       0.87      0.85      0.85       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "preds = model.predict(testx, batch_size=32)\n",
    "print(classification_report(testy.argmax(axis=1),\n",
    "                            preds.argmax(axis=1),\n",
    "                            target_names=classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# now that FC layers have been trained, lets unfreeze the final set of CONV \n",
    "# layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3765 - acc: 0.8941\n",
      "32/32 [==============================] - 14s 428ms/step - loss: 0.4800 - acc: 0.8333 - val_loss: 0.3780 - val_acc: 0.8941\n",
      "Epoch 2/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3513 - acc: 0.8971\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.3705 - acc: 0.8843 - val_loss: 0.3522 - val_acc: 0.8971\n",
      "Epoch 3/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3278 - acc: 0.9118\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.3569 - acc: 0.8892 - val_loss: 0.3311 - val_acc: 0.9118\n",
      "Epoch 4/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2968 - acc: 0.9235\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.3498 - acc: 0.8824 - val_loss: 0.2959 - val_acc: 0.9235\n",
      "Epoch 5/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3406 - acc: 0.9147\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.3274 - acc: 0.8990 - val_loss: 0.3419 - val_acc: 0.9147\n",
      "Epoch 6/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3100 - acc: 0.9206\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.3314 - acc: 0.8892 - val_loss: 0.3117 - val_acc: 0.9206\n",
      "Epoch 7/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3091 - acc: 0.9088\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.2759 - acc: 0.9078 - val_loss: 0.3091 - val_acc: 0.9088\n",
      "Epoch 8/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3008 - acc: 0.9265\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.3474 - acc: 0.8784 - val_loss: 0.2987 - val_acc: 0.9265\n",
      "Epoch 9/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3324 - acc: 0.9029\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.2990 - acc: 0.9059 - val_loss: 0.3283 - val_acc: 0.9029\n",
      "Epoch 10/100\n",
      "340/340 [==============================] - 3s 10ms/sample - loss: 0.2900 - acc: 0.9206\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 0.2733 - acc: 0.9069 - val_loss: 0.2888 - val_acc: 0.9206\n",
      "Epoch 11/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3192 - acc: 0.9176\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.2751 - acc: 0.9039 - val_loss: 0.3177 - val_acc: 0.9176\n",
      "Epoch 12/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2984 - acc: 0.9206\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.3117 - acc: 0.8931 - val_loss: 0.2990 - val_acc: 0.9206\n",
      "Epoch 13/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2978 - acc: 0.9235\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.2338 - acc: 0.9225 - val_loss: 0.2972 - val_acc: 0.9235\n",
      "Epoch 14/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2937 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.2306 - acc: 0.9186 - val_loss: 0.2918 - val_acc: 0.9294\n",
      "Epoch 15/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3036 - acc: 0.9176\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.2493 - acc: 0.9167 - val_loss: 0.3033 - val_acc: 0.9176\n",
      "Epoch 16/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2961 - acc: 0.9176\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.2404 - acc: 0.9275 - val_loss: 0.2939 - val_acc: 0.9176\n",
      "Epoch 17/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3008 - acc: 0.9206\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.2326 - acc: 0.9196 - val_loss: 0.3002 - val_acc: 0.9206\n",
      "Epoch 18/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2867 - acc: 0.9324\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.2057 - acc: 0.9412 - val_loss: 0.2848 - val_acc: 0.9324\n",
      "Epoch 19/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3053 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.2377 - acc: 0.9157 - val_loss: 0.3061 - val_acc: 0.9294\n",
      "Epoch 20/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3179 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.2141 - acc: 0.9255 - val_loss: 0.3165 - val_acc: 0.9353\n",
      "Epoch 21/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2909 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.2345 - acc: 0.9216 - val_loss: 0.2889 - val_acc: 0.9294\n",
      "Epoch 22/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2944 - acc: 0.9235\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.2275 - acc: 0.9167 - val_loss: 0.2935 - val_acc: 0.9235\n",
      "Epoch 23/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2992 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1944 - acc: 0.9353 - val_loss: 0.2977 - val_acc: 0.9353\n",
      "Epoch 24/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2858 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.1962 - acc: 0.9373 - val_loss: 0.2842 - val_acc: 0.9294\n",
      "Epoch 25/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2922 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1988 - acc: 0.9333 - val_loss: 0.2890 - val_acc: 0.9353\n",
      "Epoch 26/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2956 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.2048 - acc: 0.9284 - val_loss: 0.2950 - val_acc: 0.9294\n",
      "Epoch 27/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2740 - acc: 0.9324\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.1988 - acc: 0.9422 - val_loss: 0.2694 - val_acc: 0.9324\n",
      "Epoch 28/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3003 - acc: 0.9324\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.1690 - acc: 0.9422 - val_loss: 0.2969 - val_acc: 0.9324\n",
      "Epoch 29/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2765 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.1879 - acc: 0.9382 - val_loss: 0.2733 - val_acc: 0.9353\n",
      "Epoch 30/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2691 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.1848 - acc: 0.9402 - val_loss: 0.2662 - val_acc: 0.9382\n",
      "Epoch 31/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3179 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1600 - acc: 0.9490 - val_loss: 0.3152 - val_acc: 0.9294\n",
      "Epoch 32/100\n",
      "340/340 [==============================] - 4s 12ms/sample - loss: 0.2933 - acc: 0.9324\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 0.1961 - acc: 0.9333 - val_loss: 0.3161 - val_acc: 0.9324\n",
      "Epoch 33/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2847 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.1850 - acc: 0.9382 - val_loss: 0.2831 - val_acc: 0.9294\n",
      "Epoch 34/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2894 - acc: 0.9235\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1567 - acc: 0.9451 - val_loss: 0.2876 - val_acc: 0.9235\n",
      "Epoch 35/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3034 - acc: 0.9265\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1598 - acc: 0.9500 - val_loss: 0.3043 - val_acc: 0.9265\n",
      "Epoch 36/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2914 - acc: 0.9235\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1663 - acc: 0.9363 - val_loss: 0.2891 - val_acc: 0.9235\n",
      "Epoch 37/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2888 - acc: 0.9324\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.1756 - acc: 0.9422 - val_loss: 0.2884 - val_acc: 0.9324\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2754 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.1798 - acc: 0.9314 - val_loss: 0.2758 - val_acc: 0.9294\n",
      "Epoch 39/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2645 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.1723 - acc: 0.9451 - val_loss: 0.2607 - val_acc: 0.9382\n",
      "Epoch 40/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2985 - acc: 0.9324\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.1661 - acc: 0.9422 - val_loss: 0.2974 - val_acc: 0.9324\n",
      "Epoch 41/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2831 - acc: 0.9324\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.1930 - acc: 0.9333 - val_loss: 0.2773 - val_acc: 0.9324\n",
      "Epoch 42/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3133 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1726 - acc: 0.9402 - val_loss: 0.3102 - val_acc: 0.9294\n",
      "Epoch 43/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2704 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1773 - acc: 0.9314 - val_loss: 0.2691 - val_acc: 0.9353\n",
      "Epoch 44/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.3095 - acc: 0.9235\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1582 - acc: 0.9500 - val_loss: 0.3068 - val_acc: 0.9235\n",
      "Epoch 45/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2488 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1575 - acc: 0.9471 - val_loss: 0.2463 - val_acc: 0.9412\n",
      "Epoch 46/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2684 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1715 - acc: 0.9402 - val_loss: 0.2663 - val_acc: 0.9382\n",
      "Epoch 47/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2971 - acc: 0.9324\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.1575 - acc: 0.9471 - val_loss: 0.2932 - val_acc: 0.9324\n",
      "Epoch 48/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2835 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.1681 - acc: 0.9402 - val_loss: 0.2800 - val_acc: 0.9353\n",
      "Epoch 49/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2832 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1575 - acc: 0.9461 - val_loss: 0.2786 - val_acc: 0.9412\n",
      "Epoch 50/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2606 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.1855 - acc: 0.9333 - val_loss: 0.2571 - val_acc: 0.9412\n",
      "Epoch 51/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2667 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.1837 - acc: 0.9353 - val_loss: 0.2656 - val_acc: 0.9382\n",
      "Epoch 52/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2557 - acc: 0.9441\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1810 - acc: 0.9422 - val_loss: 0.2544 - val_acc: 0.9441\n",
      "Epoch 53/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2851 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1481 - acc: 0.9490 - val_loss: 0.2871 - val_acc: 0.9294\n",
      "Epoch 54/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2733 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.1470 - acc: 0.9500 - val_loss: 0.2720 - val_acc: 0.9412\n",
      "Epoch 55/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2641 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1337 - acc: 0.9588 - val_loss: 0.2652 - val_acc: 0.9382\n",
      "Epoch 56/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2520 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1414 - acc: 0.9471 - val_loss: 0.2516 - val_acc: 0.9353\n",
      "Epoch 57/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2670 - acc: 0.9441\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1499 - acc: 0.9529 - val_loss: 0.2647 - val_acc: 0.9441\n",
      "Epoch 58/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2727 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1419 - acc: 0.9451 - val_loss: 0.2684 - val_acc: 0.9294\n",
      "Epoch 59/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2657 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.1211 - acc: 0.9598 - val_loss: 0.2616 - val_acc: 0.9353\n",
      "Epoch 60/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2662 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.1443 - acc: 0.9500 - val_loss: 0.2642 - val_acc: 0.9382\n",
      "Epoch 61/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2852 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1660 - acc: 0.9441 - val_loss: 0.2848 - val_acc: 0.9412\n",
      "Epoch 62/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2828 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.1535 - acc: 0.9490 - val_loss: 0.2816 - val_acc: 0.9353\n",
      "Epoch 63/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2457 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1381 - acc: 0.9618 - val_loss: 0.2450 - val_acc: 0.9412\n",
      "Epoch 64/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2880 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.1188 - acc: 0.9588 - val_loss: 0.2866 - val_acc: 0.9412\n",
      "Epoch 65/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2558 - acc: 0.9324\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1371 - acc: 0.9461 - val_loss: 0.2511 - val_acc: 0.9324\n",
      "Epoch 66/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2701 - acc: 0.9441\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.1239 - acc: 0.9559 - val_loss: 0.2660 - val_acc: 0.9441\n",
      "Epoch 67/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2392 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.1529 - acc: 0.9422 - val_loss: 0.2361 - val_acc: 0.9382\n",
      "Epoch 68/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2592 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1209 - acc: 0.9520 - val_loss: 0.2574 - val_acc: 0.9382\n",
      "Epoch 69/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2633 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.1151 - acc: 0.9598 - val_loss: 0.2624 - val_acc: 0.9382\n",
      "Epoch 70/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2798 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.1226 - acc: 0.9588 - val_loss: 0.2818 - val_acc: 0.9412\n",
      "Epoch 71/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2790 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.1310 - acc: 0.9578 - val_loss: 0.2785 - val_acc: 0.9382\n",
      "Epoch 72/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2628 - acc: 0.9324\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1444 - acc: 0.9529 - val_loss: 0.2606 - val_acc: 0.9324\n",
      "Epoch 73/100\n",
      "340/340 [==============================] - 3s 10ms/sample - loss: 0.2821 - acc: 0.9471\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.1178 - acc: 0.9588 - val_loss: 0.2783 - val_acc: 0.9471\n",
      "Epoch 74/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2581 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1120 - acc: 0.9608 - val_loss: 0.2556 - val_acc: 0.9412\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2478 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1189 - acc: 0.9588 - val_loss: 0.2469 - val_acc: 0.9412\n",
      "Epoch 76/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2501 - acc: 0.9441\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.1428 - acc: 0.9569 - val_loss: 0.2501 - val_acc: 0.9441\n",
      "Epoch 77/100\n",
      "340/340 [==============================] - 4s 12ms/sample - loss: 0.2678 - acc: 0.9353\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 0.1234 - acc: 0.9520 - val_loss: 0.2685 - val_acc: 0.9353\n",
      "Epoch 78/100\n",
      "340/340 [==============================] - 3s 10ms/sample - loss: 0.2839 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.1181 - acc: 0.9520 - val_loss: 0.2820 - val_acc: 0.9353\n",
      "Epoch 79/100\n",
      "340/340 [==============================] - 4s 11ms/sample - loss: 0.2718 - acc: 0.9412\n",
      "32/32 [==============================] - 14s 432ms/step - loss: 0.1165 - acc: 0.9627 - val_loss: 0.2841 - val_acc: 0.9412\n",
      "Epoch 80/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2510 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1424 - acc: 0.9490 - val_loss: 0.2501 - val_acc: 0.9382\n",
      "Epoch 81/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2721 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.1459 - acc: 0.9490 - val_loss: 0.2737 - val_acc: 0.9382\n",
      "Epoch 82/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2569 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1241 - acc: 0.9520 - val_loss: 0.2580 - val_acc: 0.9382\n",
      "Epoch 83/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2397 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.1233 - acc: 0.9637 - val_loss: 0.2372 - val_acc: 0.9412\n",
      "Epoch 84/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2791 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1052 - acc: 0.9647 - val_loss: 0.2768 - val_acc: 0.9353\n",
      "Epoch 85/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2758 - acc: 0.9441\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.0950 - acc: 0.9686 - val_loss: 0.2764 - val_acc: 0.9441\n",
      "Epoch 86/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2629 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.1267 - acc: 0.9578 - val_loss: 0.2616 - val_acc: 0.9353\n",
      "Epoch 87/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2366 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1350 - acc: 0.9500 - val_loss: 0.2345 - val_acc: 0.9412\n",
      "Epoch 88/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2356 - acc: 0.9471\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.1034 - acc: 0.9608 - val_loss: 0.2325 - val_acc: 0.9471\n",
      "Epoch 89/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2458 - acc: 0.9294\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1421 - acc: 0.9569 - val_loss: 0.2440 - val_acc: 0.9294\n",
      "Epoch 90/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2396 - acc: 0.9471\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1204 - acc: 0.9539 - val_loss: 0.2359 - val_acc: 0.9471\n",
      "Epoch 91/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2548 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1104 - acc: 0.9569 - val_loss: 0.2549 - val_acc: 0.9353\n",
      "Epoch 92/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2426 - acc: 0.9382\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.0938 - acc: 0.9686 - val_loss: 0.2398 - val_acc: 0.9382\n",
      "Epoch 93/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2556 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1064 - acc: 0.9637 - val_loss: 0.2560 - val_acc: 0.9353\n",
      "Epoch 94/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2536 - acc: 0.9441\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.1078 - acc: 0.9647 - val_loss: 0.2523 - val_acc: 0.9441\n",
      "Epoch 95/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2635 - acc: 0.9471\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.1021 - acc: 0.9676 - val_loss: 0.2656 - val_acc: 0.9471\n",
      "Epoch 96/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2453 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.1133 - acc: 0.9608 - val_loss: 0.2416 - val_acc: 0.9412\n",
      "Epoch 97/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2521 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.1055 - acc: 0.9676 - val_loss: 0.2508 - val_acc: 0.9412\n",
      "Epoch 98/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2664 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.0950 - acc: 0.9667 - val_loss: 0.2666 - val_acc: 0.9412\n",
      "Epoch 99/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2498 - acc: 0.9353\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.1058 - acc: 0.9647 - val_loss: 0.2462 - val_acc: 0.9353\n",
      "Epoch 100/100\n",
      "340/340 [==============================] - 3s 9ms/sample - loss: 0.2816 - acc: 0.9412\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.0984 - acc: 0.9676 - val_loss: 0.2834 - val_acc: 0.9412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33b51e2668>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for changes to take effect we need to recompile model\n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.fit_generator(aug.flow(trainx, trainy, batch_size=32),\n",
    "                    validation_data=(testx, testy),\n",
    "                    epochs=100,\n",
    "                    steps_per_epoch=len(trainx) // 32,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bluebell       0.95      0.95      0.95        20\n",
      "   buttercup       1.00      0.91      0.95        22\n",
      "   coltsfoot       0.88      1.00      0.94        15\n",
      "     cowslip       0.74      1.00      0.85        20\n",
      "      crocus       1.00      0.96      0.98        23\n",
      "    daffodil       1.00      0.83      0.91        18\n",
      "       daisy       1.00      0.95      0.97        19\n",
      "   dandelion       1.00      0.90      0.95        20\n",
      "  fritillary       0.95      0.90      0.92        20\n",
      "        iris       1.00      0.81      0.90        16\n",
      "  lilyvalley       0.88      1.00      0.94        23\n",
      "       pansy       0.94      1.00      0.97        16\n",
      "    snowdrop       0.88      1.00      0.94        23\n",
      "   sunflower       1.00      1.00      1.00        19\n",
      "   tigerlily       0.96      0.96      0.96        27\n",
      "       tulip       1.00      0.86      0.92        21\n",
      "  windflower       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.94       340\n",
      "   macro avg       0.95      0.94      0.94       340\n",
      "weighted avg       0.95      0.94      0.94       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network again\n",
    "preds = model.predict(testx, batch_size=32)\n",
    "print(classification_report(testy.argmax(axis=1),\n",
    "                            preds.argmax(axis=1),\n",
    "                            target_names=classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save serialised model\n",
    "model.save(args['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
